{"pages":[{"title":"about","text":"想用文字记录一些人生中的事情","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"友情链接","text":"","link":"/links/index.html"}],"posts":[{"title":"Android网络基础","text":"1.HttpClientApache提供的高效的网络访问模块。 Android 2.2(API 8)及以前使用HttpClient比价好，bug少。 但是在最新的Android版本中移除了，如果你还想使用这个，在build.gradle里面添加： android { useLibrary &apos;org.apache.http.legacy&apos; }具体使用方法：String urlAddress = &quot;http://192.168.1.102:8080/qualityserver/login.do&quot;; // 发送GET请求 public String doGet(String username,String password){ String getUrl = urlAddress + &quot;?username=&quot;+username+&quot;&amp;password=&quot;+password; HttpGet httpGet = new HttpGet(getUrl); HttpParams hp = httpGet.getParams(); hp.getParameter(&quot;true&quot;); HttpClient hc = new DefaultHttpClient(); try { HttpResponse ht = hc.execute(httpGet); if(ht.getStatusLine().getStatusCode() == HttpStatus.SC_OK){ HttpEntity he = ht.getEntity(); InputStream is = he.getContent(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String response = &quot;&quot;; String readLine = null; while((readLine =br.readLine()) != null){ //response = br.readLine(); response = response + readLine; } is.close(); br.close(); //String str = EntityUtils.toString(he); System.out.println(&quot;=========&quot;+response); return response; }else{ return &quot;error&quot;; } } catch (ClientProtocolException e) { e.printStackTrace(); return &quot;exception&quot;; } catch (IOException e) { e.printStackTrace(); return &quot;exception&quot;; } } public String doPost(String username,String password){ //String getUrl = urlAddress + &quot;?username=&quot;+username+&quot;&amp;password=&quot;+password; HttpPost httpPost = new HttpPost(urlAddress); List params = new ArrayList(); NameValuePair pair1 = new BasicNameValuePair(&quot;username&quot;, username); NameValuePair pair2 = new BasicNameValuePair(&quot;password&quot;, password); params.add(pair1); params.add(pair2); HttpEntity he; try { he = new UrlEncodedFormEntity(params, &quot;gbk&quot;); httpPost.setEntity(he); } catch (UnsupportedEncodingException e1) { e1.printStackTrace(); } HttpClient hc = new DefaultHttpClient(); try { HttpResponse ht = hc.execute(httpPost); //连接成功 if(ht.getStatusLine().getStatusCode() == HttpStatus.SC_OK){ HttpEntity het = ht.getEntity(); InputStream is = het.getContent(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String response = &quot;&quot;; String readLine = null; while((readLine =br.readLine()) != null){ //response = br.readLine(); response = response + readLine; } is.close(); br.close(); //String str = EntityUtils.toString(he); System.out.println(&quot;=========&amp;&amp;&quot;+response); return response; }else{ return &quot;error&quot;; } } catch (ClientProtocolException e) { e.printStackTrace(); return &quot;exception&quot;; } catch (IOException e) { e.printStackTrace(); return &quot;exception&quot;; } }2.HttpURLConnectionHttpURLConnection是一种多用途、轻量极的HTTP客户端，使用它来进行HTTP操作可以适用于大多数的应用程序。 注意事项 HttpURLConnection在Android 2.2及以前有一些bug。 参看笔记：Android 4.0 Ice Cream Sandwich GET请求变POST请求 具体使用方法：String urlAddress = &quot;http://192.168.1.102:8080/AndroidServer/login.do&quot;; URL url; HttpURLConnection uRLConnection; //向服务器发送get请求 public String doGet(String username,String password){ String getUrl = urlAddress + &quot;?username=&quot;+username+&quot;&amp;password=&quot;+password; try { url = new URL(getUrl); uRLConnection = (HttpURLConnection)url.openConnection(); InputStream is = uRLConnection.getInputStream(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String response = &quot;&quot;; String readLine = null; while((readLine =br.readLine()) != null){ //response = br.readLine(); response = response + readLine; } is.close(); br.close(); uRLConnection.disconnect(); return response; } catch (MalformedURLException e) { e.printStackTrace(); return null; } catch (IOException e) { e.printStackTrace(); return null; } } //向服务器发送post请求 public String doPost(String username,String password){ try { url = new URL(urlAddress); uRLConnection = (HttpURLConnection)url.openConnection(); uRLConnection.setDoInput(true); uRLConnection.setDoOutput(true); uRLConnection.setRequestMethod(&quot;POST&quot;); uRLConnection.setUseCaches(false); uRLConnection.setInstanceFollowRedirects(false); uRLConnection.setRequestProperty(&quot;Content-Type&quot;, &quot;application/x-www-form-urlencoded&quot;); uRLConnection.connect(); DataOutputStream out = new DataOutputStream(uRLConnection.getOutputStream()); String content = &quot;username=&quot;+username+&quot;&amp;password=&quot;+password; out.writeBytes(content); out.flush(); out.close(); InputStream is = uRLConnection.getInputStream(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String response = &quot;&quot;; String readLine = null; while((readLine =br.readLine()) != null){ //response = br.readLine(); response = response + readLine; } is.close(); br.close(); uRLConnection.disconnect(); return response; } catch (MalformedURLException e) { e.printStackTrace(); return null; } catch (IOException e) { e.printStackTrace(); return null; } }参考资料http://blog.csdn.net/guolin_blog/article/details/12452307","link":"/2015/12/02/Android/Android%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"},{"title":"Android Studio导出并使用aar和jar","text":"今天想往项目中导入Zxing,不知道怎么就想到不使用library的方式而使用包的方式来导入,然后就有了下面的东西了. AARAAR是Android Library的一种新的二进制分发格式，它把资源也一起打包，这样一来图片和布局资源文件也能够被同时分发。同时AAR还可以包含jar包. 1.生成AAR当我们运行工程后,该工程的/build/outputs/arr下包含Android Studio自动打包的AAR文件 2.使用AAR将AAR文件拷贝到项目的libs目录下,然后在项目的build.gradle文件中配置即可 apply plugin: &apos;com.android.application&apos; android { compileSdkVersion 23 buildToolsVersion &quot;23.0.3&quot; defaultConfig { applicationId &quot;com.qtparking.btool_as&quot; minSdkVersion 11 targetSdkVersion 23 versionCode 1 versionName &quot;1.0&quot; } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile(&apos;proguard-android.txt&apos;), &apos;proguard-rules.pro&apos; } } } // 添加arr文件的引用 还要在dependencies里面添加引用 repositories { flatDir { dirs &apos;libs&apos; } } dependencies { compile fileTree(dir: &apos;libs&apos;, include: [&apos;*.jar&apos;]) testCompile &apos;junit:junit:4.12&apos; compile &apos;com.android.support:appcompat-v7:23.3.0&apos; compile &apos;com.android.support:design:23.3.0&apos; // 添加AAR文件的引用,文件名字为zxing,类型为aar compile(name:&apos;zxing&apos;, ext:&apos;aar&apos;) }JarJar包应该不陌生了,但是如何使用Android Studio导出jar包呢? 1.配置gradle任务在需要打包成jar包的项目的build.gradle添加gradle任务: apply plugin: &apos;com.android.library&apos; android { compileSdkVersion 21 buildToolsVersion &quot;21.1.2&quot; defaultConfig { minSdkVersion 9 targetSdkVersion 21 testApplicationId &quot;com.android.volley.tests&quot; testInstrumentationRunner &quot;android.test.InstrumentationTestRunner&quot; } lintOptions { abortOnError false } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile(&apos;proguard-android.txt&apos;), &apos;proguard-rules.txt&apos; } } } task makeJar(type: Copy) { delete &apos;build/libs/lfVolley.jar&apos; //删除旧的jar包 from(&apos;build/intermediates/bundles/release/&apos;) // 文件来自哪里 into(&apos;build/libs/&apos;) // 生成的jar包存放目录 include(&apos;classes.jar&apos;) rename (&apos;classes.jar&apos;, &apos;lfVolley.jar&apos;) // 重命名成我们的jar包 } makeJar.dependsOn(build) dependencies { compile &apos;com.android.support:support-v4:21.0.3&apos; }2.执行gradle任务有的文章中推荐我们执行:./gradview makeJar.但是,我个人测试是无法成功的.可以通过Android Studio来执行gradle任务: 2.1在Gradle projects中寻找需要打包的Module: 2.2找到makeJar的gradle任务并双击执行: 2.3gradle任务执行完成后显示如下: 至此,就完成了jar包的生成,可以直接拷贝到其他项目中使用了. TODO:1.有一个小想法,这个是不是和插件化有点关系呢,从来没有了解过插件化,还不知道怎么弄呢.后面有时间再说吧.2.后面研究下如何导出混淆的aar和jar,现在没有时间研究呢还.","link":"/2016/06/27/Android/Android-Studio%E5%AF%BC%E5%87%BA%E5%B9%B6%E4%BD%BF%E7%94%A8aar%E5%92%8Cjar/"},{"title":"Android网络层二次封装","text":"项目介绍对Volley进行二次封装，方便使用和扩展。主要是学习封装的思想。 该示例主体代码来自传智的某位Android讲师，具体不清楚。 网络层封装示意图 接下来前期准备public class App extends Application { public static Context application; public static HttpLoader HL; @Override public void onCreate() { super.onCreate(); application = this; // 初始化网络请求相关的核心类 HL = HttpLoader.getInstance(this); } }不用我介绍了吧，记得在AndroidManiFest文件中添加name属性&amp;&amp;&amp;&amp;&amp;&amp;&amp;联网权限 1.Activity实现HttpListener接口HttpListener是我们连接网络层和UI层的桥梁，记得重写接口中的成功和失败的方法。 2.创建Protocol类发起网络请求new MainProtocol(MainActivity.this,&quot;15613566958&quot;).doRequest(this);这样我们就发起了一个网络请求，感觉简单了好多。 具体MainProtocol的具体实现 public class MainProtocol extends BaseProtrocol { private String phone; private Context actContext; // 传入必备参数 public MainProtocol(Context actContext,String phone) { this.actContext = actContext; this.phone = phone; } @Override public void doRequest(HttpLoader loader, HttpLoader.HttpListener listener) { HttpParams params = new HttpParams().put(&quot;phone&quot;, phone); // 发起GET请求 loader.get(actContext, AppConstants.URL_COUPONS, params, AppConstants.REQUEST_CODE_COUPONS, listener); } }3.HttpLoader–网络请求类单例类，不要问我为什么，这是网络请求的类啊，能不单利吗！！！！ 其中mRequestQueue是保存请求队列的，mInFlightRequests是用来保存已经等待的请求，同时具有过滤重复请求的功能。 get方法会调用request方法，这里才是请求的主体，request方法在发起请求前会通过tryLoadCacheResponse方法首先读取缓存，然后在进行访问网络的操作。然后根据返回结果的不同，分别调用HttpListener的不同的回调方法，这样就把服务器的结果返回到UI层了。 /** * ResponseListener，封装了Volley的错误和成功的回调监听，并执行一些默认处理，同时会将事件通过HttpListener分发到UI层 */ private class ResponseListener implements Response.ErrorListener, Response.Listener&lt;String&gt; { private HttpListener listener; private int requestCode; public ResponseListener(int requestCode, HttpListener listener) { this.listener = listener; this.requestCode = requestCode; } @Override public void onErrorResponse(VolleyError volleyError) { LLog.w(&quot;Request error from network!&quot;); volleyError.printStackTrace(); mInFlightRequests.remove(requestCode);// 请求错误，从请求集合中删除该请求 if (listener != null) { listener.onGetResponseError(requestCode, volleyError); } } @Override public void onResponse(String response) { mInFlightRequests.remove(requestCode);// 请求成功，从请求集合中删除该请求 if (response != null) { //SystemClock.sleep(2000); LLog.i(&quot;Request success from network!&quot;); try { JSONObject jsonObject = new JSONObject(response);// 处理分发数据---解析json String status = jsonObject.getString(&quot;status&quot;); if (listener != null &amp;&amp; response != null) {// 分发数据 if ((&quot;success&quot;.equals(status) || &quot;ok&quot;.equals(status))) { String data = null; try { data = jsonObject.getString(&quot;data&quot;); listener.onGetResponseSuccess(requestCode, data); } catch (Exception e) { // 不是标准格式的时候就把原始数据传回去 listener.onGetResponseSuccess(requestCode, response); } } else if ((&quot;fail&quot;.equals(status) || &quot;error&quot;.equals(status))) { String errMsg = null; try { errMsg = jsonObject.getString(&quot;msg&quot;); } catch (Exception e) { errMsg = jsonObject.getString(&quot;message&quot;); } finally { listener.onGetResponseError(requestCode, new VolleyError(errMsg)); } } } } catch (Exception e) { e.printStackTrace(); listener.onGetResponseError(requestCode, new VolleyError(&quot;解析问题&quot;)); } } } }这之中ResponseListener是关键，他关联了三方框架的回调方法和HttpListener的回调方法。然后不要问我为嘛onResponse里面写了这么多，你是为了健壮性更好吗？ 我能骂街吗？后台返回数据是乱七八糟的好不？ 小结好了，到了这里你肯定还没有看懂，废话，我才写了几篇文章，哪有那么快就写的让你看懂。如果你还没有看懂的话就看我的代码去吧，我不是链接 还是看不懂？ 找我要视频啊~ 看完了再看这几篇文章就好了 多搞搞就好了","link":"/2016/05/18/Android/Android%E7%BD%91%E7%BB%9C%E5%B1%82%E4%BA%8C%E6%AC%A1%E5%B0%81%E8%A3%85/"},{"title":"Volley学习第一篇-框架入口.md","text":"前文概要这是我的Volley学习第一篇的笔记.看了一个星期的各类教程之后的总结,准备把Volley的整体流程都总结一遍,同时会对Volley进行一些扩展,最后会跟着大神的脚步模仿一个Volley出来. 水平有限,望多指教. 资源 郭霖大神的博客 codeKK Volley源码解析 Volley源码 创建全局的RequestQueue使用Volley的时候会创建一个全局的RequestQueue,一般会在自定义的Application类里面创建. RequestQueue requestQueue = Volley.newRequestQueue(appContext);Volley框架的入口点这里我们就发现原来Volley的入口是Volley类里面的一个静态方法newRequestQueue() public static RequestQueue newRequestQueue(Context context) { return newRequestQueue(context, null); }Volley框架的真正的入口这是一个参数的方法,会调用两个参数的newRequestQueue方法,传入一个默认的null. public static RequestQueue newRequestQueue(Context context, HttpStack stack) { File cacheDir = new File(context.getCacheDir(), DEFAULT_CACHE_DIR); String userAgent = &quot;volley/0&quot;; try { String packageName = context.getPackageName(); PackageInfo info = context.getPackageManager().getPackageInfo(packageName, 0); userAgent = packageName + &quot;/&quot; + info.versionCode; } catch (NameNotFoundException e) { } if (stack == null) { if (Build.VERSION.SDK_INT &gt;= 9) { stack = new HurlStack(); } else { // Prior to Gingerbread, HttpUrlConnection was unreliable. // See: http://android-developers.blogspot.com/2011/09/androids-http-clients.html stack = new HttpClientStack(AndroidHttpClient.newInstance(userAgent)); } } Network network = new BasicNetwork(stack); RequestQueue queue = new RequestQueue(new DiskBasedCache(cacheDir), network); queue.start(); return queue; }这里才是真正的创建RequestQueue的地方,因为传入的第二个参数是null,所以stack== null是成立的,这是就会根据不同的系统版本创建不同的HttpStack子类的实例对象,然后将它包装成BasicNetwork对象. 同时第一行的时候就创建了Volley的缓存目录(当然你可以根据你的需求随意更改缓存目录的位置),并将缓存目录包装成一个DiskBasedCache对象. 至此,RequestQueue需要的缓存和网络请求对象就创建成功了,然后我们的RequestQueue请求队列就创建成功了. 通过start()方法就启动了我们的请求队列. 小结两个newRequestQueue方法使用的这种方式其实非常巧妙,以前我看到这种方式就叫他重载调用(不知道叫的对不对,哈哈). 这是我的Volley系列的第一篇,好的开始,加油↖(^ω^)↗!","link":"/2016/05/21/Android/Volley%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E7%AF%87-%E6%A1%86%E6%9E%B6%E5%85%A5%E5%8F%A3/"},{"title":"Volley学习第三篇-网络线程","text":"前文概要其实NetworkDispatcher和CacheDispatcher是很相像的.感觉看NetworkDispatcher要比CacheDispatcher要简单. 因为它不需要进行判断缓存的过期时间和新鲜时间,仅仅是执行请求,然后在缓存响应结果,所以要简单些. 流程分析 同样的继承Thread,只看run()方法里面的就好了 同样的死循环,队列无内容时阻塞 1.首先从队列中取出Request请求 request = mQueue.take(); 2.判断请求是否取消 if (request.isCanceled()) { request.finish(&quot;network-discard-cancelled&quot;); continue; } 3.请求未取消,执行网络请求并得到NetworkResponse对象 NetworkResponse networkResponse = mNetwork.performRequest(request);具体的网络请求还是需要看Network接口的实现类中是如何操作的. 4.判断服务器返回码是否是304(资源未更新) if (networkResponse.notModified &amp;&amp; request.hasHadResponseDelivered()) { request.finish(&quot;not-modified&quot;); continue; } 5.是否缓存请求的响应 if (request.shouldCache() &amp;&amp; response.cacheEntry != null) { mCache.put(request.getCacheKey(), response.cacheEntry); request.addMarker(&quot;network-cache-written&quot;); } 6.分发 mDelivery.postResponse(request, response); 小结其实看明白先前的缓存线程之后,理解网络线程也不是难事了. 明天详细解释下具体响应的转化和分发流程.","link":"/2016/05/23/Android/Volley%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E7%AF%87-%E7%BD%91%E7%BB%9C%E7%BA%BF%E7%A8%8B/"},{"title":"基础加强--框架加强","text":"新特性Static Import : 静态导入，当前类中可以直接使用静态资源（字段|方法） 格式：import static java.lang.Math.*;Varargs ：可变参数 public void demo(String... args){ 当成数组使用 }Autoboxing/Unboxing 自动装箱、自动拆箱（基本类型 &lt;–&gt; 包装类） 装箱：基本类型 --&gt; 包装类。例如：Integer i = 10; --&gt; Integer m = new Integer(10); 拆箱：包装类 --&gt; 基本类型。例如：int j = i; --&gt; int n = m.intValue();Enhanced for Loop 增强for循环 for(类型 变量 : 容器){} --&gt; 容器：数组、Iterable接口（iterator方法）Typesafe Enums 枚举 public class Hello {} public enum Color {}泛型特点 1.将运行时的问题提升到编译时 2.方法级别的泛型定义主要是用在工具类中的 public class TestGeneric2 { public void demo(){ int m = 10; String s = init(&quot;abc&quot;); Integer i = init(123); } //方法级别的定义 MyBeanUtils public &lt;T&gt; T init(T obj){ //算法 System.out.println(obj); return obj; } }泛型擦除 以下两个方法不能同时存在 public void init(List&lt;String&gt; list){} public void init(List&lt;Integer&gt; list){} 类型擦除之后，两个方法是完全相同反射中Class对象的三种获取方式: Class.forName(&quot;全限定类名&quot;); String.class obj.getClass反射和泛型混合使用的例子: public class Dao&lt;T&gt; { private Session session; private Class beanClass; public Dao() { //1 在运行时，获得当前运行类 父类中泛型的实际参数 //this.getClass().getSuperclass(); //jdk1.4之前，获得父类，不含泛型信息 // * 获得被参数化的类型 ArrayList&lt;Integer&gt; ，含有泛型信息 ParameterizedType type = (ParameterizedType) this.getClass().getGenericSuperclass(); //2 获得所有的实际参数类型。类&lt;A,B,C,D&gt; ,返回数组，获得第一个实际参数 Type firstType = type.getActualTypeArguments()[0]; this.beanClass = (Class) firstType; /* //回顾 反射 api beanClass.getName(); //类名 beanClass.getMethod(name, parameterTypes) //方法 beanClass.getConstructor(parameterTypes) //构造 beanClass.getField(name) //字段 */ System.out.println(beanClass); } /* 泛型 ，将运行时问题 提升 编译时 * 泛型实参只有在运行时才可以确定，编译时 T 不能确定类型（User | Book） 只有在运行时才可以确定 * 思想：如何在运行时获得实际类型参数？ */ public T findById(Integer id){ return (T) session.get(beanClass, id); } }注解介绍 注解就是类,用于修饰对象(类/构造/字段/方法等),常用语取代xml配置. 但是,开发中常用注解+xml混合使用JDK提供的常用注解 @Override 在jdk1.5表示子类覆写父类的方法 在jdk1.6表示子类实现父接口的方法 @Deprecated 表示被修饰对象已经过期了,过期的方法依旧可以使用. 以下情况被标记过期:1.安全问题 2.有新的API @SuppressWarnings 抑制警告,如果有警告通过编辑器不进行警告 deprecation:如果过期不警告 rawtypes:没有泛型 unused:未使用 null:空指针 serial:序列化 all:所有 建议:尽量不使用抑制自定义注解注解架构 定义注解 使用注解 解析注解基本语法 定义注解使用关键字 : `@interface` ,和定义类class相似 public @interface xxx{} 成员格式: 修饰符 返回值 属性名() [default 默认值] eg: public String username(); 注意点: 1.修饰符:默认值 public abstract,且只能是这两个 2.返回值:只能是基本类型/字符串String/Class/注解/枚举,以及以上类型的一维数组.使用注解—重点!!! 注解出现的目的就是用来代替xml的","link":"/2016/07/29/Android/%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA--%E6%A1%86%E6%9E%B6%E5%8A%A0%E5%BC%BA/"},{"title":"Docker Compose无法部署Vue项目","text":"近期在进行Vue项目自动化构建，遇到一些问题，下面记录一个典型的问题。 1. 问题出现在使用docker部署vue项目的时候，使用了multi-stage-build来构建最终镜像，然鹅在构建时却出现了如下问题： 12345678Building nginx_managerStep 1/12 : FROM node:lts-alpine as baseService 'nginx_manager' failed to build: Error parsing reference: &quot;node:lts-alpine as base&quot; \\is not a valid repository/tag: invalid reference formatSSH: EXEC: completed after 1,636 msSSH: Disconnecting configuration [tencent_server] ...ERROR: Exception when publishing, exception message [Exec exit status not zero. Status [1]]Finished: UNSTABLE 这贴一下我最原始的Dockerfile和docker-compose.yml 12345678910111213FROM node:lts-alpine as base-buildWORKDIR /appCOPY package*.json ./RUN npm installCOPY . .RUN npm run build:prod# production stageFROM nginx:stable-alpine as nginx-build# 将修改的文件替换掉容器中的nginx配置# COPY default.conf /etc/nginx/conf.d/default.confCOPY --from=base-build /app/dist /usr/share/nginx/htmlEXPOSE 80CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 1234567891011version: &quot;3&quot;services: nginx: container_name: manager build: context: ./manager dockerfile: Dockerfile ports: - 8080:80 environment: HOST: 0.0.0.0 2. 查找解决方案于是开展各种搜索，搜索到一个相关问题，推荐使用target的方式来指定具体的构建阶段 相关链接：https://stackoverflow.com/questions/53093487/multi-stage-build-in-docker-compose 修改后的docker-compose.yml 123456789101112version: &quot;3.4&quot;services: nginx_manager: container_name: manager build: context: ./manager dockerfile: Dockerfile target: nginx-build ports: - 8080:80 environment: HOST: 0.0.0.0 执行后依旧是上面的错误。。。 于是又进行了搜索，在GitHub上搜索到相关问题，原因竟然在于docker版本过低！ 相关链接：https://github.com/tootsuite/mastodon/issues/8240 GitHub上的讨论指出： 1Docker's &quot;multi stage build&quot; with keyword &quot;as&quot; is supported on Docker 17.05 or later. 查看服务器docker版本，确实是低于17.05，于是重装了docker。 123456789# 安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2# 修改为阿里云的源yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 删除原来的dockeryum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate \\ docker-logrotate docker-selinux docker-engine-selinux docker-engine# 安装docker ceyum install docker-ce 安装成功后启动docker，结果出现如下错误： 12Error response from daemon: Unknown runtime specified docker-runcError: failed to start containers: 7253e1be7fb3 真是一波未平一波又起啊，不过有解决方案： 12345678910111213[root@VM_12_255_centos ~]# cd /var/lib/docker/containers/[root@VM_12_255_centos containers]# grep -rl &quot;docker-runc&quot; ../550dc5fda621f02b5079e0d70d502c01752fef6a03f0bf3dbf533f0634fc6013/hostconfig.json./d2bc485ef863b5742c29d4e95e5de641aaf5b474657eb16c47b51bc3d679ca1a/hostconfig.json./afa79db1bd41284e99446404afee1f43f06a7381889fd90961493d83ffb31658/hostconfig.json./b405ade18866912841727c384c4eb71625d59865dc72676c39dfdde1592c8748/hostconfig.json./9c291209f3e09e5cdf6f7333873d8216be531aba940d185f12160a1ff98fdc6e/hostconfig.json./9c291209f3e09e5cdf6f7333873d8216be531aba940d185f12160a1ff98fdc6e/config.v2.json./e5a7f498b6a8501f4e625e4e8598b819577141dbb137f945356777d3c9c0c077/hostconfig.json./c58152c4ceeb6506aeca1eacf029c51e53cfc3848bc588120b51e97ee6463f74/hostconfig.json./b4b59541feb03b0f102f521da336f358be4c70f23ecdc837644e3835c024535d/hostconfig.json./b4b59541feb03b0f102f521da336f358be4c70f23ecdc837644e3835c024535d/config.v2.json[root@VM_12_255_centos containers]# sed -i &quot;s/docker-runc//g&quot; ./550dc5fda621f02b5079e0d70d502c01752fef6a03f0bf3dbf533f0634fc6013/hostconfig.json 将上面grep搜索出来的文件全都执行sed命令替换，之后正常重启即可 相关链接：https://forums.docker.com/t/after-upgrade-to-docker-ce-containers-will-not-start/40243/3 3. 总结至此，此次问题告一段落，版本兼容问题确实不容小觑啊！ Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/12/CI&CD/Docker%20Compose%E6%97%A0%E6%B3%95%E9%83%A8%E7%BD%B2Vue%E9%A1%B9%E7%9B%AE/"},{"title":"Docker教程(一)---Docker简介","text":"虚拟化技术传统虚拟化方式是虚拟机虚拟出一套硬件后,在上面运行一个完整的操作系统;而容器技术是直接使用宿主机的资源,是一种轻量级的虚拟技术. Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 这幅图比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。 虚拟机和容器的区别相同点: 均可在不同主机之间进行迁移 权限级别操作相同 不同点: 虚拟机是硬件虚拟化,容器是系统层面虚拟化 虚拟机臃肿性能有限,迁移难度较大;容器轻量占用空间小,迁移方便,性能接近原生系统 一台服务器支持虚拟机数量有限,容器却可以达到上千个 容器和虚拟机各有各的优缺点，容器也并不是虚拟机的替代品，只是二者在适应不同的需求下各有特点 Docker思想及理念 docker 封装思想和 Java 的跨平台思想非常相似 建议一个容器只部署一个应用(当然也可以部署多个) Docker应用场景 大量部署相同相似环境服务器(例如微信公众号环境) 为开发、测试提供一个轻量级的独立沙盒环境,让应用程序在不同的环境中，得到相同的运行结果 应用的自动化测试/持续集成/自动化打包/发布 高性能、超大规模的宿主机部署 欢迎大家关注 : LF工作室 简书 : https://www.jianshu.com/u/e61935d18b09 掘金 : https://juejin.im/user/59239002570c350069c5f0bb 微信公众号 :头条号 :","link":"/2017/02/19/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E4%B8%80-Docker%E7%AE%80%E4%BB%8B/"},{"title":"Simpleblog博客系统(一)---DaoCloud持续集成","text":"DaoCloud持续集成 DaoCloud提供了非常棒的CI系统,配合github完美持续集成应用部署. 操作步骤 创建项目 02创建项目 03初始界面 04流程 05安全构建 06构建准备 安全构建 08手动触发 09master分支触发 10查看日志 11执行成功 12应用-创建应用 13部署最新版本 14基本信息 15应用设置 16启动应用 欢迎大家关注😁","link":"/2018/03/21/Docker%E6%95%99%E7%A8%8B/DaoCloud%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"title":"微信支付","text":"写在前面的话 小豪从来都是一个认认真真写总结的人(●’◡’●) 微信支付 APP端开发步骤说明 Android接入指南 demo下载 第一个坑好像修改了应用签名的时候需要等着它审核。 Android集成微信支付正确姿势 引入微信的jar包 初始化注册到微信 IWXAPI msgApi = WXAPIFactory.createWXAPI(this,Constants.APP_ID, true);// 第二个参数是是否校验签名，坑！！！ msgApi.registerApp(Constants.APP_ID); 官方的什么鬼，不要理他，第三个参数记得要填true！ 解析后台传入的订单信息 就是逐个解析，但是，为什么不用Gson呢？ { &quot;appId&quot;: &quot;你的APPID&quot;, &quot;money&quot;: 4, &quot;nonceStr&quot;: &quot;d33JjYv6I8a8DmPG&quot;, &quot;partnerId&quot;: &quot;1264518301&quot;, &quot;paySign&quot;: &quot;1ADA353C0A710E144B77804F3B1A525F&quot;, &quot;prepay_id&quot;: &quot;wx2016041117561365055d7bd30985662433&quot;, &quot;timeStamp&quot;: &quot;1460368573&quot;, &quot;wxPackage&quot;: &quot;Sign=WXPay&quot; } 将订单信息传入请求，调起微信支付 PayReq request = new PayReq(); request.appId = wx.getAppId(); request.partnerId = wx.getPartnerId(); request.prepayId = wx.getPrepay_id(); request.nonceStr = wx.getNonceStr(); request.timeStamp = wx.getTimeStamp(); request.packageValue = wx.getWxPackage(); request.sign = wx.getPaySign(); //request.extData = &quot;app data&quot;; // optional msgApi.sendReq(request);// 调起微信支付 此时，你以为就可以成功调起微信支付了。 支付结果的回调 想要成功回调，还需要编写WXPayEntryActivity类(包名或类名不一致会造成无法回调) 必须放在wxapi包下，且这个包必须是在根目录下 不能放在其他包下 应该是这样的结构： 清单文件应该是这样的： &lt;activity android:name=&quot;.wxapi.WXPayEntryActivity&quot; android:exported=&quot;true&quot; android:launchMode=&quot;singleTop&quot; /&gt; 必须这样写！！！回调的Activity必须是：你的包名（微信demo里是：net.sourceforge.simcpux）+.wxapi.WXPayEntryActivity.java你就不！好，那你就别想回调成功。 我仿佛看到了这样的嘴脸 这一切文档里没有，demo里写错的！ 需要注意,如果errorCode总是为 -1请尝试通过下面方法解决： 用提交的签名的keystore文件打包 清理微信的缓存 看上面再来一遍 其他人的总结 Android常用第三方支付 移动应用微信支付集成小结 http://www.th7.cn/Program/Android/201501/351050.shtml http://www.tqcto.com/article/mobile/57931.html 最后的提醒看完这篇如果还没有成功，那你就去骂腾讯吧","link":"/2016/04/12/Android/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98/"},{"title":"Docker教程(七)---构建Tomcat镜像","text":"这次镜像构建是基于上篇的JDK镜像构建的. DockerfileFROM lujiahao/jdk1.7 MAINTAINER lujiahao ADD apache-tomcat-7.0.75.tar.gz /usr/local/ RUN mv /usr/local/apache-tomcat-7.0.75 /usr/local/tomcat7 WORKDIR /usr/local/tomcat7/bin EXPOSE 8080构建命令docker build -t=&quot;lujiahao/tomcat7&quot; .启动容器测试docker run --name tomcat7 -p 8080:8080 -d lujiahao/tomcat7 ./catalina.sh run 注意：在运行装有tomcat的容器的时候使用catalina.sh run (调试模式，在前台运行)来启动，如果使用startup.sh 的话会在后台运行，容器会认为进程down掉，容器也会自动停止。 然后在浏览器中查看能否访问tomcat主页","link":"/2017/03/07/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E4%B8%83-%E6%9E%84%E5%BB%BATomcat%E9%95%9C%E5%83%8F/"},{"title":"Docker教程(三)---容器命令","text":"Docker 容器命令交互式操作流程 运行一个容器（交互式）docker run -i -t centos /bin/bash -i 表示stdin标准输入 -t表示tty终端第一次执行docker run命令会先从远程仓库中拉取centos的镜像内部流程如下图 退出容器exit重命名容器docker rename 旧名称 新名称 另一种方法,启动时重命名 docker run --name crxy -t -i centos /bin/bash 合法的容器名称正则[a-zA-Z0-9_.-]查看容器列表docker ps [-a] [-l] [-n num]重新启动已经停止的容器docker start 容器名称/容器ID附着到一个容器上docker attach 容器名称/容器ID 使用`exit`退出容器后,重新由`docker start`命令启动了容器 此时可以使用这个命令重新进入到容器里面 可以理解为从外部进入到这个容器内部 仅仅适用于使用-it启动的容器,像下面的后台启动的是无法使用这个命令的后台长期运行 创建长期运行的容器docker run --name lujiahao -d centos /bin/bash -c &quot;while true;do echo hello world;sleep 1;done&quot;会返回该容器的长id : 55ba56913bb5666ecb352a031503b5191cc8f186558e2f22380c2adadecc7c14 我们通过docker ps获得的是这个长id的前十二位 docker run后面追加-d=true或者-d，那么容器将会运行在后台模式. 获取容器日志docker logs [--tail num] [-t] [-f] 容器名称/容器ID 旧版本的日志位置/var/lib/docker/containers/ID/ID-json.log 但是新版本的实验并没有发现这个log存在位置 -t 是来添加时间戳的 -f 持续输出查看容器内的进程docker top 容器名称/容器ID操作一个正在运行的容器在容器内部运行进程(docker1.3之后才支持) docker exec -d lujiahao touch /etc/lujiahao.txt 在后台运行的容器里面创建一个文件 docker exec -it lujiahao /bin/bash 连到一个在后台运行的容器,此时执行exit退出,后台容器还在运行停止容器docker stop 容器名称/容器ID 向容器发送停止指令,容器自己停止,建议使用 docker kill 容器名称/容器ID 直接停掉,不建议使用获取容器详细信息docker inspect [--format | -f] 容器名称/容器ID 例子：docker inspect --format=&apos;{{.State.Running}}&apos; lujiahao 容器存储位置：/var/lib/docker/containers删除容器docker rm 容器名称/容器ID正在运行中的容器是无法删除的,会出现下面的提示 Error response from daemon: You cannot remove a running container 55ba56913bb5666ecb352a031503b5191cc8f186558e2f22380c2adadecc7c14. Stop the container before attempting removal or use -f可以先停止容器,或者使用 -f 参数 批量删除正在运行中的容器docker rm `docker ps -a -q` docker ps -a -q : 这个命令用来获取所有容器的id容器的导入和导出导出：docker export 容器ID/名称 &gt; my_container.tar 导入：cat mycontainer.tar | docker import - 镜像名称:标签镜像的保存和加载(暂时还没讲到)保存：docker save 镜像ID &gt; my_image.tar 加载：docker load&lt; my_image.tar","link":"/2017/02/24/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E4%B8%89-%E5%AE%B9%E5%99%A8%E5%91%BD%E4%BB%A4/"},{"title":"Docker教程(五)---Azure虚拟安装Docker","text":"老大把Azure的权限给我了,哈哈,可惜我已经准备离职了,但是工作还是要继续的. 一切进行的非常顺利,登录Azure云平台,创建虚机,然后切换root权限安装docker,退出root用户,准备docker pull centos…无法运行,卧槽! 运行docker命令弹出如下提示: Cannot connect to the Docker daemon. Is the docker daemon running on this host?docker出于安全的考虑才会这样做(http://dockone.io/article/589). 解决方案 切换root权限 visudo -f /etc/sudoers 在 /etc/sudoers 中添加如下内容 azureuser ALL=(ALL) NOPASSWD: /usr/bin/docker 退出root用户 执行 vim ~/.bashrc 添加 alias docker=&apos;sudo /usr/bin/docker&apos; 保存后执行 source ~/.bashrc 此时就可以自由的使用docker命令了.","link":"/2017/03/06/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E4%BA%94-Azure%E8%99%9A%E6%8B%9F%E5%AE%89%E8%A3%85Docker/"},{"title":"Docker教程(二)---安装Docker","text":"Docker 核心组件镜像(Image)镜像是构建docker世界的基石,也是docker生命周期中的构建阶段. 仓库(Registry)存储用户构建的镜像以及官方的镜像,分为公有和私有.Docker公司运营的公有仓库叫做 Docker Hub 容器(Container)容器是基于镜像启动的，容器中可以运行一个或多个进程。容器是docker生命周期中的启动或执行阶段。 仓库里面存储着镜像,基于镜像可以启动容器container = image + docker run Docker工作流 安装Docker 宿主机Centos7 64位,因为 Docker 是基于64位系统构建的. 验证linux内核版本uname -a,官方建议使用3.8版本以上 检查Device Mapper(Docker的存储驱动) grep device-mapper /proc/devices 如果不存在则安装yum install -y device-mapper 加载dm_mod内核模块 modprobe dm_mod 安装 yum -y install docker(默认安装最新版) 安装指定版本 Docker 查看可安装的版本 yum makecache fast(相当于更新本地缓存) yum list docker --showduplicates 安装指定版本 yum install 2:1.12.5-14.el7.centos 验证 启动docker systemctl start docker(centos7) 添加开机启动项 systemctl enable docker(centos7) 验证docker是否正常 systemctl status docker docker info出现下面图片表示安装成功了 总结至此,Docker已经顺利安装了,下面进入到基础命令学习阶段吧! 欢迎大家关注 : LF工作室 简书 : https://www.jianshu.com/u/e61935d18b09 掘金 : https://juejin.im/user/59239002570c350069c5f0bb 微信公众号 :头条号 :","link":"/2017/02/23/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E4%BA%8C-%E5%AE%89%E8%A3%85Docker/"},{"title":"Docker教程(六)---构建JDK镜像","text":"1.创建文件夹jdk因为会把当前构建目录中的内容添加到镜像里面 所以要单独创建一个文件夹2.编写Dockerfile文件FROM centos MAINTAINER lujiahao ADD jdk-7u80-linux-x64.tar.gz /usr/local RUN mv /usr/local/jdk1.7.0_80 /usr/local/jdk1.7 ENV JAVA_HOME /usr/local/jdk1.7 ENV JRE_HOME /usr/local/jdk1.7/jre ENV CLASSPATH .:$JAVA_HOME/jre/lib/rt.jar :$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ENV PATH $JAVA_HOME/bin:$PATH3.构建镜像docker build -t=&quot;lujiahao/jdk1.7&quot; .4.构建完成之后启动一个临时性容器来测试docker run --rm -it lujiahao/jdk1.7 /bin/bash 在运行java和javac看看,java -version看版本相关资源可以到 DockerfileCollection 中寻找对应的 Dockerfile 文件","link":"/2017/03/06/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E5%85%AD-%E6%9E%84%E5%BB%BAJDK%E9%95%9C%E5%83%8F/"},{"title":"Docker教程(八)---构建Kafka镜像","text":"Kafka 该容器的前提依赖是使用我的JDK的镜像的依赖,后面我会把镜像同步到线上. 构建镜像下载好Dockerfile文件执行 docker build -t=&quot;lujiahao/kafkatest&quot; .启动容器docker run --name test_kafka -it -p 2181:2181 -p 9092:9092 lujiahao/kafkatest /bin/bash额外配置容器中使用kafka还需要将容器的内部IP配置到config/server.properties中 docker inspcet test_kafka查看容器的内部IP然后更改config目录中的server.properties中的三个配置 #容器的ip地址 host.name=172.17.0.1 #容器的ip地址 listeners=PLAINTEXT://172.17.0.1:9092 #宿主机的IP地址,用于外部Producer和Consumer使用(公司服务器你懂得) advertised.listeners=PLAINTEXT://xx.xx.xx.xx:9092启动Kafka./kafkastart.sh错误总结1.无法分配内存Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c0000000, 1073741824, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)解决方案 vi zookeeper-server-start.sh 将 export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Xms512M&quot; 改成 export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Xms128M&quot; vi kafka-server-start.sh 将 export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot; 改成 export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Xms128M&quot; 把这两个值改成相同的就行了参考资料 2.无法发送消息Error when sending message to topic TESTTOPIC with key: null, value: 9 bytes with error: Failed to update metadata after 60000 ms. (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)解决方案 在 server.properties 中添加 advertised.listeners=PLAINTEXT://xx.xx.xx.xx:9092 ,对应的IP为宿主机的IP参考资料 Kafka的基本操作 创建topic kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 查看topic kafka-topics.sh --list --zookeeper localhost:2181 生产者 kafka-console-producer.sh --broker-list localhost:9092 --topic test 消费者 kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning","link":"/2017/03/22/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E5%85%AB-%E6%9E%84%E5%BB%BAKafka%E9%95%9C%E5%83%8F/"},{"title":"Travis CI持续集成GitHub个人博客","text":"什么是Travis CI Travis CI 是目前新兴的开源持续集成构建项目，它与jenkins，GO的很明显的特别在于采用yaml格式，同时他是在在线的服务，不像jenkins需要你本地打架服务器，简洁清新独树一帜。目前大多数的github项目都已经移入到Travis CI的构建队列中，据说Travis CI每天运行超过4000次完整构建。对于做开源项目或者github的使用者，快将你的项目加入Travis CI构建队列吧! 目标使用Hexo搭建托管在Github上的个人博客,每次推送新博客到Github,Travis CI 自动构建并推送到博客项目的master分支上.由于GitPages服务规定网页文件必须在master分支上,所以博客源码内容在项目的hexo-source分支. 步骤1.TravisCI创建账户最好使用Github账户直接登录,登录后界面如下,勾选个人博客项目即可. 2.生成并配置Access Token在GitHub生成Travis CI 的token 生成之后一定要保存好，因为只会出现一次，丢失了就只能再重新生成了。 之后将生成的token配置到Travis CI中 3.创建.travis.yml配置文件在项目的hexo-source分支中,项目的根目录下创建.travis.yml配置文件 : 1234567891011121314151617181920212223242526272829language: node_jsnode_js: 6# S: Build Lifecycleinstall: - npm install#before_script: # - npm install -g gulpscript: - hexo gafter_script: - cd ./public - git init - git config user.name \"lujiahao0708\" - git config user.email \"lujiahao0708@gmail.com\" - git add . - git commit -m \"Update docs\" - git push --force --quiet \"https://${GH_TOKEN}@${GH_REF}\" master:master# E: Build LifeCyclebranches: only: - hexo-sourceenv: global: - GH_REF: github.com/lujiahao0708/lujiahao0708.github.io.git 替换git config信息为你自己的,GH_REF的值更改为你的仓库地址. 4.发布新博客将博客内容推送到hexo-source分支上,就会触发Travis CI 的自动构建. Q&amp;A1.Travis CI编译错误我参照的教程中.travis.yml配置文件的node_js版本使用`stable`,但是会出现错误. 解决方案 : 使用低版本的NodeJS版本 https://segmentfault.com/q/10100000113177832.自定义域名无法跳转CNAME文件直接放到了工程的根目录下,将无法打包进去 解决方案 : 将CNAME文件放到source目录下参考教程https://blog.csdn.net/woblog/article/details/51319364https://www.jianshu.com/p/5691815b81b6 欢迎大家关注😁","link":"/2018/06/27/Docker%E6%95%99%E7%A8%8B/Travis%20CI%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"title":"07.JavaWeb基础_Servlet笔记","text":"Servlet基础是用Java编写的服务器端程序 类关系 根据生命周期打断点 生命周期执行流程init()方法当我们首次访问HelloServlet时,会在tomcat中创建该Servlet,此时会执行init()方法,Java中方法执行是首先从当前类中找是否有此方法,如果没有的话就会往该类的父类里面找.这就到了HttpServlet方法,发现里面也没有init()方法,继续往上找.而GenericServlet中有相关的东西 public void init(ServletConfig config) throws ServletException { this.config = config; this.init(); } public void init() throws ServletException { }第一个是生命周期的方法,而下面的方法是用来被子类覆写的初始化方法,这样的写法既可以实现初始化Servlet,又可以避免子类覆写父类的方法造成父类方法无法执行的问题. service()方法service()方法和这个是类似的流程.首先会从HelloServlet中寻找service()方法,没有,进入到HttpServlet中寻找,找到 public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; try { request = (HttpServletRequest)req; response = (HttpServletResponse)res; } catch (ClassCastException var6) { throw new ServletException(&quot;non-HTTP request or response&quot;); } this.service(request, response); }这里会调用一个service()的重载方法,这个重载方法里面有执行其中操作的具体方法,以doGet()为例,虽然HttpServlet中有doGet()的实现,但是我们的HelloServlet中覆写了doGet()方法,具体的实现就看我们的覆写的方法中的操作了. destory()方法这个没啥好写的,就是销毁 Servlet总结 Servlet是单例，一生只有一个实例。 多个线程同时执行doGet方法，存在线程并发问题（安全问题）解决方案：不要使用成员变量 初始化操作：复写init() 业务操作：在doGet()和doPost() 所有的servlet都必须在web.xml配置 注意：配置当前使用的servlet（父类HttpServlet和爷类GenericServlet不要配置的）","link":"/2016/11/20/JavaWeb%E5%9F%BA%E7%A1%80/07-JavaWeb%E5%9F%BA%E7%A1%80-Servlet%E7%AC%94%E8%AE%B0/"},{"title":"10-JavaWeb基础-JSP笔记","text":"什么是JSP tomcat安装目录下的work目录就是tomcat处理jsp的工作目录 JSP是以Java语言为基础的动态网页开发技术(Servlet也是动态网页开发技术) 二者特点 servlet特点:在java代码中嵌入html代码 jsp特点:在html代码中嵌入java代码 JSP本质上就是servlet tomcat获得jsp文件后,将jsp转化成servlet,会产生xxx_jsp.java(servlet源码) D:\\java\\tomcat\\apache-tomcat-7.0.53\\work\\Catalina\\localhost\\day10\\org\\apache\\jsp\\b_005fdemo_jsp.java tomcat安装目录 引擎 主机 项目 固定包名 jsp文件对应servle tomcat将java文件编译产生class文件 tomcat运行class文件,并将结果输出到浏览器 源码分析: public final class xxx_jsp extends org.apache.jasper.runtime.HttpJspBase public abstract class HttpJspBase extends HttpServlet 注意:jsp生成java代码,默认是第一次生成,之后直接执行,除非内容修改 JSP脚本元素 表达式:&lt;%= 表达式 %&gt; 将表达式结果输出到浏览器,底层解析使用out.print(表达式); 代码片段:&lt;% java代码 %&gt; 将”java代码”完整复制到service方法体中 脚本声明:&lt;%! 声明内容 %&gt; 将”声明内容”完整复制到class类中(成员变量or成员方法) 注意:脚本不能嵌套 JSP注释JSP注释将jsp源码内容注释掉,tomcat生成java源码中将没有注释掉的内容 &lt;%-- 注释内容 --%&gt;JSP指令配置给tomcat,tomcat将jsp生成java源码(servlet)依据. 格式:`&lt;%@ 指令名称 属性=值 属性=值 ...%&gt;` 指令包括:page/include/taglibpage指令 编码[*] pageEncoding:当前页面的编码 contentType:jsp生成servlet响应给浏览器编码 注意:一般一致 对比: 如果只有pageEncoding,设置当前页面编码,也可以设置响应编码 如果只有contentType,可以设置响应编码,也可以设置当前页面编码 jsp缓存机制 buffer:设置缓存大小,默认8Kb autoFlash:缓存如果溢出,将自动刷新 如果设置为false可能异常:java.io.IOException:Error:JSP Buffer overflow jsp错误处理机制 errorPage:设置错误页面. 当前jsp页面出现异常,将显示错误界面(友好界面). isErrorPage:指定当前页面发生错误时的错误处理页,可以捕获异常信息. 思考：当页面过多时如何配置错误页面? 使用统一管理，给整个web项目配置友好页面。web.xml Element : error-page 需要使用&lt;error-page&gt;标签指定 Content Model : ((error-code | exception-type), location) &lt;error-code&gt; 错误码（状态码）：500、404等 &lt;exception-type&gt; java异常类型：java.lang.RuntimeException &lt;location&gt; 出现指定错误时，指定的显示页面 常用 session:表示当前jsp页面是否可以使用session内置对象. true:可以在jsp脚本(表达式/代码块)中使用session import:jsp使用其他类，进行导包。【】 分别导入：java.util.List 一次性导入：java.util.List,java.util.ArrayList 星号：java.util.* language :表示jsp支持嵌入语言(java) info : 使用在servlet接口第5个方法，getServletInfo() 指令的使用注意 一个指令可以编写多个属性 一个指令可以多次使用 指令可以使用在jsp页面任何位置 大部分指令只能使用一次,但是`import`可以使用多次. include指令格式:&lt;%@include file=&quot;&quot;%&gt; 分类: taglib指令具体请参看EL&amp;JSTL笔记. JSP九大内置对象[***]可以在jsp表达式脚本&lt;%= &amp;&gt;和代码片段脚本&lt;% %&gt;可以使用的变量.都在service()方法中,及service()方法提供的变量. page —–&gt; 表示当前页面.就是this引用 config —–&gt; 表示servlet配置.类型是:ServletConfig application —–&gt; 表示web应用的上下文.类型是:ServeltContext request —–&gt; 表示一次请求.类型:HttpServletRequest response —–&gt; 表示一次响应.类型:HttpServletResponse session —–&gt; 表示一次会话.类型:HttpSession out —–&gt; 表示输出响应体.类型:JspWriter exception —–&gt; 表示异常.类型:Throwable pageContext —–&gt; 表示jsp页面的上下文(jsp管理者).类型:PageContext JSP四个作用域 page —–&gt; 当前页面(一个页面) request —–&gt; 一次请求(默认就一个页面,如果使用请求转发可以多个页面) session —–&gt; 一次会话(可以有多次请求) application —–&gt; 一个应用(可以多次会话) JSP输出 输出类型:JspWriter jsp输出底层使用的是response.getWriter() private void initOut() throws IOException { if(out == null){ out = response.getWriter(); } } 下面代码输出情况: &lt;% out.print(&quot;aaa&quot;); response.getWriter().print(&quot;bbb&quot;); out.print(&quot;ccc&quot;); %&gt; 输出结果:bbbaaaccc 原理解析:jsp和servlet各自都有自己的缓存,jsp首先写入到jsp自己的缓存中(JspWriter), 然后再刷新到servlet缓存(response.getWriter();) 小知识点:如果在jsp片段中使用response.getOutputStream().print(&quot;abc&quot;);的话会报错java.lang.IllegalStateException原因是因为jsp底层使用了getWriter(),不能和getOutputStream()混合使用. JSP动作标签JSP 内置标签，可以取代 jsp脚本。 格式： &lt;jsp:标签名 /&gt; &lt;jsp:include page=&quot;&quot; /&gt; 动态包含 &lt;jsp:forward /&gt; 转发 &lt;jsp:param/&gt; 处理请求参数的 ， 可以将中文内容进行 URL编码， 类似 &lt;form enctype=&quot;application/x-www-form-urlencoded&quot;&gt; &lt;jsp:include page=&quot;/error.jsp&quot;&gt; &lt;jsp:param value=&quot;屌丝&quot; name=&quot;username&quot;/&gt; &lt;/jsp:include&gt; &lt;jsp:useBean id=&quot;user&quot; class=&quot;com.itheima.User&quot;&gt;&lt;/jsp:useBean&gt; &lt;%-- User user = new User(); pageContext.setAttribute(&quot;user&quot;,user)--%&gt; &lt;jsp:setProperty property=&quot;username&quot; name=&quot;user&quot; value=&quot;jack&quot;/&gt; &lt;%-- user.setUsername(&quot;jack&quot;) --%&gt; &lt;jsp:getProperty property=&quot;username&quot; name=&quot;user&quot;/&gt; &lt;%-- user.getUsername() --%&gt;JavaBean属性public class User{ private String id2;// 字段(Field) public String getId(){ return id2; } public void setId(String id){ this.id2 = id; } // javabean属性(property) --&gt; 由setter或getter方法获得 --&gt; setId --&gt; Id --&gt; id // 这个bean的属性叫id }用户登录案例// 登录处理 if (userLogin != null) { // 登录成功 session保存用户信息 重定向到成功界面 request.getSession().setAttribute(&quot;userLogin&quot;,userLogin); // 重定向 String url = request.getContextPath() + &quot;/login_success.jsp&quot;; response.sendRedirect(url); } else { // 登录失败 request设置错误,请求转发,在登录页面显示提示信息 // request作用域保存错误信息 request.setAttribute(&quot;msg&quot;,&quot;用户名和密码不匹配&quot;); request.setAttribute(&quot;username&quot;,username); // 使用请求转发(一次请求涉及到多个页面) request.getRequestDispatcher(&quot;/login.jsp&quot;).forward(request,response); }","link":"/2016/12/05/JavaWeb%E5%9F%BA%E7%A1%80/10-JavaWeb%E5%9F%BA%E7%A1%80-JSP%E7%AC%94%E8%AE%B0/"},{"title":"Hibernate笔记一","text":"Hibernate介绍Hibernate是轻量级JavaEE应用的持久层解决方案，是一个关系数据库ORM框架.Hibernate的持久化方案，将用户从原始的JDBC底层SQL访问中解放出来,用户无须关注底层数据库操作，只要通过操作映射到数据表的Java对象，就可以对数据库进行增删改查 ORM (Object Relational Mapping对象关系映射) ORM 就是通过将Java对象映射到数据库表，通过操作Java对象，就可以完成对数据表的操作 流行数据库框架 1. JPA(Java Persistence API) : 通过注解描述对象与数据表映射关系 （只有接口规范） 2. Hibernate : 最流行ORM框架，通过对象-关系映射配置，可以完全脱离底层SQL ， Hibernate实现JPA规范 3. MyBatis : 本是apache的一个开源项目 iBatis，支持普通 SQL查询，存储过程和高级映射的优秀持久层框架 （企业主流） * MyBaits 并不是完全ORM ， 需要在xml中配置SQL语句 4. Apache DBUtils(超链接到DBUtils那节笔记里面去) 5. Spring JDBCTemplate SQL语句封装程度 Hibernate &gt; MyBatis &gt; Apache DBUtils 、Spring JDBCTemplateHibernate中的ORM实现数据库中的表与java中的类对应表中的记录是与类中的对象对应表中的字段是与类中的属性对应 Hibernate体系结构 Hibernate目录结构 Hibernate使用1.导入jar包导包的内容参见上一步,目录结构中导入即可 特别介绍: log4j(链接上log4j的单独的笔记内容) 2.编写类和关系映射配置xx.hbm.xmlpublic class Customer { private int id; private String name; private int age; private String city; ... }hibernate 完全ORM，只需要操作Customer类对象， 自动生成SQL 操作customer 表但是需要为实体类和数据表进行关系映射配置 1.在实体类所在的包下创建名为:类名.hbm.xml文件,eg:Customer.hbm.xml 2.配置规则参见 hibernate3.jar org/hibernate/hibernate-mapping-3.0.dtd 配置属性到列映射时，指定类型，类型有三种写法 第一种 java类型 java.lang.String 第二种 hibernate类型 string 第三种 SQL类型 varchar(20) 3.配置核心配置文件hibernate.cfg.xmlHibernate框架支持两种 Hibernate属性配置方式 1.hibernate.properties 采用properties方式，必须手动编程加载 hbm文件或者 持久化类 2.hibernate.cfg.xml 采用XML配置方式，可以通过配置添加hbm文件 规则参见 hibernate3.jar /org/hibernate/hibernate-configuration-3.0.dtd &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&gt; &lt;hibernate-configuration&gt; &lt;!-- 会话连接工厂，建立数据库连接需要SessionFactory --&gt; &lt;session-factory&gt; &lt;!-- JDBC连接基本参数 --&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:mysql:///hibernatetest&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;1234&lt;/property&gt; &lt;!-- 配置数据库方言，便于生成一些与数据库相关SQL方言 --&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5Dialect&lt;/property&gt; &lt;!-- DDL策略 可以根据需要自动创建数据表 --&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; &lt;!-- 将SQL语句 输出到控制台 --&gt; &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 导入映射的po类的xx.hbm.xml映射文件--&gt; &lt;mapping resource=&quot;cn/itcast/domain/Customer.hbm.xml&quot;&gt;&lt;/mapping&gt; &lt;/session-factory&gt; &lt;/hibernate-configuration&gt;注意: 配置文件必须放在根目录下 通常采用方式2来配置 编程操作使用Hibernate框架web层的javabean叫vo viewobject service层 bo business object dao层 po 持久化对象po类需要有个无参构造,get/set方法,私有化属性,属性使用包装类型,不要用基本类型,类不能为final(因为要为他生成代理),还需要有一个与表中主键映射的字段 hbm映射介绍 pojo是个啥? 视频两分钟的时候介绍了下","link":"/2016/08/08/JavaWeb%E5%9F%BA%E7%A1%80/Hibernate%E7%AC%94%E8%AE%B0%E4%B8%80/"},{"title":"MySQL笔记-SQL语句分类","text":"SQL语句可以分为以下四类 : 数据操作语言(DML) , 数据定义语言(DDL) , 数据控制语言(DCL) , 事务控制语言(TCL). 数据定义语言(DDL : Data Definition Language)用于定义SQL模式,基本表,视图和索引的创建和撤消操作.主要包含CREATE , ALTER , DROP , TRUNCATE , COMMENT , REPLACE(RENAME)等语句,一般不需要commit等事务操作. 数据操作语言(DML : Data Manipulation Language)由数据库管理系统(DBMS) 提供,用于让用户或程序员使用，实现对数据库中数据的操作.主要包含SELECT , INSERT , UPDATE , DELETE , MERGE , CALL , EXPLAIN PLAN , LOCK TABLE等语句. 数据控制语言(DCL：Data Control Language)授权用户或用户组操作和访问数据的权限.主要包含GRANT , REVOKE等语句. 事务控制语言(TCL：Transaction Control Language)用于数据库的事务管理,确保被DML语句影响的表的所有行及时得以更新.主要包含SAVEPOINT , SET TRANSACTION , BEGIN TRANSACTION , COMMIT , ROLLBACK等语句。 非官方分法##数据查询语言(DQL : Data Queries Language)用以从表中获得数据.主要包含SELECT , WHERE , GROUP BY , HAVING和ORDER BY.","link":"/2017/05/23/JavaWeb%E5%9F%BA%E7%A1%80/MySQL%E7%AC%94%E8%AE%B0-SQL%E8%AF%AD%E5%8F%A5%E5%88%86%E7%B1%BB/"},{"title":"Listener-监听器","text":"TODO:这一部分不太明白,需要后面在好好看看吧","link":"/2016/07/26/JavaWeb%E5%9F%BA%E7%A1%80/Listener-%E7%9B%91%E5%90%AC%E5%99%A8/"},{"title":"IntellJ创建Web项目","text":"照着他们的教程就行了 http://blog.csdn.net/guyue35/article/details/50551305 http://blog.csdn.net/wo541075754/article/details/46348135 其实第一个教程比价好","link":"/2016/06/22/JavaWeb%E5%9F%BA%E7%A1%80/IntellJ%E5%88%9B%E5%BB%BAWeb%E9%A1%B9%E7%9B%AE/"},{"title":"MVC介绍&amp;用户管理系统","text":"MVCMVC基本定义一种软件设计模式，B/S架构都支持。例如：java、.net、php等思想：业务逻辑处理与数据显示相分离。 Model：模型，用于封装数据 View：视图，用于显示数据 Controller：控制器，用于控制正常执行。 Web项目分包结构 面向接口编程 用户管理系统功能分析 注册 登录 查询所有用户 查询详情 修改用户 删除用户 技术分析 MVC三层架构 xml/dom4j servlet/jsp/javabean 导入需要的jar包解析xml需要 包结构com.lujiahao.web.servlet web层 com.lujiahao.service service层 com.lujiahao.dao dao层 com.lujiahao.domain javabean com.lujiahao.utils 工具包数据库暂定使用xml xml内容: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;users&gt; &lt;user id=&quot;u001&quot;&gt; &lt;username&gt;jack&lt;/username&gt; &lt;password&gt;1234&lt;/password&gt; &lt;gender&gt;男&lt;/gender&gt; &lt;age&gt;18&lt;/age&gt; &lt;/user&gt; &lt;/users&gt;JavaBean数据库定义完成之后就开始编写JavaBean dao层实现随便写点数据的增删改查功能 数据校验表单校验Bean - UserFormBean一般都是写在和servlet同级的包里面这种类型的bean里面所有的字段都是字符串用于获得浏览器发送的数据,并对数据的有效性进行校验 提供校验validate() 记录每一项的校验结果 具体代码实现: public class UserFormBean { private String id; private String username; private String password; private String repassword; private String gender; private String age;// 因为服务器传过来的数据都是string类型的 public UserFormBean() {} public UserFormBean(String id, String username, String password, String repassword, String gender, String age) { this.id = id; this.username = username; this.password = password; this.repassword = repassword; this.gender = gender; this.age = age; } public String getId() { return id; } public void setId(String id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public String getRepassword() { return repassword; } public void setRepassword(String repassword) { this.repassword = repassword; } public String getGender() { return gender; } public void setGender(String gender) { this.gender = gender; } public String getAge() { return age; } public void setAge(String age) { this.age = age; } // 记录错误信息 key:对应字段 value:提示信息 private Map&lt;String,String&gt; errorMsg = new HashMap&lt;&gt;(); /** * 校验方法 */ public boolean validate() { boolean temp = true; // 用户名不能为空 if (username == null || &quot;&quot;.equals(username)) { errorMsg.put(&quot;usernameMsg&quot;,&quot;用户名不能为空&quot;); temp = false; } if (password == null || &quot;&quot;.equals(password)) { errorMsg.put(&quot;passwordMsg&quot;,&quot;密码不能为空&quot;); temp = false; } else if (! password.equals(repassword)){ errorMsg.put(&quot;repasswordMsg&quot;,&quot;确认密码和密码不一致&quot;); temp = false; } return temp; } public Map&lt;String, String&gt; getErrorMsg() { return errorMsg; } }使用接口三层结构每一层都应该是有接口和具体的实现类 使用Intellj重构代码 BeanUtils 通过封装的类来简化参数的自动封装使用了反射和内省 初始代码: // 1.获取请求参数 String id = request.getParameter(&quot;id&quot;); String username = request.getParameter(&quot;username&quot;); String password = request.getParameter(&quot;password&quot;); String repassword = request.getParameter(&quot;repassword&quot;); String gender = request.getParameter(&quot;gender&quot;); String age = request.getParameter(&quot;age&quot;); /** * 数据校验 */ UserFormBean userFormBean = new UserFormBean(id,username,password,repassword,gender,age);封装后的代码: UserFormBean userFormBean = MyBeanUtils.populate(UserFormBean.class,request.getParameterMap());BeanUtils详细代码: public class MyBeanUtils { /** * 创建JavaBean实例,并自动将对应的参数进行封装 * @param beanClass * @param parameterMap * @param &lt;T&gt; * @return */ public static &lt;T&gt; T populate(Class&lt;T&gt; beanClass, Map&lt;String,String[]&gt; parameterMap){ try { // 1.使用反射创建javabean实例 T bean = beanClass.newInstance(); // 2.获得javabean属性(property username--&gt;setUsername()--&gt;执行set方法,数据来自map // 2.1获得所有属性--使用内省(java.beans.Introspector):jdk提供工具类,用于操作javabean // BeanInfo jdk提供用于对javabean进行描述(封装)对象 BeanInfo beanInfo = Introspector.getBeanInfo(beanClass, Object.class); // 2.2 获得所有的属性描述对象 PropertyDescriptor[] allPd = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor pd : allPd) { // 2.3 获得属性名称 String propName = pd.getName(); // 2.4 获得表单中对应的数据 String[] allValue = parameterMap.get(propName); if (allValue == null) { continue;// 当没有值的时候就跳过这个字段 } String propValue = allValue[0]; // 2.5 如果有值,将执行set方法 if (propValue != null &amp;&amp; !&quot;&quot;.equals(propValue)) { Method writeMethod = pd.getWriteMethod();// 相当于set方法 getReadMethod--相当于get方法 if (writeMethod != null) { writeMethod.invoke(bean,propValue); } } } return bean; } catch (Exception e){ throw new RuntimeException(e); } } }","link":"/2016/06/24/JavaWeb%E5%9F%BA%E7%A1%80/MVC%E4%BB%8B%E7%BB%8D&%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/"},{"title":"emall商城-SSO单点登录","text":"1. 前期准备 准备一台Redis服务器 添加host127.0.0.1 sso.emall.com 搭建emall-sso工程并整合响应的框架 2. 实现原理 单点登录的场景随处可见,此功能极大的简化了用户在网站间的重复登录,使得用户体验更加良好.本教程单点登录的实现原理:用户根据用户名和密码登录,成功后服务器返回token信息,并将token信息写入Redis和Cookie中,用户再次登录时,首先判断Cookie中是否有token信息,如果有则根据token去后台换取用户信息;否则提示用户重新登录. 3. 实现步骤3.1 登录接口/** * 用户登录 */ @Override public CommonResult userLogin(UserDTO userDTO, HttpServletRequest request, HttpServletResponse response) { String username = userDTO.getUsername(); String password = userDTO.getPassword(); TbUserExample example = new TbUserExample(); TbUserExample.Criteria criteria = example.createCriteria(); criteria.andUsernameEqualTo(username); List&lt;TbUser&gt; list = tbUserMapper.selectByExample(example); // 如果没有此用户名 没用用户名也返回这个信息是因为防止猜测用户名 if (list == null || list.size() == 0) { return CommonResult.build(400, &quot;用户名或密码错误&quot;); } TbUser tbUser = list.get(0); // 对比密码 if (!DigestUtils.md5DigestAsHex(password.getBytes()).equals(tbUser.getPassword())) { return CommonResult.build(400, &quot;用户名或密码错误&quot;); } // 生成token String token = UUID.randomUUID().toString(); // 保存用户信息前先把密码清除,为了安全起见 tbUser.setPassword(null); // 用户信息存入Redis saveUserInfoToRedis(tbUser, token); // 添加写cookie的逻辑 cookie有效期是关闭浏览器失效 CookieUtils.setCookie(request, response, COOKIE_TOKEN, token); return CommonResult.ok(token); }3.2 根据token查询用户信息/** * 根据token查询用户信息 */ @Override public CommonResult getUserByToken(String token) { // 根据token从redis中查询用户信息 String json = jedisClientDao.get(REDIS_USER_SESSION_KEY + &quot;:&quot; + token); if (StringUtils.isBlank(json)) { return CommonResult.build(400, &quot;此Session已经过期,请重新登录&quot;); } // 更新过期时间 jedisClientDao.expire(REDIS_USER_SESSION_KEY + &quot;:&quot; + token, SSO_SESSION_EXPIRE); // 返回用户信息 return CommonResult.ok(JsonUtils.jsonToPojo(json, TbUser.class)); }4. 跨域4.1 JSONPJSONP的实现与 ajax 没有任何关系，JSONP是通过script的src实现的，最终都是向服务器发送请求数据然后回调，而且方便起见，jquery把 JSONP 封装在了 $.ajax 方法中，调用方式与 ajax 调用方式略有区别。JSONP本质是:动态创建script标签，然后通过他的src属性发送跨域请求. /** * 通过token查询用户信息 * * @param token * @return */ @RequestMapping(value = &quot;/token/{token}&quot;) @ResponseBody public Object getUserByToken(@PathVariable String token, String callback) { CommonResult result = null; try { result = userService.getUserByToken(token); } catch (Exception e) { e.printStackTrace(); result = CommonResult.build(500, ExceptionUtil.getStackTrace(e)); } // 判断是否为jsonp调用 if (StringUtils.isBlank(callback)) { // 不是jsonp调用 return result; } else { MappingJacksonValue mappingJacksonValue = new MappingJacksonValue(result); mappingJacksonValue.setJsonpFunction(callback); return mappingJacksonValue; } }4.2 CORS此种方式后端实现有两种方式: 让所有的controller类继承自定义的BaseController类，改类中将对返回的头部做些特殊处理; 通过filter实现所有的请求封装跨域.4.2.1 继承BaseControllerpublic abstract class BaseController { /** * description:send the ajax response back to the client side * @param responseObj * @param response */ protected void writeAjaxJSONResponse(Object responseObj, HttpServletResponse response) { response.setCharacterEncoding(&quot;UTF-8&quot;); response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache, no-store, must-revalidate&quot;); // HTTP 1.1 response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;); // HTTP 1.0 /** * for ajax-cross-domain request TODO get the ip address from * configration(ajax-cross-domain.properties) */ response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.setDateHeader(&quot;Expires&quot;, 0); // Proxies. PrintWriter writer = getWriter(response); writeAjaxJSONResponse(responseObj, writer); } /** * * @param response * @return */ protected PrintWriter getWriter(HttpServletResponse response) { if(null == response){ return null; } PrintWriter writer = null; try { writer = response.getWriter(); } catch (IOException e) { logger.error(&quot;unknow exception&quot;, e); } return writer; } /** * description:send the ajax response back to the client side. * * @param responseObj * @param writer * @param writer */ protected void writeAjaxJSONResponse(Object responseObj, PrintWriter writer) { if (writer == null || responseObj == null) { return; } try { writer.write(JSON.toJSONString(responseObj,SerializerFeature.DisableCircularReferenceDetect)); } finally { writer.flush(); writer.close(); } } }4.2.2 Filter实现/** * @author lujiahao * @version 1.0 * @date 2017-10-15 22:20 */ public class HeadersCORSFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletResponse response = (HttpServletResponse) servletResponse; response.setHeader(&quot;Access-Control-Allow-Origin&quot;,&quot;*&quot;); filterChain.doFilter(servletRequest, response); } @Override public void destroy() { } }web.xml中配置: &lt;!-- Ajax Access-Control-Allow-Origin 跨域 拦截器解决方案 --&gt; &lt;filter&gt; &lt;filter-name&gt;ACAOFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.lujiahao.sso.filter.HeadersCORSFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ACAOFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;5. 代码详见emall-sso6. 实现效果 7. 说明emall商城系列是整合[淘淘商城]和[慕课网Java从零到企业级电商项目实战]的系列,这两部教程来自互联网.","link":"/2017/10/18/JavaWeb%E5%9F%BA%E7%A1%80/emall%E5%95%86%E5%9F%8E-SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/"},{"title":"Mac iTerm2 配置 rz&#x2F;sz 上传下载功能","text":"使用mac的同学要进行远程服务器文件的上传下载，推荐使用 sz 和 rz 命令，下文为iTerm2配置的方法。 1. 安装lrzsz1brew install lrzsz 2. 下载脚本https://github.com/mmastrac/iterm2-zmodem 3. 复制脚本将脚本iterm2-send-zmodem.sh和iterm2-recv-zmodem.sh复制到/usr/local/bin/目录中即可 1cp iterm2-recv-zmodem.sh iterm2-send-zmodem.sh /usr/local/bin/ 4. 配置 iTerm2打开 iTerm2,按⌘+,打开Perfences，选择Profiles标签页，在Profiles标签页下选择Advanced标签页，编辑Triggers Regular expression: rz waiting to receive.\\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Instant: checked Regular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh Instant: checked图示 : 5. 远程服务器安装lrzszCentOS安装方法 : yum -y install lrzsz 6. 使用方法 本地上传文件到远程服务器 登录到远程服务器，在远端服务器上输入 rz ，回车 弹框中选择本地要上传的文件 确定后等待上传完成 远程服务器下载文件到本地 在远程服务器输入 sz filename filename1 ... filenameN 弹框中选择本地的存储目录 确定后等待下载完成 至此，我们就可以使用这项黑科技了！ Tips本文同步发表在公众号，欢迎大家关注！😁 各位大佬点点广告，万分感谢！！！","link":"/2019/01/31/JavaWeb%E5%9F%BA%E7%A1%80/mac-iterm2-%E9%85%8D%E7%BD%AE%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E5%8A%9F%E8%83%BD/"},{"title":"分页","text":"实现思路 分页语法select ..... limit 参数1,参数2; 参数1 ，表示开始索引，从0开始。startIndex ，算法 (pageNum - 1) * pageSize 参数2 ，表示每页显示个数。pageSizeServlet的写法/** * 查询所有--分页查询 */ private void findAllWithPage(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException{ try { // 1.获得数据并封装 // 获得当前页码 String pageNumStr = request.getParameter(&quot;pageNum&quot;); int pageNum = 1; try { // 这种处理方式可以防止在地址栏里面输入非数字导致转化异常 pageNum = Integer.parseInt(pageNumStr); } catch (Exception e){ } // * 每页显示个数(固定值) int pageSize = 5; // 2.通知service查询所有 CustomerServeice customerServeice = new CustomerServiceImpl(); PageBean&lt;Customer&gt; pageBean = customerServeice.findAllCustomerWithPage(pageNum, pageSize); // 3.显示 // 存放到request作用域中--每一次查询都是新的数据 request.setAttribute(&quot;pageBean&quot;,pageBean); // servlet到jsp中显示,一次请求需要使用请求转发 request.getRequestDispatcher(&quot;/pages/show_all_page.jsp&quot;).forward(request,response); } catch (Exception e){ // 1.打印日志 e.printStackTrace(); // 2.请求转发到消息界面 request.setAttribute(&quot;msg&quot;,&quot;查询失败,请稍后重试.&quot;); request.getRequestDispatcher(&quot;/pages/message.jsp&quot;).forward(request,response); } }Service写法@Override public PageBean&lt;Customer&gt; findAllCustomerWithPage(int pageNum, int pageSize) { // 一般分页的逻辑是要在service里面来写 // 创建PageBean封装分页所有的数据,并将封装后的数据返回 // 1.查询总记录数 int totalRecord = customerDao.getTotalRecord(); // 2.创建PageBean PageBean&lt;Customer&gt; pageBean = new PageBean&lt;&gt;(pageNum,pageSize,totalRecord); // 3.查询结果 List&lt;Customer&gt; data = customerDao.findAll(pageBean.getStartIndex(), pageBean.getPageSize()); pageBean.setData(data); return pageBean; }Dao写法@Override public List&lt;Customer&gt; findAll(int startIndex, int pageSize) { try { String sql = &quot;select * from t_customer limit ?,?&quot;; Object[] params = {startIndex,pageSize}; return runner.query(sql,new BeanListHandler&lt;Customer&gt;(Customer.class),params); } catch (Exception e){ throw new DaoException(e); } }JSP界面当前${pageBean.pageNum}页,共${pageBean.totalPage}页,总条数${pageBean.totalRecord}条&lt;br/&gt; &lt;c:url value=&quot;${pageContext.request.contextPath}/CustomerServlet&quot; var=&quot;baseUrl&quot;&gt; &lt;c:param name=&quot;method&quot; value=&quot;findAllWithPage&quot;&gt;&lt;/c:param&gt; &lt;c:param name=&quot;pageNum&quot; value=&quot;&quot;&gt;&lt;/c:param&gt; &lt;/c:url&gt; &lt;c:if test=&quot;${pageBean.pageNum &gt; 1}&quot;&gt; &lt;a href=&quot;${baseUrl}1&quot;&gt;首页&lt;/a&gt; &lt;a href=&quot;${baseUrl}${pageBean.pageNum-1}&quot;&gt;上一页&lt;/a&gt; &lt;/c:if&gt; &lt;c:forEach begin=&quot;${pageBean.start}&quot; end=&quot;${pageBean.end}&quot; var=&quot;num&quot;&gt; &lt;a href=&quot;${baseUrl}${num}&quot;&gt;${num}&lt;/a&gt; &lt;/c:forEach&gt; &lt;c:if test=&quot;${pageBean.pageNum &lt; pageBean.totalPage}&quot;&gt; &lt;a href=&quot;${baseUrl}${pageBean.pageNum+1}&quot;&gt;下一页&lt;/a&gt; &lt;a href=&quot;${baseUrl}${pageBean.totalPage}&quot;&gt;尾页&lt;/a&gt; &lt;/c:if&gt;PageBean的封装/** * 分页的封装类 * 封装的两种思路: * -- 集合Map(Android中常见的请求参数的封装) * -- 自定义JavaBean对象 * Created by lujiahao on 2016/7/25. */ public class PageBean&lt;T&gt; { // 分页必备选项,为下面计算提供数据 private int pageNum; // 当前页(第几页) private int pageSize; // 每页显示个数 private int totalRecord; // 总记录数(总条数)---这个数据需要通过查询来获得 // 通过计算获得的数据 private int startIndex; // 分页开始的索引 private int totalPage; // 总分页数 // 分页查询的结果 private List&lt;T&gt; data; // 查询分页的数据--使用泛型的目的是为了方便复用 // 导航条动态显示 首页 上一页 1 2 3 4 下一页 尾页 private int start; // 循环开始 private int end; // 循环结束 public PageBean(int pageNum, int pageSize, int totalRecord) { // 构造方法中初始化三个必备选项 this.pageNum = pageNum; this.pageSize = pageSize; this.totalRecord = totalRecord; // 处理地址栏输入负页数 if (this.pageNum &lt; 1) { this.pageNum = 1; } // 计算分页开始的索引:(当前页 - 1) * 每页显示个数 this.startIndex = (this.pageNum - 1) * this.pageSize; // 计算总分页数 if (this.totalRecord % this.pageSize == 0){ // 能整除,总分页数 = 总记录数 / 每页显示个数 this.totalPage = this.totalRecord / this.pageSize; } else { // 不能整除,需要加一页用来存不够一页的数据 this.totalPage = this.totalRecord / this.pageSize + 1; } // 上面的快捷算法---暂时理解不了啊 //this.totalPage = (this.totalRecord + (this.pageSize - 1)) / this.pageSize; // 导航条动态显示 默认显示10页 this.start = 1; this.end = 10; // 总页数不够10页 if (this.totalPage &lt;= 10){ this.end = this.totalPage; } else { // 总页数大于10页 // 页数要求 前五后四 this.start = this.pageNum -5; this.end = this.pageNum +4; // 当pageNum=1时,其实页数至少是1 if (this.start &lt; 1){ this.start = 1; this.end = 10; } // 当pageNum到最后一页事 if (this.end &gt; this.totalPage){ this.end = this.totalPage; this.start = this.totalPage -9; // 9 = 5 + 4 } } } ...get/set }注意点容错的处理非常巧妙:这是在Servlet中的处理方式 String pageNumStr = request.getParameter(&quot;pageNum&quot;); int pageNum = 1; try { // 这种处理方式可以防止在地址栏里面输入非数字导致转化异常 pageNum = Integer.parseInt(pageNumStr); } catch (Exception e){ }这是在PageBean中的处理方式 // 处理地址栏输入负页数 if (this.pageNum &lt; 1) { this.pageNum = 1; }","link":"/2016/07/25/JavaWeb%E5%9F%BA%E7%A1%80/%E5%88%86%E9%A1%B5/"},{"title":"日志规范(一)","text":"日志规范(一) 记录在首约的工作中遇到的日志需要规范的地方,感谢鑫哥教我这么多规范. 1. 全局查找标识完整的日志是可以通过日志看到整个代码的流程.这就需要一个全局查找的标识,当我们根据这个标识搜索日志时,可以将代码执行的流程梳理出来,由此可以快速定位出问题,及时修复bug. eg : 最常见的就是订单号之类 1LOGGER.info(\"根据订单号查询优惠券id orderNo:{} response:{}\", orderNo, response); 2. Http请求 调用Http请求时将调用的url和参数输出出来,这样可以避免由于接口或参数配置错误导致无法联调成功. 同时接口的返回值也要打输出出来,这样可以避免接口返回值格式错误导致的异常. 调用接口的响应时间也要输出,调用接口的响应时间大大影响了自身接口的性能,因此输出接口响应时间是非常必要的. 1234567891011121314151617181920212223242526272829303132public void cancelOrderFee(Order order) { long startTime = System.currentTimeMillis(); String orderNo = order.getOrderNo(); try { Map&lt;String, Object&gt; paramMap = new HashMap&lt;&gt;(); paramMap.put(\"customerId\", order.getBookingUserId()); paramMap.put(\"phone\", order.getBookingUserPhone()); paramMap.put(\"orderNo\", orderNo); LOGGER.info(\"退还指定司机费 orderNo:{} url:{} param:{}\", orderNo, REFUND_CANCELORDER_FEE_URL, paramMap); String response = HttpUtil.getIntance().post(REFUND_CANCELORDER_FEE_URL, paramMap); LOGGER.info(\"退还指定司机费 orderNo:{} 接口响应:{}\", orderNo, response); if (StringUtils.isNotBlank(response)) { ResponseResult responseResult = JsonUtils.fromJson(response, ResponseResult.class); if (ResponseResult.SUCCESS_CODE == responseResult.getCode()) { int data = (int) responseResult.getData(); if (0 == data) { LOGGER.info(\"退还指定司机费[成功] orderNo:{}\", orderNo); } else { LOGGER.error(\"退还指定司机费[失败] orderNo:{} 失败原因:{}\", orderNo, responseResult.getMsg()); } } else { LOGGER.error(\"退还指定司机费[失败] orderNo:{} 接口调用失败 失败原因:{}\", orderNo, responseResult.getMsg()); } } else { LOGGER.error(\"退还指定司机费[失败] orderNo:{} 接口返回值错误 response:{}\", orderNo, response); } } catch (Exception e) { LOGGER.error(\"退还指定司机费[异常] orderNo:{} 异常信息:\", orderNo, e); } finally { LOGGER.info(\"退还指定司机费 orderNo:{} 接口耗时:{}ms\", orderNo, System.currentTimeMillis() - startTime); }} 3. 查询结果数组或集合输出个数1234567891011121314151617List&lt;OrderTasks&gt; unArrivedOrders = orderTaskService.getUnArrivedOrders();if (unArrivedOrders != null &amp;&amp; unArrivedOrders.size() &gt; 0) { LOGGER.info(\"定时任务-订单自动取消逻辑 listSize:\" + unArrivedOrders.size() + \" threadId:\" + threadId); for (OrderTasks orderTasks : unArrivedOrders) { try { CarFactOrderMongo order = carFactOrderSlaveMapper.selectVOByOrderNo(orderTasks.getOrderNo()); if (order != null &amp;&amp; StringUtils.isNotBlank(order.getRiderPhone()) &amp;&amp; orderTaskService.validCityAndServiceType(order)) { LOGGER.info(\"定时任务-订单自动取消逻辑-将要执行取消 orderNo:\" + order.getOrderNo() + \" threadId:\" + threadId); orderTaskService.cancelOrder(order, orderTasks.getNotArraiveCancelPeriod()); } else { LOGGER.info(\"定时任务-订单自动取消逻辑-条件不满足 orderNo:\" + order.getOrderNo()); } } catch (Exception e) { LOGGER.error(\"定时任务-订单自动取消逻辑-异常 orderNo:\" + orderTasks.getOrderNo() + \" threadId:\" + threadId, e); } }} 4. 定时任务需要打印线程Id12long threadId = Thread.currentThread().getId();LOGGER.info(\"定时任务-订单自动取消逻辑-job start threadId:{}\", threadId);","link":"/2017/11/14/JavaWeb%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%BF%97%E8%A7%84%E8%8C%83-%E4%B8%80/"},{"title":"emall商城-面向接口编程实践","text":"1. 面向接口编程在一个面向对象的系统中，系统的各种功能是由许许多多的不同对象协作完成的。在这种情况下， 各个对象内部是如何实现自己的,对系统设计人员来讲就不那么重要了；而各个对象之间的协作关 系则成为系统设计的关键。小到不同类之间的通信，大到各模块之间的交互，在系统设计之初都 是要着重考虑的，这也是系统设计的主要工作内容。面向接口编程就是指按照这种思想来编程。上述内容来自百度百科(说实话我没看懂). 2. 需求emall商城中有用户登录后需要将用户的token信息在服务端保存一份,实现这个功能有两个思路: Redis Guava的LoadingCache 此处就需要将存储token的这一逻辑抽象成接口,两种方式分别实现此接口,从而达到业务逻辑与底层实现分离. 3. 实现3.1 抽象ILocalCache接口1234567891011121314151617181920212223242526272829/** * 本地缓存 * @author lujiahao * @version 1.0 * @date 2017-10-20 17:24 */public interface ILocalCache&lt;T&gt; { /** * 设置缓存 * @param key * @param value * @return */ boolean setCache(String key, T value); /** * 删除缓存 * @param key * @return */ boolean cleanCache(String key); /** * 获取缓存 * @param key * @return */ Object getCache(String key);} 3.2 Redis实现方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Redis实现缓存 * @author lujiahao * @version 1.0 * @date 2017-10-20 17:33 */public class RedisCacheImpl&lt;T&gt; implements ILocalCache&lt;T&gt; { public static final Logger LOGGER = LoggerFactory.getLogger(RedisCacheImpl.class); @Autowired private JedisClientDao jedisClientDao; @Override public boolean setCache(String key, T value) { // 把用户信息写入redis jedisClientDao.set(Const.CACHE_TOKEN + \":\" + key, JsonUtils.objectToJson(value)); // 设置session过期时间 jedisClientDao.expire(Const.CACHE_TOKEN + \":\" + key, Const.CACHE_TOKEN_EXPIRE); return true; } @Override public boolean cleanCache(String key) { try { // 根据token从redis中查询用户信息 String json = jedisClientDao.get(Const.CACHE_TOKEN + \":\" + key); if (StringUtils.isNoneBlank(json)) { // 更新过期时间--清除key jedisClientDao.expire(Const.CACHE_TOKEN + \":\" + key, 0); } return true; } catch (Exception e) { return false; } } @Override public Object getCache(String key) { try { // 根据token从redis中查询用户信息 String json = jedisClientDao.get(Const.CACHE_TOKEN + \":\" + key); if (StringUtils.isBlank(json)) { return ServerResponse.build(400, \"此Session已经过期,请重新登录\"); } // 更新过期时间 jedisClientDao.expire(Const.CACHE_TOKEN + \":\" + key, Const.CACHE_TOKEN_EXPIRE); // 返回用户信息 EmallUser emallUser = JsonUtils.jsonToPojo(json, EmallUser.class); return ServerResponse.success(emallUser); } catch (Exception e) { return ServerResponse.error(\"无法获取用户信息\"); } }} 3.3 Guava的LoadingCache实现方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Guava实现缓存 * @author lujiahao * @version 1.0 * @date 2017-10-20 17:33 */public class GuavaCacheImpl&lt;T&gt; implements ILocalCache&lt;T&gt; { public static final Logger LOGGER = LoggerFactory.getLogger(GuavaCacheImpl.class); // LRU算法 private static LoadingCache&lt;String, Object&gt; localCache = CacheBuilder.newBuilder().initialCapacity(1000) .maximumSize(10000).expireAfterAccess(12, TimeUnit.HOURS) .build(new CacheLoader&lt;String, Object&gt;() { // 默认的数据加载实现,当调用get取值是,如果没有key,就执行这个方法 @Override public Object load(String s) throws Exception { return null; } }); @Override public boolean setCache(String key, T value) { try { localCache.put(key, value); } catch (Exception e) { return false; } return true; } @Override public boolean cleanCache(String key) { try { localCache.invalidate(key); } catch (Exception e) { return false; } return true; } @Override public Object getCache(String key) { try { return localCache.get(key); } catch (Exception e) { LOGGER.error(\"========== localCache get error ==========\", e); } return null; }} 3.4 applicationContext.xml中配置123&lt;!--根据具体实现采用缓存实现方式--&gt;&lt;!--&lt;bean class=\"com.lujiahao.sso.utils.cache.RedisCacheImpl\"/&gt;--&gt;&lt;bean class=\"com.lujiahao.sso.utils.cache.GuavaCacheImpl\"/&gt; 3.5 代码中使用123456789101112131415161718192021222324252627282930313233343536@Servicepublic class IUserServiceImpl implements IUserService { private static final Logger LOGGER = LoggerFactory.getLogger(IUserServiceImpl.class); @Autowired private EmallUserMapper emallUserMapper; @Autowired private ILocalCache iLocalCache; @Override public ServerResponse userLogin(String username, String password) { try { String md5Password = DigestUtils.md5DigestAsHex(password.getBytes()); EmallUser emallUser = emallUserMapper.userLogin(username, md5Password); if (emallUser == null) { // 不能返回没有此用户名 没用用户名也返回这个信息是因为防止猜测用户名 return ServerResponse.error(\"用户名或密码错误\"); } // 保存用户信息前先把密码清除,为了安全起见 emallUser.setPassword(StringUtils.EMPTY); String token = UUID.randomUUID().toString(); // 这里采用接口编程的方式,到底用redis还是用guava boolean isSaveSuccess = iLocalCache.setCache(token, emallUser); if (isSaveSuccess) { return ServerResponse.success(token); } else { LOGGER.info(\"========== 用户信息保存缓存失败 ==========\"); return ServerResponse.error(\"登录失败,请重试!\"); } } catch (Exception e) { ExceptionUtil.getStackTrace(e); return ServerResponse.error(\"服务器异常\"); } }} 在代码中使用的时候,将接口ILocalCache注入,在applicationContex.xml中根据具体要求配置不同的bean,由此就可以实现将缓存业务与缓存实现解耦. 4. 总结我理解的面向接口编程就是将业务中的需求抽取出公共的几种方式或步骤,底层由不同的类来实现这个接口,由此达到解耦的目的.个人理解,欢迎大家拍砖^_^.","link":"/2017/10/22/JavaWeb%E5%9F%BA%E7%A1%80/emall%E5%95%86%E5%9F%8E-%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/"},{"title":"淘淘商城-Nginx+FTP搭建图片服务器","text":"Nginx参看[淘淘商城-Nginx笔记] FTP配置http://blog.sina.com.cn/s/blog_a97c78020101o8fv.html 参看[淘淘商城-搭建FTP服务器] 整合Nginx和FTP1.用户登录ftp的根目录vi /etc/vsftpd/vsftpd.conf添加如下内容 # 用户登录路径 local_root=/home/ # 锁定用户到各自目录为其根目录 chroot_local_user=YES # 用户配置目录 user_config_dir=/etc/vsftpd/userconfig创建/etc/vsftpd/userconfig mkdir userconfig cd userconfig/配置各自用户访问根目录 vim ftpuser添加 local_root=/home/ftpuser/www/重启服务 /etc/init.d/vsftpd restart2.配置nginx root路径为ftp路径配置Nginx主目录 vi /usr/local/nginx/conf/nginx.conf修改内容 server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root /home/ftpuser/www/; index index.html index.htm; }此时: Nginx主目录:/home/ftpuser/www/ Vsftpd.config : local_root=/home/ Userconfig/ftpuser : local_root=/home/ftpuser/www/由于我们使用的是自定义root路径，如果权限不够，在访问图片的时候可能会报403错误。所以我们需要在nginx.conf 里配置user root 添加如下内容 此时上传的根目录变成了 : /images资源的访问url : http://192.168.2.11/images/a.jpg 杂项客户端连接FTP服务器: CentOS使用命令行启动打开/etc/inittab 文件 vi /etc/inittab在默认的 run level 设置中,可以看到第一行书写如:id:5:initdefault:(默认的 run level 等级为 5,即图形界面) 将第一行的 5 修改为 3 即可。保存文件后重启系统你就可以看见是启动的文本界面了。","link":"/2016/11/02/JavaWeb%E5%9F%BA%E7%A1%80/%E6%B7%98%E6%B7%98%E5%95%86%E5%9F%8E-Nginx+FTP%E6%90%AD%E5%BB%BA%E5%9B%BE%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"淘淘商城-Nginx笔记","text":"Nginx1.介绍Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。在高连接并发的情况下，Nginx是Apache服务器不错的替代品。 2.安装Nginx2.1 安装环境配置Nginx的安装环境: yum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel2.2 安装Nginx下载nginx wget http://nginx.org/download/nginx-1.8.0.tar.gz解压 tar -zxvf nginx-1.8.0.tar.gz进入目录 cd nginx-1.8.0配置configure ./configure \\ --prefix=/usr/local/nginx \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi注意：上边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 编译生成Makefile make安装 make installnginx安装成功截图 3.Nginx常用命令3.1 启动Nginxcd /usr/local/nginx/sbin/ ./nginx 查询nginx进程： 4780是nginx主进程的进程id，4781是nginx工作进程的进程id 注意：执行./nginx启动nginx，这里可以-c指定加载的nginx配置文件，如下：./nginx -c /usr/local/nginx/conf/nginx.conf如果不指定-c，nginx在启动时默认加载conf/nginx.conf文件，此文件的地址也可以在编译安装nginx时指定./configure的参数（–conf-path= 指向配置文件（nginx.conf）） 3.2 停止nginx方式1 : 快速停止 cd /usr/local/nginx/sbin ./nginx -s stop此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。方式2 : 完整停止(建议使用)： cd /usr/local/nginx/sbin ./nginx -s quit此方式停止步骤是待nginx进程处理任务完毕进行停止。 3.3 重启nginx方式1 : 先停止再启动（建议使用）对nginx进行重启相当于先停止nginx再启动nginx，即先执行停止命令再执行启动命令。 ./nginx -s quit ./nginx方式2 : 重新加载配置文件当nginx的配置文件nginx.conf修改后，要想让配置生效需要重启nginx，使用-s reload不用先停止nginx再启动nginx即可将配置信息在nginx中生效 ./nginx -s reloadNginx无法站外访问？ 这是一个很尴尬的场面,传智的教程里面没有提到这一部分内容.此部分内容来自互联网和我自己的实践. 刚安装好nginx一个常见的问题是无法站外访问，本机wget、telnet都正常。而服务器之外，不管是局域网的其它主机还是互联网的主机都无法访问站点。如果用telnet的话，提示：正在连接到192.168.0.xxx…不能打开到主机的连接， 在端口 80: 连接失败CentOS防火墙在虚拟机的CENTOS装好APACHE不能用,郁闷,解决方法如下 /sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT /sbin/iptables -I INPUT -p tcp --dport 22 -j ACCEPT 如果还无法访问，则需配置一下Linux防火墙: iptables -I INPUT 5 -i eth0 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT然后保存： /etc/rc.d/init.d/iptables save centos 5.3，5.4以上的版本需要用 service iptables save 来实现保存到配置文件。 这样重启计算机后,CentOS防火墙默认已经开放了80和22端口。这里应该也可以不重启计算机： /etc/init.d/iptables restart CentOS防火墙的关闭，关闭其服务即可： 查看CentOS防火墙信息：/etc/init.d/iptables status 关闭CentOS防火墙服务：/etc/init.d/iptables stop 永久关闭？不知道怎么个永久法： chkconfig –level 35 iptables off。 再次访问即可使用 4.开机自启动nginx4.1 编写shell脚本这里使用的是编写shell脚本的方式来处理 vi /etc/init.d/nginx输入下面的代码 #!/bin/bash # nginx Startup script for the Nginx HTTP Server # it is v.0.0.2 version. # chkconfig: - 85 15 # description: Nginx is a high-performance web and proxy server. # It has a lot of features, but it&apos;s not for everyone. # processname: nginx # pidfile: /var/run/nginx.pid # config: /usr/local/nginx/conf/nginx.conf nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf nginx_pid=/var/run/nginx.pid RETVAL=0 prog=&quot;nginx&quot; # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ ${NETWORKING} = &quot;no&quot; ] &amp;&amp; exit 0 [ -x $nginxd ] || exit 0 # Start nginx daemons functions. start() { if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1 fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c ${nginx_config} RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL } # Stop nginx daemons functions. stop() { echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid } # reload nginx service functions. reload() { echo -n $&quot;Reloading $prog: &quot; #kill -HUP `cat ${nginx_pid}` killproc $nginxd -HUP RETVAL=$? echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; status) status $prog RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|reload|status|help}&quot; exit 1 esac exit $RETVAL然后 :wq 保存并退出(别告诉我你不会这个) 4.2 设置文件的访问权限chmod a+x /etc/init.d/nginx (a+x ==&gt; all user can execute 所有用户可执行)这样在控制台就很容易的操作nginx了：查看Nginx当前状态、启动Nginx、停止Nginx、重启Nginx… 如果修改了nginx的配置文件nginx.conf，也可以使用上面的命令重新加载新的配置文件并运行，可以将此命令加入到rc.local文件中，这样开机的时候nginx就默认启动了 4.3 加入到rc.local文件中vi /etc/rc.local加入一行 /etc/init.d/nginx start 保存并退出，下次重启会生效。 #!/bin/sh # # This script will be executed *after* all the other init scripts. # You can put your own initialization stuff in here if you don&apos;t # want to do the full Sys V style init stuff. touch /var/lock/subsys/local # nginx auto start /etc/init.d/nginx startNginx应用-反向代理(Reverse Proxy)","link":"/2016/11/02/JavaWeb%E5%9F%BA%E7%A1%80/%E6%B7%98%E6%B7%98%E5%95%86%E5%9F%8E-Nginx%E7%AC%94%E8%AE%B0/"},{"title":"淘淘商城-搭建FTP服务器","text":"1.前期准备 因为穷,所以使用的是VMware虚拟机来搭建 安装CentOS虚拟机(如果你有服务器更好) 准备IP地址(虚拟机内网 : 192.168.2.100),并配置好 准备客户端连接软件(FileZilla/Xftp/EditPlus) 2.开始安装2.1安装vsftpd组件[root@localhost ~]# yum -y install vsftpd安装完后，有/etc/vsftpd/vsftpd.conf 文件，是vsftp的配置文件。 2.2添加一个ftp用户并设置密码[root@localhost ~]# useradd ftpuser此用户就是用来登录ftp服务器用的。登录后默认的路径为 /home/ftpuser [root@localhost ~]# passwd ftpuser输入两次密码后修改密码。 密码:123 2.3防火墙开启21端口因为ftp默认的端口为21，而centos默认是没有开启的，所以要修改iptables文件 [root@localhost ~]# vim /etc/sysconfig/iptables在行上面有22 -j ACCEPT 下面另起一行输入跟那行差不多的，只是把22换成21，然后：wq保存。 修改后的内容如下: # Firewall configuration written by system-config-firewall # Manual customization of this file is not recommended. *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT还要运行下,重启iptables防火墙 [root@localhost ~]# service iptables restart2.4修改selinux外网是可以访问上去了，可是发现没法返回目录（使用ftp的主动模式，被动模式还是无法访问），也上传不了，因为selinux作怪了。 执行以下命令查看状态： [root@localhost ~]# getsebool -a | grep ftp allow_ftpd_anon_write --&gt; off allow_ftpd_full_access --&gt; off allow_ftpd_use_cifs --&gt; off allow_ftpd_use_nfs --&gt; off ftp_home_dir --&gt; off ftpd_connect_db --&gt; off ftpd_use_passive_mode --&gt; off httpd_enable_ftp_server --&gt; off tftp_anon_write --&gt; off执行上面命令，再返回的结果看到allow_ftpd_full_access和ftp_home_dir两行都是off，代表，没有开启外网的访问 [root@localhost ~]# setsebool -P allow_ftpd_full_access on [root@localhost ~]# setsebool -P ftp_home_dir on这样应该没问题了（如果，还是不行，看看是不是用了ftp客户端工具用了passive模式访问了，如提示Entering Passive mode，就代表是passive模式，默认是不行的，因为ftp passive模式被iptables挡住了，下面会讲怎么开启，如果懒得开的话，就看看你客户端ftp是否有port模式的选项，或者把passive模式的选项去掉。如果客户端还是不行，看看客户端上的主机的电脑是否开了防火墙，关吧） 2.5关闭匿名访问[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf将anonymous_enable=YES改为anonymous_enable=NO 重启ftp服务 [root@localhost ~]# service vsftpd restart2.6开启被动模式默认是开启的，但是要指定一个端口范围，打开vsftpd.conf文件，在后面加上 pasv_min_port=30000 pasv_max_port=30999表示端口范围为30000~30999，这个可以随意改。改完重启一下vsftpd由于指定这段端口范围，iptables也要相应的开启这个范围，所以像上面那样打开iptables文件。也是在21上下面另起一行，更那行差不多，只是把21 改为30000:30999,然后:wq保存 修改后的内容如下: # Generated by iptables-save v1.4.7 on Sat Sep 3 13:04:11 2016 *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [9:1116] -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT -A INPUT -p tcp -m tcp --dport 30000:30999 -j ACCEPT -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT # Completed on Sat Sep 3 13:04:11 2016重启iptables防火墙 [root@localhost ~]# service iptables restart2.7设置开机启动vsftpd ftp服务[root@localhost ~]# chkconfig vsftpd on3.客户端连接工具介绍3.1FileZilla哈哈 这个没用过 虽然视频里面讲的是这个工具 3.2Xftp一图胜千言 3.3EditPlus五图胜千言 总结我竟然不知道EditPlus居然能连接FTP服务器,这样的话用这个东西来修改服务器配置就方便多了,不用再一点一点vim了(原谅我只会vim简单操作). 说明这篇文章整理自黑马JavaEE的课程笔记中,外加了点自己的实践的东西加油学,闪光之前总是要经历黑暗.^_^","link":"/2016/11/02/JavaWeb%E5%9F%BA%E7%A1%80/%E6%B7%98%E6%B7%98%E5%95%86%E5%9F%8E-%E6%90%AD%E5%BB%BAFTP%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"谷歌推出12款新官方主题，赶快给你的Chrome换换样子！","text":"前言新年伊始，开工大吉！新的一年，各位大佬准备好码起来了吗！俗话说得好，工欲善其事必先利其器，今天介绍下谷歌官方出品的浏览器主题，让我们的 Chrome 浏览器更加赏心悦目！ 随着 macOS Mojave 的发布，黑暗模式不再仅是手机专属，PC 端迎来了黑暗模式主题。小编本人就在第一时间更新系统，黑暗模式绝对的科技感十足！![](https://raw.githubusercontent.com/lujiahao0708/PicRepo/master/2019/20190213%E8%B0%B7%E6%AD%8C%E6%8E%A8%E5%87%BA12%E6%AC%BE%E6%96%B0%E5%AE%98%E6%96%B9%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%BB%99%E4%BD%A0%E7%9A%84Chrome%E6%8D%A2%E6%8D%A2%E6%A0%B7%E5%AD%90%EF%BC%81/macOS Mojave.png) Chrome 新主题为了满足用户对黑暗模式的需求，Google Chrome 团队在新年期间为大众提供了全新的主题模式。这套 Chrome 谷歌浏览器官方新主题共包含 12 款，其中备受欢迎的黑暗模式主题(Just Black），极大的满足了倾向于夜间工作的用户群体。![](https://raw.githubusercontent.com/lujiahao0708/PicRepo/master/2019/20190213%E8%B0%B7%E6%AD%8C%E6%8E%A8%E5%87%BA12%E6%AC%BE%E6%96%B0%E5%AE%98%E6%96%B9%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%BB%99%E4%BD%A0%E7%9A%84Chrome%E6%8D%A2%E6%8D%A2%E6%A0%B7%E5%AD%90%EF%BC%81/Just Black.png) 除了备受欢迎的黑暗模式外，还有一系列主题可选择，包括 Slate、Oceanic、Ultra Violet、Classic Blue、Banana、Black＆White、Honeysuckle、Rose、Serenity、Sea Foam、Marsala、高对比色彩、以及 Pretty in Pink 等。大家可以依据个人喜好选择自己中意的主题。 截止小编发稿是，本次新主题中好评度较高的的几款如下：![](https://raw.githubusercontent.com/lujiahao0708/PicRepo/master/2019/20190213%E8%B0%B7%E6%AD%8C%E6%8E%A8%E5%87%BA12%E6%AC%BE%E6%96%B0%E5%AE%98%E6%96%B9%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%BB%99%E4%BD%A0%E7%9A%84Chrome%E6%8D%A2%E6%8D%A2%E6%A0%B7%E5%AD%90%EF%BC%81/Ultra Violet.png)![](https://raw.githubusercontent.com/lujiahao0708/PicRepo/master/2019/20190213%E8%B0%B7%E6%AD%8C%E6%8E%A8%E5%87%BA12%E6%AC%BE%E6%96%B0%E5%AE%98%E6%96%B9%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%BB%99%E4%BD%A0%E7%9A%84Chrome%E6%8D%A2%E6%8D%A2%E6%A0%B7%E5%AD%90%EF%BC%81/Black &amp; White.png)小编个人选择了 Slate 主题。（我感觉 Just Black 主题太黑了😁，纯个人观点） 恢复默认主题 主题刚刚安装后，顶部会有一个撤销按钮，如果感觉并不满意当前的主题，可以撤销恢复默认主题。 如果用户在使用任何主题一段时间后，若要恢复成默认主题，可以单击菜单&gt;设置&gt;外观，然后单击“ 重置为默认值 ”，即可恢复。 获得主题有兴趣朋友可以访问 Chrome 网上应用商店，搜索主题背景，进入主题页面来查看及获得主题。 Tips本文同步发表在公众号，欢迎大家关注！😁 各位大佬点点广告，万分感谢！！！","link":"/2019/02/13/JavaWeb%E5%9F%BA%E7%A1%80/%E8%B0%B7%E6%AD%8C%E6%8E%A8%E5%87%BA12%E6%AC%BE%E6%96%B0%E5%AE%98%E6%96%B9%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%BB%99%E4%BD%A0%E7%9A%84Chrome%E6%8D%A2%E6%8D%A2%E6%A0%B7%E5%AD%90%EF%BC%81/"},{"title":"解决Mac下VSCode打开zsh乱码","text":"1.乱码问题iTerm2终端使用Zsh，并且配置Zsh主题，该主题主题需要安装字体来支持箭头效果，在iTerm2中设置这个字体，但是VSCode里这个箭头还是显示乱码。 iTerm2展示如下: VSCode展示如下: 2.解决方案2.1 字体在字体册查找是否已经安装Meslo LG M for Powerline字体，如果未安装就安装一下。 2.2 VSCode中配置使用⌘,打开settings界面,搜索terminal,在Font Family中添加字体Meslo LG M for Powerline 也可以在VSCode的settings.json文件，加入 : “terminal.integrated.fontFamily”: “Meslo LG M for Powerline”, 3.效果展示 欢迎大家关注😁","link":"/2019/07/21/Mac%E7%9B%B8%E5%85%B3/%E8%A7%A3%E5%86%B3Mac%E4%B8%8BVSCode%E6%89%93%E5%BC%80zsh%E4%B9%B1%E7%A0%81/"},{"title":"Mac使用ssh公钥免密登录服务器","text":"每次登陆服务器都要输入密码,重复无用的操作让人心生厌烦。“懒人是推动社会进步的动力”,我的宗旨就是能自动的就不要手动。下面就像大家介绍我是如何打造无密码登录服务器: 1. 生成公钥和密钥相信使用过git的朋友对这一部分应该不会陌生,git的公私钥配置也是这样在本地生成的,这里就不赘述了。 2. 编辑ssh配置文件1234567891011121314vim ~/.ssh/config增加：#Tencent ServerHost ts HostName 111.231.199.76 User root PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_tencent_server 1. Host ts #别名，域名缩写2. HostName 111.231.199.76 #完整的域名或ip地址3. User root #登录该域名使用的账号名4. PreferredAuthentications publickey #有些情况或许需要加入此句，优先验证类型ssh5. IdentityFile ~/.ssh/id_rsa_tencent_server #本地私钥文件的路径 详细配置见下图: 我的电脑里面配置了公司的gitlab和github,再加上服务器的就有三组配置了。 3. 放置公钥到服务器目录中1scp ~/.ssh/id_rsa_tencent_server.pub ts:~/.ssh/ 4. 服务器配置公钥1mv id_rsa.pub authorized_keys 如果服务器有authorized_keys这个文件就直接覆盖。 5. 本地和服务器文件权限123456现在为本地mac的私钥设置权限：chmod 700 ~/.sshchmod 600 ~/.ssh/id_rsa_tencent_server设置服务器上的文件权限：chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 6. 服务器禁用密码登录(可选)12345vi /etc/ssh/sshd_config # 将PasswordAuthentication设置成no，# 然后重启service sshd restart如果你需要用密码登录，这一步也可以不设置（ssh root@111.231.199.76） 7. 登录服务器1ssh ts 8. 动图演示下面的动图演示两种登录服务器的方法: ssh 用户@ip ssh 自定义名称 第一种方式需要每次手动输入密码,一旦输入错误就得重新输入,非常不方便。然而第二种方式无需每次输入密码,减少误输入的问题。通过对比不难发现第二种方式方便快捷,一劳永逸,非常推荐大家动手操作配置。 8. 参考教程 https://bitzhi.com/2015/07/login-in-linux-servers-with-sshkey-on-osx/ https://my.oschina.net/kmwzjs/blog/732601 http://cssor.com/mac-ssh-auto-login-server.html 欢迎大家关注😁","link":"/2019/05/28/Mac%E7%9B%B8%E5%85%B3/Mac%E4%BD%BF%E7%94%A8ssh%E5%85%AC%E9%92%A5%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"阿里开源项目上新，Flutter Go 请查收！","text":"前言新年伊始，阿里开源项目上新了！此次是阿里拍卖前端团队带来的 Fluttr Go ，针对于时下很火的跨平台移动解决方案推出的实例APP项目，对于Flutter初学者，学习掌握此项目是极其有益的。 Flutter 是什么?2018年6月21日Google发布Flutter首个release预览版,作为Google 大力推出的一种全新的响应式，跨平台，高性能的移动开发框架。Flutter是一个跨平台的移动UI框架，旨在帮助开发者使用一套代码开发高性能、高保真的Android和iOS应用。 flutter优点主要包括： 开源、跨平台 Hot Reload、响应式框架、及其丰富的控件以及开发工具 灵活的界面设计以及控件组合 借助可以移植的GPU加速的渲染引擎以及高性能ARM代码运行时已达到高质量的用户体验 Flutter Go 的由来 帮助开发者快速上手 Flutter Flutter学习资料太少，对于英文不好的同学相对来说比较困难 官网文档示例不够健全，不够直观 各个 widget 的用法各异，属性纷繁，要运行一个 widget 的 demo 往往要到处翻阅各种资料 Flutter Go 的优势 详解常用widget多达 140+ 个 配套 Demo 详解 widget 常规用法 集中整合 widget 案例，一个 APP 搞定所有常用 widget 的用法 持续迭代 ‘追新’ 官方版本 app 预览 后记跨平台技术蓝海已经出现，未来跨平台开发甚至多端统一的开发模式与语言势必成为主流。而我们大家一般都是只拥有一个技术栈，这就需要我们努力扩展知识宽度广度的同时，也要多涉猎时下新兴技术，紧追技术的时代大潮！ Tips本文同步发表在公众号，欢迎大家关注！😁 各位大佬点点广告，万分感谢！！！","link":"/2019/02/14/JavaWeb%E5%9F%BA%E7%A1%80/%E9%98%BF%E9%87%8C%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E4%B8%8A%E6%96%B0%EF%BC%8CFlutter-Go-%E8%AF%B7%E6%9F%A5%E6%94%B6%EF%BC%81/"},{"title":"Redis安装&amp;搭建本地环境&amp;备份恢复","text":"搭建流程记录,方便日后查看。 Windows下安装并设置Redis Redis本地环境搭建Windows 下环境搭建1. 设置hosts(这个没啥用,可以不用设置)set duapphosts=127.0.0.1 sqld.duapp.com set redisduapphosts=127.0.0.1 redis.duapp.com echo %duapphosts% &gt;&gt; C:\\Windows\\System32\\drivers\\etc\\hosts echo %redisduapphosts% &gt;&gt; C:\\Windows\\System32\\drivers\\etc\\hosts2. 下载Redis-Windows版本Redis官网下载页面: http://redis.io/download Windows下Redis项目: https://github.com/MSOpenTech/redis 在releases页面找到并下载最新的ZIP包: https://github.com/MSOpenTech/redis/releases 3. 解压安装加压下载后的文件 redis-2.8.17.zip 到 redis-2.8.17 目录. 例如: D:\\DevlopPrograms\\redis-2.8.17. 如果需要简单测试一下, 鼠标双击 redis-server.exe即可,如果没错, 稍后会弹出命令行窗口显示执行状态. 如果不是 Administrator用户,则可能需要以管理员身份运行. 或者参考 Windows 7 启用超级管理员administrator账户的N种方法 简单测试,则使用 redis-cli.exe 即可, 打开后会自动连接上本机服务器. 可以输入 info 查看服务器信息. 如果要进行基准测试,可以启动服务器后,在cmd中运行 redis-benchmark.exe 程序. 4. 启动与注册服务如果准备长期使用,则需要注册为系统服务. 进入CMD,切换目录: D: cd D:\\DevlopPrograms\\redis-2.8.17注册服务,可以保存为 service-install.bat 文件: redis-server.exe --service-install redis.windows.conf --loglevel verbose redis-server --service-start卸载服务, 可以保存为 uninstall-service.bat 文件.: redis-server --service-stop redis-server --service-uninstall可以在注册服务时,通过 –service-name redisService1 参数直接指定服务名,适合安装多个实例的情况,卸载也是同样的道理. 启动redis服务器时也可以直接指定配置文件,可以保存为 startup.bat 文件: redis-server.exe redis.windows.conf当然,指定了配置文件以后,可能会碰到启动失败的问题.此时,请修改配置文件,指定 maxheap 参数. 5. 修改配置文件修改配置文件redis.windows.conf,如果有中文,请另存为UTF-8编码. # 修改端口号 # port 6379 port 80 # 指定访问密码 # requirepass foobared requirepass 6EhSiGpsmSMRyZieglUImkTr-eoNRNBgRk397mVyu66MHYuZDsepCeZ8A-MHdLBQwQQVQiHBufZbPa # 设置最大堆内存限制,两者设置一个即可 # maxheap &lt;bytes&gt; maxheap 512000000 # 设置最大内存限制, 两者设置一个即可 # maxmemory &lt;bytes&gt; # maxmemory 512000000此时,如果用客户端来访问,使用如下cmd命令,可以保存为 client.bat 文件: redis-cli.exe -h redis.duapp.com -p 80 -a 6EhSiGpsmSMRyZieglUImkTr-eoNRNBgRk397mVyu66MHYuZDsepCeZ8A-MHdLBQwQQVQiHBufZbPa6. 其他附加管理工具: RedisStudio: https://github.com/cinience/RedisStudio 当然,目录里面也有一些word文档, 有兴趣可以读一读. 更多信息,请参考: renfufei的专栏-Redis: http://blog.csdn.net/renfufei/article/category/2470713 Redis 数据备份与恢复 Redis SAVE 命令用于创建当前数据库的备份。 语法redis Save 命令基本语法如下： redis 127.0.0.1:6379&gt; SAVE 实例redis 127.0.0.1:6379&gt; SAVE OK该命令将在 redis 安装目录中创建dump.rdb文件。 恢复数据如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。","link":"/2020/04/11/Redis/Redis%E5%AE%89%E8%A3%85-%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"},{"title":"01.Shiro简介","text":"Apache Shiro（发音为“shee-roh”，日语“堡垒（Castle）”的意思）是一个强大易用的 Java 安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。 1. 权限管理权限管理包括用户身份认证和授权两个部分,简称认证授权 身份认证 : 为判断用户是否为合法用户的过程,最常用的身份认证方式就是系统通过核对用户输入的用户名和口令,将其与系统中存储的该用户信息相对比,继而来判断用户身份是否正确 授权 : 既访问权限,控制用户访问资源的权限. 主体(subject)进行身份认证后需要分配权限方可访问系统的资源 2. Shiro核心概念三个核心的概念Subject，SecurityManager和Realms，如图所示： Subject : 主体,代表了当前”用户”,这个用户不一定是一个具体的人,与当前应用交互的任何东西都是Subject,如网络爬虫,机器人等,即为一个抽象概念. 所有Subject都绑定到SecurityManager,与Subject的所有交互都会委托给SecurityManager. 可以把Subject认为是一个门面,SecurityManager才是实际的执行者 SecurityManager : 安全管理器,即所有与安全有关的操作都会与SecurityManager交互,且它管理着所有Subject. 可以看出它是Shiro的核心,它负责与后边介绍的其他组件进行交互,如果学习过SpringMVC,你可以把它看成DispatcherServlet前端控制器 Realm : 域,Shiro从Realm获取安全数据(如用户、角色、权限),就是说SecurityManager要验证用户身份,那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法,也需要从Realm得到用户相应的角色 / 权限进行验证用户是否能进行操作. 可以把Realm看成 DataSource,即安全数据源 Shiro基本工作流程： 应用代码通过Subject来进行认证和授权,而Subject又将所有的互交都委托给了SecurityManager 我们需要给Shiro的SecurityManager注入Realm,从而让SecurityManager能得到合法的用户及其权限进行判断 Shiro不提供维护用户 / 权限，而是通过Realm让开发人员自己注入。通过继承AuthorizingRealm抽象类，实现doGetAuthorizationInfo和doGetAuthenticationInfo方法。 3. Shiro架构 Authentication : 身份认证 / 登录,验证用户是不是拥有相应的身份 Authorization : 授权,即权限验证,验证某个已认证的用户是否拥有某个权限. 即判断用户是否能做事情,常见的如 : 验证某个用户是否拥有某个角色,或者细粒度的验证某个用户对某个资源是否具有某个权限 Session Manager : 会话管理,即用户登录后就是一次会话,在没有退出之前,它的所有信息都在会话中. 会话可以是普通JavaSE环境的,也可以是如Web环境的 Cryptography : 加密,保护数据的安全性,如密码加密存储到数据库,而不是明文存储 Web Support : Web支持,可以非常容易的集成到Web环境中 Caching : 缓存,比如用户登录后,其用户信息、拥有的角色 / 权限不必每次去查,这样可以提高效率 Concurrency : shiro支持多线程应用的并发验证,即如在一个线程中开启另一个线程,能把权限自动传播过去 Testing : 提供测试支持 Run As : 允许一个用户假装为另一个用户(在他们允许的情况下)的身份进行访问 Remember Me : 记住我,这个是非常常见的功能,即一次登录后,下次不用重复登录了 4. Shiro架构详解 Subject : 主体,可以看到主体可以是任何可以与应用交互的”用户” SecurityManager : 相当于SpringMVC中的DispatcherServlet或Struts2中的FilterDispatcher; 是Shiro的心脏. 所有具体的交互都通过SecurityManager进行控制,它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理 Authenticator : 认证器,负责主体认证的,这是一个扩展点,如果用户觉得Shiro默认的不好,可以自定义实现. 其需要认证策略(Authentication Strategy),即什么情况下算用户认证通过了 Authrizer : 授权器,或者访问控制器,用来决定主体是否有权限进行相应的操作,即控制着用户能访问应用中的哪些功能 Realm : 可以有1个或多个Realm,可以认为是安全实体数据源,即用于获取安全实体. 可以是JDBC实现,也可以是LDAP实现,或者内存实现等,由用户提供. 注意 : Shiro不知道你的用户 / 权限存储在哪及以何种格式存储,所以我们一般在应用中都需要实现自己的Realm SessionManager : 如果写过Servlet就应该知道Session的概念,Session需要有人去管理它的生命周期,这个组件就是SessionManager,而Shiro并不仅仅可以用在Web环境,也可以用在如普通的JavaSE环境、EJB等环境. 所以Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据. 这样的话,比如我们在Web环境用,刚开始是一台Web服务器,接着又上了台EJB服务器,这时想把两台服务器的会话数据放到一个地方,这个时候就可以实现自己的分布式会话(如把数据放到Memcached服务器) SessionDAO : DAO大家都用过,数据访问对象,用于会话的CRUD,比如我们想把Session保存到数据库,那么可以实现自己的 SessionDAO,通过如JDBC写到数据库. 比如想把Session放到Memcached中,可以实现自己的Memcached SessionDAO. 另外SessionDAO中可以使用Cache进行缓存,以提高性能 CacheManager : 缓存控制器,来管理如用户、角色、权限等的缓存的. 因为这些数据基本上很少去改变,放到缓存中后可以提高访问的性能 Cryptography : 密码模块,Shiro提高了一些常见的加密组件用于如密码加密 / 解密 参考资料 https://www.infoq.cn/article/apache-shiro/ http://shiro.apache.org/architecture.html https://mrbird.cc/tags/Shiro/ Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/12/Shiro/01-Shiro%E7%AE%80%E4%BB%8B/"},{"title":"02.Shiro入门实例","text":"本篇为Shiro入门案例，使用Spring Boot集成。 1. 引入坐标依赖有两种方式引入jar包 SpringBoot starter方式（推荐） shiro-spring 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 或者 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 2. 创建ini文件Shiro最基础的配置方式，存储用户身份信息（即用户名和密码） 12[users]lujiahao=123 3. 主体代码编写这里我有点偷懒了，直接在Application的main方法写了，你可以使用单元测试的写法，这样更加专业些。 1234567891011121314151617181920212223242526272829303132@SpringBootApplicationpublic class ShiroIniApplication { public static void main(String[] args) { SpringApplication.run(ShiroIniApplication.class, args); // 1.加载配置文件，创建SecurityManger工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(\"classpath:shiro.ini\"); // 2.获得SecurityManager实例对象 SecurityManager securityManager = factory.getInstance(); // 3.将SecurityManger绑定到当前运行环境中 SecurityUtils.setSecurityManager(securityManager); // 4.创建当前登录主体 Subject currentUser = SecurityUtils.getSubject(); // 5.绑定主体登录的身份凭证（即账户密码） UsernamePasswordToken token = new UsernamePasswordToken(\"lujiahao\", \"123\"); // 6.主体登录 try { currentUser.login(token); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated()); } catch (UnknownAccountException e) { System.out.println(\"账户信息错误：无此账户信息\"); } catch (IncorrectCredentialsException e) { System.out.println(\"密码错误！\"); } catch (Exception e) { e.printStackTrace(); } // 7.注销登录 currentUser.logout(); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated()); }} 4. 运行结果正常执行： 12用户身份验证：true用户身份验证：false 账户不存在： 12账户信息错误：无此账户信息用户身份验证：false 修改代码中的用户名，与ini文件中不一致即可 密码错误： 12密码错误！用户身份验证：false 修改代码中的密码，与ini文件中不一致即可 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://juejin.im/post/5cff0cfc5188250d28510681 https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/13/Shiro/02-Shiro%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B/"},{"title":"04-Shiro角色及权限","text":"授权，也叫访问控制，即在应用中控制谁能访问哪些资源(如访问页面/编辑数据/页面操作等)。 1. 相关概念在授权中需了解的几个关键对象：主体(Subject)、资源(Resource)、权限(Permission)、角色(Role)，其解析如下所示： 主体 : 即访问应用的用户，在Shiro中使用Subject代表该用户。用户只有授权后才允许访问相应的资源。 资源 : 在应用中用户可以访问的任何资源，比如访问JSP页面、查看/编辑某些数据、访问某个业务方法、打印文本等等用户需要授权后方可访问。 权限 : 安全策略中的原子授权单位,可用权限控制用户在应用中是否能访问某个资源,如访问用户列表页面,查看/新增/修改/删除用户数据(基本为CRUD式权限控制)。 角色 : 角色代表了操作集合,可以理解为权限的集合,一般情况下我们会赋予用户角色而不是权限,即这样用户可以拥有一组权限,不同的角色拥有一组不同的权限。 隐式角色 : 即直接通过角色来验证用户有没有操作权限，即粒度是以角色为单位进行访问控制的，粒度较粗。若进行变更可能需要多处代码的修改。 显示角色 : 在程序中通过权限控制谁能访问某个资源，角色聚合一组权限集合。这样若需要哪个角色不能访问某个资源，只需要从角色代表的权限集合中移除指定的访问权限即可，无须修改多处代码。 2. 授权方式Shiro有三种授权方式： 2.1 编程方式123456Subject subject = SecurityUtils.getSubject();if(subject.hasRole(\"admin\")) { //有权限} else { // 无权限} 2.2 注解方式1234@RequiresRoles(\"admin\")public void hello() { // 有权限} 2.3 jsp标签形式123&lt;shiro:hasRole name=\"admin\"&gt;// 有权限&lt;/shiro:hasRole&gt; 3. ini方式验证角色和权限3.1 shiro-roles.ini1234567891011[users]# 用户lujiahao的密码是123，拥有role1和role2两个角色lujiahao=123,role1,role2zhangsan=321,role3[roles]# 角色role1对资源user拥有create和update权限role1=user:create,user:update# 角色role2对资源user拥有delete权限role2=user:deleterole3=user:update 配置规则： 用户名=密码,角色1,角色2... 角色=权限1,权限2... 权限字符串的规则：操作:资源实例标识符 可以使用*通配符 eg： 用户创建权限：user:create 用户修改实例001的权限：user:update:0013.2 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Testpublic void testRole() { // 用户登录，授权操作的前提是用户已经通过认证 Subject subject = this.doLogin(\"shiro-roles.ini\", \"lujiahao\", \"123\"); System.out.println(\"验证用户是否拥有某个角色 true：拥有 false：没有\"); System.out.println(subject.hasRole(\"role1\")); System.out.println(\"验证用户是否拥有所有角色 true：全部拥有 false：不全部拥有\"); System.out.println(subject.hasAllRoles(Arrays.asList(\"role1\", \"role2\", \"role3\"))); System.out.println(\"验证用户是否拥有角色，返回boolean类型数组 true：拥有 false：没有\"); System.out.println(Arrays.toString(subject.hasRoles(Arrays.asList(\"role1\", \"role2\", \"role3\")))); System.out.println(\"验证用户是否拥有某个角色 拥有：无异常 没有：报UnauthorizedException异常\"); subject.checkRole(\"role1\"); System.out.println(\"验证用户是否拥有所有角色 拥有：无异常 没有：报UnauthorizedException异常\"); subject.checkRoles(\"role1\", \"role2\"); System.out.println(\"验证用户是否拥有所有角色 拥有：无异常 没有：报UnauthorizedException异常\"); subject.checkRoles(Arrays.asList(\"role1\", \"role2\"));}@Testpublic void testPermission() { // 用户登录，授权操作的前提是用户已经通过认证 Subject subject = this.doLogin(\"shiro-roles.ini\", \"lujiahao\", \"123\"); System.out.println(\"验证用户是否拥有某个权限 true：拥有 false：没有\"); System.out.println(subject.isPermitted(\"user:list\")); System.out.println(\"验证用户是否拥有所有权限 true：全部拥有 false：不全部拥有\"); System.out.println(subject.isPermittedAll(\"user:delete\", \"user:update\", \"user:create\")); System.out.println(\"验证用户是否拥有权限，返回boolean类型数组 true：拥有 false：没有\"); System.out.println(Arrays.toString(subject.isPermitted(\"user:list\", \"user:update\", \"user:create\"))); System.out.println(\"验证用户是否拥有某个权限 拥有：无异常 没有：报UnauthorizedException异常\"); subject.checkPermission(\"user:update\"); System.out.println(\"验证用户是否拥有所有权限 拥有：无异常 没有：报UnauthorizedException异常\"); subject.checkPermissions(\"user:delete\", \"user:update\", \"user:create\");} 4. 自定义Realm验证角色和权限4.1 shiro-permission-realm.ini1234# 声明一个realmmyRealm=com.lujiahao.PermissionRealm# 指定securitymanager的realms实现securityManager.realms=$myRealm 4.2 自定义Realm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 自定义realm实现 * * @author lujiahao * @date 2019/10/14 */public class PermissionRealm extends AuthorizingRealm { @Override public String getName() { return \"permissionRealm\"; } /** * 用户权限和角色 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { // 当前用户登录信息 String username = (String) principalCollection.getPrimaryPrincipal(); // 模拟数据库查询用户角色和权限 List&lt;String&gt; roles = new ArrayList&lt;&gt;(); List&lt;String&gt; permissions = new ArrayList&lt;&gt;(); roles.add(\"role1\"); permissions.add(\"user:read\"); // 增加权限 SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); info.addRoles(roles); info.addStringPermissions(permissions); return info; } /** * 用户认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { // 获取用户信息 String username = (String) token.getPrincipal(); // 模拟从数据库获取用户名和密码 String dbUsername = \"lujiahao\"; String dbPassword = \"123\"; // 验证用户 if (!dbUsername.equals(username)) { return null; } // 参数列表依次是： 用户名 密码 当前realm名字 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, dbPassword, getName()); return info; }} 4.3 测试代码12345678@Testpublic void testPermissionRealm() { // 用户登录，授权操作的前提是用户已经通过认证 Subject subject = this.doLogin(\"shiro-permission-realm.ini\", \"lujiahao\", \"123\"); System.out.println(subject.isPermitted(\"user:read\")); System.out.println(subject.hasRole(\"role1\"));} 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/15/Shiro/04-Shiro%E8%A7%92%E8%89%B2%E5%8F%8A%E6%9D%83%E9%99%90/"},{"title":"06-Shiro与Spring Boot用户认证","text":"Spring Boot与Shiro整合案例，用户认证部分。 Spring Boot集成Shiro主要配置两个类： ShiroConfig类及继承AuthorizingRealm的Realm类。 ShiroConfig：是Shiro的配置，相当于Spring中的xml配置。包括：包括过滤器(ShiroFilter)、安全事务管理器(SecurityManager)、密码凭证匹配器(CredentialsMatcher)、缓冲管理器(EhCacheManager)、AOP注解支持(authorizationAttributeSourceAdvisor)、等等 UserRealm：自定义的UserRealm继承自AuthorizingRealm，重写doGetAuthorizationInfo(授权认证)和doGetAuthenticationInfo(登陆认证)这两个方法。 1. 依赖1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- thymeleaf --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-web-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2. ShiroConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Configurationpublic class ShiroConfig { /** * 过滤规则 */ @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) { ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 设置securityManager shiroFilterFactoryBean.setSecurityManager(securityManager); // 登录的url shiroFilterFactoryBean.setLoginUrl(\"/login\"); // 登录成功后跳转的url shiroFilterFactoryBean.setSuccessUrl(\"/index\"); // 未授权url shiroFilterFactoryBean.setUnauthorizedUrl(\"/403\"); // LinkedHashMap是有序的，shiro会按照顺序依次匹配，匹配成功就不验证了，因此下面的url是较为宽松的 // 上面的url是比较严格的 \"/**\"一定要放在最后 Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); // 定义filterChain，静态资源不拦截 filterChainDefinitionMap.put(\"/css/**\", \"anon\"); filterChainDefinitionMap.put(\"/js/**\", \"anon\"); filterChainDefinitionMap.put(\"/fonts/**\", \"anon\"); filterChainDefinitionMap.put(\"/img/**\", \"anon\"); // 配置退出过滤器，其中具体的退出代码Shiro已经替我们实现了 filterChainDefinitionMap.put(\"/logout\", \"logout\"); // 除上以外所有url都必须认证通过才可以访问，未通过认证自动访问LoginUrl filterChainDefinitionMap.put(\"/**\", \"authc\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; } /** * 安全管理器 * 注：使用shiro-spring-boot-starter 1.4时，返回类型是SecurityManager会报错，直接引用shiro-spring则不报错 */ @Bean public DefaultWebSecurityManager securityManager(){ DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(userRealm()); return securityManager; } /** * 自定义realm */ @Bean public UserRealm userRealm(){ UserRealm userRealm = new UserRealm(); return userRealm; }} 3. 自定义Realm12345678910111213141516171819202122232425262728293031323334353637383940@Slf4jpublic class UserRealm extends AuthorizingRealm { @Autowired private UserMapper userMapper; /** * 获取用户角色和权限 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principal) { return null; } /** * 登录认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { // 获取用户输入的用户名和密码 String userName = (String) token.getPrincipal(); String password = new String((char[]) token.getCredentials()); log.info(\"用户:{} 执行登录认证操作\", userName); // 通过用户名到数据库查询用户信息 User user = userMapper.findByUserName(userName); if (user == null) { throw new UnknownAccountException(\"用户名或密码错误！\"); } if (!password.equals(user.getPassword())) { throw new IncorrectCredentialsException(\"用户名或密码错误！\"); } SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, password, getName()); return info; }} 4. Service/Mapper/SQL 参考工程中的data.sql 5. html登录界面： 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;登录&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"login-page\"&gt; &lt;div class=\"form\"&gt; &lt;input type=\"text\" placeholder=\"用户名\" name=\"username\" required=\"required\"/&gt;&lt;br/&gt; &lt;input type=\"password\" placeholder=\"密码\" name=\"password\" required=\"required\"/&gt;&lt;br/&gt; &lt;button onclick=\"login()\"&gt;登录&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;script th:inline=\"javascript\"&gt; function login() { var username = $(\"input[name='username']\").val(); var password = $(\"input[name='password']\").val(); $.ajax({ type: \"post\", url: \"/login\", data: {\"username\": username,\"password\": password}, dataType: \"json\", success: function (r) { if (r.code == 0) { location.href = '/index'; } else { alert(r.msg); } } }); }&lt;/script&gt;&lt;/html&gt; 首页： 123456789101112&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;首页&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;你好！[[${user.username}]]&lt;/p&gt;&lt;a th:href=\"@{/logout}\"&gt;注销&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/17/Shiro/06-Shiro%E4%B8%8ESpring%20Boot%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/"},{"title":"05-Shiro拦截器","text":"Shiro内置了很多默认的拦截器，比如身份验证、授权等相关的。 拦截器列表 Filter Name Class Description anon org.apache.shiro.web.filter.authc.AnonymousFilter 匿名拦截器，即不需要登录即可访问；一般用于静态资源过滤；示例/static/**=anon authc org.apache.shiro.web.filter.authc.FormAuthenticationFilter 基于表单的拦截器；如/**=authc，如果没有登录会跳到相应的登录页面登录 authcBasic org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter Basic HTTP身份验证拦截器 logout org.apache.shiro.web.filter.authc.LogoutFilter 退出拦截器，主要属性：redirectUrl：退出成功后重定向的地址（/），示例/logout=logout noSessionCreation org.apache.shiro.web.filter.session.NoSessionCreationFilter 不创建会话拦截器，调用subject.getSession(false)不会有什么问题，但是如果subject.getSession(true)将抛出DisabledSessionException异常 perms org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter 权限授权拦截器，验证用户是否拥有所有权限；属性和roles一样；示例/user/**=perms[“user:create”] port org.apache.shiro.web.filter.authz.PortFilter 端口拦截器，主要属性port(80)：可以通过的端口；示例/test= port[80]，如果用户访问该页面是非80，将自动将请求端口改为80并重定向到该80端口，其他路径/参数等都一样 rest org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter rest风格拦截器，自动根据请求方法构建权限字符串；示例/users=rest[user]，会自动拼出user:read,user:create,user:update,user:delete权限字符串进行权限匹配（所有都得匹配，isPermittedAll） roles org.apache.shiro.web.filter.authz.RolesAuthorizationFilter 角色授权拦截器，验证用户是否拥有所有角色；示例/admin/**=roles[admin] ssl org.apache.shiro.web.filter.authz.SslFilter SSL拦截器，只有请求协议是https才能通过；否则自动跳转会https端口443；其他和port拦截器一样； user org.apache.shiro.web.filter.authc.UserFilter 用户拦截器，用户已经身份验证/记住我登录的都可；示例/**=user anon,authcBasic,auchc,user是认证过滤器. perms,roles,ssl,rest,port是授权过滤器 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/16/Shiro/05-Shiro%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"title":"07-Shiro与Spring Boot用户授权.md","text":"Spring Boot与Shiro整合案例，用户授权部分。 Spring Boot集成Shiro主要配置两个类： ShiroConfig类及继承AuthorizingRealm的Realm类。 ShiroConfig：是Shiro的配置，相当于Spring中的xml配置。包括：包括过滤器(ShiroFilter)、安全事务管理器(SecurityManager)、密码凭证匹配器(CredentialsMatcher)、缓冲管理器(EhCacheManager)、AOP注解支持(authorizationAttributeSourceAdvisor)、等等 UserRealm：自定义的UserRealm继承自AuthorizingRealm，重写doGetAuthorizationInfo(授权认证)和doGetAuthenticationInfo(登陆认证)这两个方法。 1. 依赖1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- thymeleaf --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-web-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2. ShiroConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Configurationpublic class ShiroConfig { /** * 过滤规则 */ @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) { ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 设置securityManager shiroFilterFactoryBean.setSecurityManager(securityManager); // 登录的url shiroFilterFactoryBean.setLoginUrl(\"/login\"); // 登录成功后跳转的url shiroFilterFactoryBean.setSuccessUrl(\"/index\"); // 未授权url shiroFilterFactoryBean.setUnauthorizedUrl(\"/403\"); // LinkedHashMap是有序的，shiro会按照顺序依次匹配，匹配成功就不验证了，因此下面的url是较为宽松的 // 上面的url是比较严格的 \"/**\"一定要放在最后 Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); // 定义filterChain，静态资源不拦截 filterChainDefinitionMap.put(\"/css/**\", \"anon\"); filterChainDefinitionMap.put(\"/js/**\", \"anon\"); filterChainDefinitionMap.put(\"/fonts/**\", \"anon\"); filterChainDefinitionMap.put(\"/img/**\", \"anon\"); // 配置退出过滤器，其中具体的退出代码Shiro已经替我们实现了 filterChainDefinitionMap.put(\"/logout\", \"logout\"); // 除上以外所有url都必须认证通过才可以访问，未通过认证自动访问LoginUrl filterChainDefinitionMap.put(\"/**\", \"authc\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; } /** * 安全管理器 * 注：使用shiro-spring-boot-starter 1.4时，返回类型是SecurityManager会报错，直接引用shiro-spring则不报错 */ @Bean public DefaultWebSecurityManager securityManager(){ DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(userRealm()); return securityManager; } /** * 自定义realm */ @Bean public UserRealm userRealm(){ UserRealm userRealm = new UserRealm(); return userRealm; }} 3. 自定义Realm12345678910111213141516171819202122232425262728293031323334353637383940@Slf4jpublic class UserRealm extends AuthorizingRealm { @Autowired private UserMapper userMapper; /** * 获取用户角色和权限 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principal) { return null; } /** * 登录认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { // 获取用户输入的用户名和密码 String userName = (String) token.getPrincipal(); String password = new String((char[]) token.getCredentials()); log.info(\"用户:{} 执行登录认证操作\", userName); // 通过用户名到数据库查询用户信息 User user = userMapper.findByUserName(userName); if (user == null) { throw new UnknownAccountException(\"用户名或密码错误！\"); } if (!password.equals(user.getPassword())) { throw new IncorrectCredentialsException(\"用户名或密码错误！\"); } SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, password, getName()); return info; }} 4. Service/Mapper/SQL 参考工程中的data.sql 5. html登录界面： 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;登录&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"login-page\"&gt; &lt;div class=\"form\"&gt; &lt;input type=\"text\" placeholder=\"用户名\" name=\"username\" required=\"required\"/&gt;&lt;br/&gt; &lt;input type=\"password\" placeholder=\"密码\" name=\"password\" required=\"required\"/&gt;&lt;br/&gt; &lt;button onclick=\"login()\"&gt;登录&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;script th:inline=\"javascript\"&gt; function login() { var username = $(\"input[name='username']\").val(); var password = $(\"input[name='password']\").val(); $.ajax({ type: \"post\", url: \"/login\", data: {\"username\": username,\"password\": password}, dataType: \"json\", success: function (r) { if (r.code == 0) { location.href = '/index'; } else { alert(r.msg); } } }); }&lt;/script&gt;&lt;/html&gt; 首页： 123456789101112&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;首页&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;你好！[[${user.username}]]&lt;/p&gt;&lt;a th:href=\"@{/logout}\"&gt;注销&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/18/Shiro/07-Shiro%E4%B8%8ESpring%20Boot%E7%94%A8%E6%88%B7%E6%8E%88%E6%9D%83/"},{"title":"《Elasticsearch技术解析与实战》Chapter 1.2 Elasticsearch安装","text":"1. 下载安装1.1 下载12https://www.elastic.co/downloads/elasticsearch下载 https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.7.0.tar.gz 1.2 解压1tar -zxvf elasticsearch-6.7.0.tar.gz 1.3 运行12cd elasticsearch-6.7.0bin/elasticsearch 1.4 检验1234567891011121314curl http://localhost:9200 或者浏览器访问{ \"name\": \"q9sdES9\", \"cluster_name\": \"docker-cluster\", \"cluster_uuid\": \"6klEi4d0Q6y0LC3YNYVXTQ\", \"version\": { \"number\": \"5.5.0\", \"build_hash\": \"260387d\", \"build_date\": \"2017-06-30T23:16:05.735Z\", \"build_snapshot\": false, \"lucene_version\": \"6.6.0\" }, \"tagline\": \"You Know, for Search\"} 2. Docker部署 官方文档 : https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 2.1 拉取镜像1docker pull docker.elastic.co/elasticsearch/elasticsearch:5.5.1 2.2 启动容器1docker run -p 9200:9200 9300:9300 -e \"http.host=0.0.0.0\" -e “transport.host=0.0.0.0\" --name elasticsearch_5.5.0 -d docker.elastic.co/elasticsearch/elasticsearch:5.5.0 2.3 修改配置12345进入到容器中 : docker exec -it elasticsearch_5.5.0 /bin/bash修改jvm配置 : vi /config/jvm.options -Xms2g —&gt; -Xms512m -Xmx2g —&gt; -Xmx512m 修改小一些,服务器内存有限😂 2.4 重启容器,查看是否成功123456789101112131415http://服务器ip:9200{ \"name\": \"q9sdES9\", \"cluster_name\": \"docker-cluster\", \"cluster_uuid\": \"6klEi4d0Q6y0LC3YNYVXTQ\", \"version\": { \"number\": \"5.5.0\", \"build_hash\": \"260387d\", \"build_date\": \"2017-06-30T23:16:05.735Z\", \"build_snapshot\": false, \"lucene_version\": \"6.6.0\" }, \"tagline\": \"You Know, for Search\"}此处集群的名称为 docker-cluster, 可以自行修改 : vi /config/elasticsearch.yml Tips本文同步发表在公众号，欢迎大家关注！😁后续笔记欢迎关注获取第一时间更新！","link":"/2019/04/14/%E3%80%8AElasticsearch%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Chapter%201.2%20Elasticsearch%E5%AE%89%E8%A3%85/"},{"title":"《Elasticsearch技术解析与实战》Chapter 1.3 Elasticsearch增删改查","text":"1. 新增文档，建立索引语法格式: PUT /index/type/id { &quot;json数据&quot; }输入: PUT /person/chinese/1 { &quot;id&quot;:12345, &quot;name&quot;:&quot;lujiahao&quot;, &quot;age&quot;:18 }输出: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;created&quot;: true } es会自动建立index和type，不需要提前创建，而且es默认会对document每个field都建立倒排索引，让其可以被搜索。 2. 检索文档格式: GET /index/type/id输入: GET /person/chinese/1输出: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: { &quot;id&quot;: 12345, &quot;name&quot;: &quot;lujiahao&quot;, &quot;age&quot;: 18 } }3. 更新文档3.1 替换方式格式: PUT /index/type/id { &quot;json数据&quot; }输入: PUT /person/chinese/1 { &quot;name&quot;:&quot;lujiahao123&quot; }输出: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;created&quot;: false }查询: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: { &quot;name&quot;: &quot;lujiahao123&quot; } } 替换方式更新文档时，必须带上所有的field，才能去进行信息的修改；如果缺少field就会丢失部分数据。其原理时替换，因此需要全部字段。不推荐此种方式更新文档。 3.1 更新方式格式: POST /index/type/id/_update { &quot;doc&quot;:{ &quot;json数据&quot; } }输入: POST /person/chinese/1/_update { &quot;doc&quot;:{ &quot;name&quot;:&quot;lujiahao10010&quot; } }输出: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 4, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;created&quot;: false }再次查询： { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 6, &quot;found&quot;: true, &quot;_source&quot;: { &quot;id&quot;: 12345, &quot;name&quot;: &quot;lujiahao10010&quot;, &quot;age&quot;: 18 } }4. 删除文档格式: DELETE /index/type/id/_update { &quot;doc&quot;:{ &quot;json数据&quot; } }输入: DELETE /person/chinese/1输出: { &quot;found&quot;: true, &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 7, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 } }再次查询: { &quot;_index&quot;: &quot;person&quot;, &quot;_type&quot;: &quot;chinese&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;found&quot;: false }5. 小结本文所有操作都是在kibana的Dev tools中进行的，相较于Elasticsearch-Heade插件，kibana中更加方便与美观（个人观点），推荐大家使用。 Tips本文同步发表在公众号，欢迎大家关注！😁后续笔记欢迎关注获取第一时间更新！","link":"/2019/04/15/%E3%80%8AElasticsearch%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Chapter%201.3%20Elasticsearch%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"title":"《Elasticsearch技术解析与实战》Chapter 2.1 Elasticsearch索引增删改查","text":"1. 创建索引123456PUT /lujiahao123{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true}索引默认的主分片数量是5，每个主分片的副本数量是1。 创建自定义字段类型的索引： 1234567891011121314151617181920212223PUT /order{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 2 }, &quot;mappings&quot;: { &quot;carpoolType&quot;:{ &quot;properties&quot;: { &quot;orderNo&quot;:{ &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; } } } }}#! Deprecation: The [string] field is deprecated, please use [text] or [keyword] instead on [orderNo]{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true}ES5.0版本中string类型被拆分为text和keyword类型: https://www.elastic.co/blog/strings-are-dead-long-live-strings 2. 修改索引1234PUT /order/_settings{ &quot;number_of_replicas&quot;: 2} 更新分词器 1234567891011121314POST /order/_closePUT /order/_settings{ &quot;analysis&quot;: { &quot;analyzer&quot;: { &quot;content&quot;:{ &quot;type&quot;:&quot;customer&quot;, &quot;tokenizer&quot;:&quot;whitespace&quot; } } }}POST /order/_open添加分析器之前必须先关闭索引，添加之后再打开索引。 尝试修改索引主分片数： 1234PUT /order/_settings{ &quot;number_of_shards&quot;: 2} 错误提示： 123456789101112131415{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Can't update non dynamic settings [[index.number_of_shards]] for open indices [[order/2cOJ6Ga7THCyW10idoPPig]]&quot; } ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Can't update non dynamic settings [[index.number_of_shards]] for open indices [[order/2cOJ6Ga7THCyW10idoPPig]]&quot; }, &quot;status&quot;: 400}主分片是无法修改的，主分片个数一旦建立就无法修改，但是看错误原因里面说因为这个是open的索引，那是不是关闭的索引就可以修改主分片个数了呢？这个我们后面再解答。 3. 删除索引123删除单个索引：DELETE /order删除索引需要指定索引名称，别名或者通配符 123删除多个索引：DELETE order,order1,order2DELETE order* 123删除全部索引：DELETE _allDELETE * 使用_all 和通配符删除全部索引为了防止误删除，设置config/elasticsearch.yml属性action.destructive_requires_name=true，以禁用通配符或_all删除索引。 4. 查询索引123456789101112131415161718192021222324252627GET /order{ &quot;order&quot;: { &quot;aliases&quot;: {}, &quot;mappings&quot;: { &quot;carpoolType&quot;: { &quot;properties&quot;: { &quot;orderNo&quot;: { &quot;type&quot;: &quot;keyword&quot; } } } }, &quot;settings&quot;: { &quot;index&quot;: { &quot;creation_date&quot;: &quot;1555054886098&quot;, &quot;number_of_shards&quot;: &quot;3&quot;, &quot;number_of_replicas&quot;: &quot;2&quot;, &quot;uuid&quot;: &quot;uSh9K26CS_q1uZKaos7NRQ&quot;, &quot;version&quot;: { &quot;created&quot;: &quot;5050099&quot; }, &quot;provided_name&quot;: &quot;order&quot; } } }} 自定义返回结果的属性： 123456789101112131415161718GET /order/_settings,_aliases{ &quot;order&quot;: { &quot;settings&quot;: { &quot;index&quot;: { &quot;creation_date&quot;: &quot;1555054886098&quot;, &quot;number_of_shards&quot;: &quot;3&quot;, &quot;number_of_replicas&quot;: &quot;2&quot;, &quot;uuid&quot;: &quot;uSh9K26CS_q1uZKaos7NRQ&quot;, &quot;version&quot;: { &quot;created&quot;: &quot;5050099&quot; }, &quot;provided_name&quot;: &quot;order&quot; } }, &quot;aliases&quot;: {} }} 5. 打开/关闭索引索引关闭只能显示索引元数据信息，不能够进行读写。 12345POST /order/_closePOST /order/_openhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open .kibana 8n5wnGEjRJ-aVa54l_jTjA 1 1 1 0 3.1kb 3.1kbyellow open order uSh9K26CS_q1uZKaos7NRQ 3 2 0 0 486b 486b 可以同时打开或关闭多个索引。如果指向不存在的索引会抛出错误，可通过配置ignore_unavailable=true 关闭异常提示。禁止使用关闭索引功能，配置settingscluster.indices.close.enable为false，默认值是ture。 6. 关闭索引后尝试修改主分片个数1234567891011121314151617PUT /order/_settings{ &quot;number_of_shards&quot;: 2}{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;final order setting [index.number_of_shards], not updateable&quot; } ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;final order setting [index.number_of_shards], not updateable&quot; }, &quot;status&quot;: 400} 解答了之前的问题，索引一旦建立，主分片数量不可改变。 Tips本文同步发表在公众号，欢迎大家关注！😁后续笔记欢迎关注获取第一时间更新！","link":"/2019/04/17/%E3%80%8AElasticsearch%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Chapter%202.1%20Elasticsearch%E7%B4%A2%E5%BC%95%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"title":"《Elasticsearch技术解析与实战》Chapter 1.4 Spring Boot整合Elasticsearch","text":"1. spring-boot-starter-data-elasticsearch1.1 pom.xml和application.yml123456789101112&lt;!-- Spring Boot Elasticsearch 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt;spring: data: elasticsearch: repositories: enabled: true cluster-name: docker-cluster cluster-nodes: lujiahao.ml:9300 1.2 创建Repository1234@Repositorypublic interface PersonEsRepository extends ElasticsearchRepository&lt;Person,Long&gt; { List&lt;Person&gt; findPersonByName(String name);} 1.3 文档实体类12345678910@Data@Document(indexName = \"person\", type = \"chinese\")public class Person implements Serializable{ private static final long serialVersionUID = -6804453833406105286L; @Id private Long id; private String name; private Integer age; private String address;} 1.4 增删改查1234567891011121314151617181920212223242526272829@Servicepublic class EsStarterService { @Autowired private PersonEsRepository repository; /** * 增 */ public Person save(Person person) { return repository.save(person); } /** * 删 */ public void delete(Person person) { repository.delete(person); } /** * 改 */ public Person update(Person person) { return repository.save(person); } /** * 查 */ public Iterable&lt;Person&gt; findAll() { return repository.findAll(); }} 1.5 单元测试1234567891011121314151617181920212223242526272829303132@RunWith(SpringRunner.class)@SpringBootTestpublic class EsStarterServiceTest { @Autowired private EsStarterService esStarterService; @Test public void save() { Person person = new Person(); person.setId(new Random().nextLong()); person.setName(\"lujiahao\"); esStarterService.save(person); } @Test public void delete() { Person person = new Person(); person.setId(-5264182431891613084L); person.setName(\"lujiahao123456\"); esStarterService.delete(person); } @Test public void update() { Person person = new Person(); person.setId(542136934419565287L); person.setName(\"lujiahao123456\"); esStarterService.update(person); } @Test public void findAll() { Iterable&lt;Person&gt; all = esStarterService.findAll(); all.forEach(System.out::println); }} 2. ElasticsearchTemplate2.1 pom.xml和application.ym123456789101112&lt;!--elasticsearch--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt;spring: data: elasticsearch: repositories: enabled: true cluster-name: docker-cluster cluster-nodes: lujiahao.ml:9300 2.2 文档实体类同上 2.3 增删改查123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Servicepublic class ElasticsearchTemplateService { @Autowired public ElasticsearchTemplate elasticsearchTemplate; private static final String INDEX_NAME = \"person\"; private static final String TYPE_NAME = \"chinese\"; /** * 增 */ public String save(Person person) { IndexQuery indexQuery = new IndexQueryBuilder() .withIndexName(INDEX_NAME) .withType(TYPE_NAME) .withId(String.valueOf(person.getId())) .withObject(person) .build(); String index = elasticsearchTemplate.index(indexQuery); System.out.println(\"xxxxxxxxxxxx \" + index); return index; } /** * 删 */ public void deleteByName(String name) { DeleteQuery deleteQuery = new DeleteQuery(); deleteQuery.setQuery(QueryBuilders.matchQuery(\"name\", name)); deleteQuery.setIndex(INDEX_NAME); deleteQuery.setType(TYPE_NAME); elasticsearchTemplate.delete(deleteQuery); } /** * 改 */ public UpdateResponse update(Person person) { try { UpdateRequest updateRequest = new UpdateRequest() .index(INDEX_NAME) .type(TYPE_NAME) .id(String.valueOf(person.getId())) .doc(XContentFactory.jsonBuilder() .startObject() .field(\"name\", person.getName()) .endObject()); UpdateQuery updateQuery = new UpdateQueryBuilder() .withIndexName(INDEX_NAME) .withType(TYPE_NAME) .withId(String.valueOf(person.getId())) .withClass(Person.class) .withUpdateRequest(updateRequest) .build(); UpdateResponse update = elasticsearchTemplate.update(updateQuery); return update; } catch (Exception e) { return null; } } /** * 查 */ public List&lt;Person&gt; getAll() { SearchQuery searchQuery = new NativeSearchQueryBuilder() .withQuery(QueryBuilders.matchAllQuery()) .build(); return elasticsearchTemplate.queryForList(searchQuery, Person.class); }} 2.4 单元测试12345678910111213141516171819202122232425262728293031@RunWith(SpringRunner.class)@SpringBootTestpublic class ElasticsearchTemplateServiceTest { @Autowired private ElasticsearchTemplateService elasticsearchTemplateService; @Test public void save() { Person person = new Person(); person.setId(new Random().nextLong()); person.setName(\"haha\"); String save = elasticsearchTemplateService.save(person); System.out.println(save); } @Test public void deleteByName() { elasticsearchTemplateService.deleteByName(\"lujiahao\"); } @Test public void update() { Person person = new Person(); person.setId(-5264182431891613084L); person.setName(\"hahaaaaaaaaa\"); UpdateResponse update = elasticsearchTemplateService.update(person); System.out.println(update); } @Test public void getAll() { List&lt;Person&gt; all = elasticsearchTemplateService.getAll(); System.out.println(all); }} 3. 代码示例1https://github.com/lujiahao0708/LearnSeries/tree/master/LearnElasticSerach Tips本文同步发表在公众号，欢迎大家关注！😁后续笔记欢迎关注获取第一时间更新！","link":"/2019/04/16/%E3%80%8AElasticsearch%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Chapter%201.4%20Spring%20Boot%E6%95%B4%E5%90%88Elasticsearch/"},{"title":"《Java 8 in Action》Chapter 1：为什么要关心Java 8","text":"自1998年 JDK 1.0(Java 1.0) 发布以来，Java 已经受到了学生、项目经理和程序员等一大批活跃用户的欢迎。这一语言极富活力，不断被用在大大小小的项目里。从 Java 1.1(1997年) 一直到 Java 7(2011年)，Java 通过增加新功能，不断得到良好的升级。Java 8 则是在2014年3月发布的。Java 8 所做的改变，在许多方面比 Java 历史上任何一次改变都深远，而且极大的提高了 Java 代码的简洁性。 1. lambda 表达式本文通过筛选苹果的需求引入 Java 8 ，对 inventory 中的苹果按照重量进行排序。Java 8 之前的版本： 12345Collections.sort(inventory, new Comparator&lt;Apple&gt;() { public int compare(Apple a1, Apple a2){ return a1.getWeight().compareTo(a2.getWeight()); }}); Java 8 版本： 1inventory.sort(comparing(Apple::getWeight)); 通过对比我们不难发现，使用 Java 8 可以编写更为简洁的代码，而且代码读起来更接近问题的描述。 2. 方法引用在 Java 8 之前类（Class）是Java中的一等公民，Java8中将方法和lambda增加为一等公民。方法和lambda作为一等公民，是Java8中方法引用的基础。除了允许(命名)函数成为一等值外，Java 8还体现了更广义的将函数作为值的思想，包括 Lambda1(或匿名函数)。 筛选一个目录中的所有隐藏文件，Java 8 之前版本： 12345File[] hiddenFiles = new File(“.”).listFiles(new FileFilter() { public boolean accept (File file) { return file.isHidden(); }} Java 8 版本： 1File[] hiddenFiles = new File(\".\").listFiles(File::isHidden); 3. 流在Java8之前，遍历处理集合元素，你得用for-each循环一个个去迭代元素，然后再处理元素。我们把这种数据迭代的方法称为外部迭代。相反，有了Stream API，你根本用不着操心循环的事情。数据处理完全是在库内部进行的。我们把这种思想叫作内部迭代。 Java 8 中对于大数据量的集合，用Stream API(java.util.stream)解决了：集合处理时的套路和晦涩，以及难以利用多核这两个问题。 如下展示 Java 8 中使用 Stream API 并行处理数据： 12import static java.util.stream.Collectors.toList;List&lt;Apple&gt; heavyApples = inventory.parallelStream().filter((Apple a) -&gt; a.getWeight() &gt; 150) .collect(toList()); 4. 默认方法Java 8中加入默认方法主要是为了支持库设计师，让他们能够写出更容易改进的接口。同时，普通开发者也可以在接口中使用默认方法，在实现类没有实现方法时提供方法内容，进一步方便开发。 12List&lt;Apple&gt; heavyApples1 = inventory.stream().filter((Apple a) -&gt; a.getWeight() &gt; 150).collect(toList());List&lt;Apple&gt; heavyApples2 = inventory.parallelStream().filter((Apple a) -&gt; a.getWeight() &gt; 150).collect(toList()); 在Java 8之前，List并没有stream或parallelStream方法，它实现 的Collection接口也没有。Java 8 给接口设计者提供了一个扩充接口的方式，而不会破坏现有的代码。Java 8在接口声明 中使用新的default关键字来表示这一点。这样就实现了改变已发布的接口而不破坏已有的实现。 总结本章主要总结Java 8 的主要变化(Lambda表达式、方法引用、流和默认方法)，为后面更进一步学习打下坚实基础。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/02/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%201%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%85%B3%E5%BF%83Java-8/"},{"title":"《Java 8 in Action》Chapter 4：引入流","text":"1. 流简介流是Java API的新成员，它允许你以声明性方式处理数据集合(通过查询语句来表达，而不是临时编写一个实现)。就现在来说，你可以把它们看成遍历数据集的高级迭代器。此外，流还可以透明地并行处理。让我们来看一个实例返回低热量(&lt;400)的菜肴名称： 12345678910111213141516171819202122232425262728Java7版本：List&lt;Dish&gt; lowCaloricDishes = new ArrayList&lt;&gt;();// 用累加器筛选元素for(Dish d: menu){ if(d.getCalories() &lt; 400){ lowCaloricDishes.add(d); }}// 用匿名类对菜肴排序Collections.sort(lowCaloricDishes, new Comparator&lt;Dish&gt;() { public int compare(Dish d1, Dish d2){ return Integer.compare(d1.getCalories(), d2.getCalories()); }});// 处理排序后的菜名列表List&lt;String&gt; lowCaloricDishesName = new ArrayList&lt;&gt;();for(Dish d: lowCaloricDishes){ lowCaloricDishesName.add(d.getName());}Java8版本：import static java.util.Comparator.comparing;import static java.util.stream.Collectors.toList;List&lt;String&gt; lowCaloricDishesName = menu.stream() .filter(d -&gt; d.getCalories() &lt; 400) // 选出400卡路里以下的菜肴 .sorted(comparing(Dish::getCalories)) // 按照卡路里排序 .map(Dish::getName) // 提取菜肴名称 .collect(toList()); // 将所有的名称保存在List中利用多核架构并行执行，只需要把stream()换成parallelStream() Java 8中的Stream API特性： 声明性——更简洁，更易读 可复合——更灵活 可并行——性能更好 流定义： 元素序列——就像集合一样，流也提供了一个接口，可以访问特定元素类型的一组有序 值。 源——流会使用一个提供数据的源，如集合、数组或输入/输出资源。 请注意，从有序集 合生成流时会保留原有的顺序。由列表生成的流，其元素顺序与列表一致。 数据处理操作——流的数据处理功能支持类似于数据库的操作，以及函数式编程语言中的常用操作，如filter、map、reduce、find、match、sort等。流操作可以顺序执行，也可并行执行。 流水线——很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。这让我们下一章中的一些优化成为可能，如延迟和短路。流水线的操作可以看作对数据源进行数据库式查询。 内部迭代——与使用迭代器显式迭代的集合不同，流的迭代操作是在背后进行的。 2. 流与集合集合与流之间的差异就在于什么时候进行计算。集合是一个内存中的数据结构，它包含数据结构中目前所有的值——集合中的每个元素都得先算出来才能添加到集合中。相比之下，流则是在概念上固定的数据结构(你不能添加或删除元素)，其元素则是按需计算的。集合和流的另一个关键区别在于它们遍历数据的方式。 2.1 只能遍历一次和迭代器类似，流只能遍历一次。遍历完之后，我们就说这个流已经被消费掉了。以下代码会抛出一个异常，说流已被消费掉了： 123456789List&lt;String&gt; title = Arrays.asList(“Java8”,”In”, “Action”);Stream&lt;String&gt; s = title.stream();s.forEach(System.out::println);s.forEach(System.out::println);Exception in thread \"main\" java.lang.IllegalStateException: stream has already been operated upon or closed at java.util.stream.AbstractPipeline.sourceStageSpliterator(AbstractPipeline.java:279) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at com.lujiahao.learnjava8.chapter4.StreamAndCollection.main(StreamAndCollection.java:16) 2.2 外部迭代与内部迭代使用Collection接口需要用户去做迭代(比如用for-each)，这称为外部迭代。相反,Streams库使用内部迭代 123456789101112131415161718集合:用for-each循环外部迭代List&lt;String&gt; names = new ArrayList&lt;&gt;();for(Dish d: menu){ names.add(d.getName());}集合:用背后的迭代器做外部迭代List&lt;String&gt; names = new ArrayList&lt;&gt;();Iterator&lt;String&gt; iterator = menu.iterator();while(iterator.hasNext()) { Dish d = iterator.next(); names.add(d.getName());}流:内部迭代List&lt;String&gt; names = menu.stream() .map(Dish::getName) .collect(toList()); 3. 流操作java.util.stream.Stream中的Stream接口定义了许多操作。它们可以分为两大类。可以连接起来的流操作称为中间操作，关闭流的操作称为终端操作。中间操作：除非流水线上触发一个终端操作，否则中间操作不会执行任何处理。终端操作：会从流的流水线生成结果。其结果是任何不是流的值。 流的使用一般包括三件事: 一个数据源(如集合)来执行一个查询; 一个中间操作链，形成一条流的流水线; 一个终端操作，执行流水线，并能生成结果。 流的流水线背后的理念类似于构建器模式。 常见流操作： 4. 小结以下是你应从本章中学到的一些关键概念。 流是“从支持数据处理操作的源生成的一系列元素”。 流利用内部迭代:迭代通过filter、map、sorted等操作被抽象掉了。 流操作有两类:中间操作和终端操作。 filter和map等中间操作会返回一个流，并可以链接在一起。可以用它们来设置一条流水线，但并不会生成任何结果 forEach和count等终端操作会返回一个非流的值，并处理流水线以返回结果。 流中的元素是按需计算的。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/08/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%204%EF%BC%9A%E5%BC%95%E5%85%A5%E6%B5%81/"},{"title":"第一章 快速认识线程","text":"对于计算机而言每个任务就是一个进程,在每个进程内部至少要有一个线程,因此有时线程也称为轻量级进程.线程是程序执行的一个路径,每一个线程都有自己的局部变量表,程序计数器以及各自的生命周期. 1.创建线程1.1 演示并行运行1234567891011121314151617181920212223242526272829303132333435363738public class TryConcurrencyThread { public static void main(String[] args) { // 通过匿名内部类的方式创建线程,并重写其中的run方法 new Thread() { @Override public void run() { enjoyMusic(); } }.start(); browseNews(); } private static void browseNews() { for (; ; ) { System.out.println(\"Uh-huh, the good news.\"); sleep(1); } } private static void enjoyMusic() { for (; ; ) { System.out.println(\"Uh-huh, the nice music.\"); sleep(1); } } /** * 模拟等待并忽略异常 */ private static void sleep(int seconds) { try { TimeUnit.SECONDS.sleep(seconds); } catch (Exception e) { e.printStackTrace(); } }} 输出结果: 1234Uh-huh, the good news.Uh-huh, the nice music.Uh-huh, the good news.Uh-huh, the nice music. 上面创建线程的方法可以使用 Java 8 Lambda优化 new Thread(TryConcurrencyThreadLambda::enjoyMusic).start(); 1.2 使用Jconsole观察线程Jconsole是JDK自身提供的监测工具.可以在控制台启动jconsole 图中Thread-0就是我们创建的新线程. 2.线程生命周期 线程生命周期: NEW RUNNABLE RUNNING BLOCKED TERMINATED 2.1 线程NEW状态当我们用关键字 new 创建一个 Thread 对象时,此时它并不处于执行状态,因为没有调用 start 方法启动该线程,那么线程的状态为 NEW 状态,准确的说,它只是 Thread 对象的状态,因为在没有 start 之前,该线程根本不存在,与你用关键字 new 创建一个普通的 Java 对象没有什么区别. NEW 状态通过 start 方法进入 RUNNABLE 状态. 2.2 线程RUNNABLE状态线程对象进入 RUNNABLE 状态必须调用 start 方法,那么此时才是真正的在 JVM 进程中创建了一个线程,线程启动后是不会立即执行的,需要听令于 CPU 的调度,此时称此状态为可执行状态(RUNNABLE),即线程具备执行资格,但是并没有真正执行,在等待 CPU 调度. 由于存在 running 状态,所以不会直接进入 BLOCKED 状态和 TERMINATED 状态,即使是在线程的执行逻辑中调用 wait sleep 或者其他 block 的IO 操作等,也不许先获得 CPU 的调度执行权才可以,严格来讲, RUNNABLE 的线程只能意外终止或者进入 RUNNING 状态. 2.3 线程RUNNING状态一旦 CPU 通过轮询或者其他方式从任务可执行队列中选中了线程,那么此时它才能真正的执行自己的逻辑代码,需要说明的一点是一个正在 RUNNING 状态的线程事实上也是 RUNNABLE 的,反之则不成立. 此状态下线程的状态可以发生如下转换: 直接进入 TERMINATED 状态,比如调用 JDK 已经不推荐的 stop 方法或者判断某个逻辑标识 进入 BLOCKED 状态,比如调用 sleep 或者wait 方法而加入 waitSet中 进行某个阻塞 IO 操作,比如因网络的读写而进入 BLOCKED 状态 获取某个锁资源,从而加入到该锁的阻塞队列中而进入 BLOCKED 状态 由于 CPU 的调度器轮询使该线程放弃执行,进入 RUNNABLE 状态 线程主动调用 yield 方法,放弃 CPU 执行权,进入 RUNNABLE 状态 2.4 线程BLOCKED状态从上节即可获得线程进入 BLOCKED 状态的原因,接下来介绍线程在 BLOCKED 状态中可以切换至如下几个状态: 直接进入 TERMINATED 状态,比如调用 JDK 已经不推荐的 stop 方法或者意外死亡(JVM Crash) 线程阻塞操作结束,比如读取了想要的数据字节进入到 RUNNABLE 状态 线程完成了指定时间的休眠,进入到 RUNNABLE 状态 Wait 中的线程被其他线程 notify/notifyall 唤醒,进入到RUNNABLE 状态 线程获取到了某个锁资源,进入到 RUNNABLE 状态 线程在阻塞过程中被打断,比如其他线程调用了 interrupt 方法,进入 RUNNABLE 状态 2.5 线程TERMINATED状态TERMINATED 是一个线程的最终途状态,在该状态中线程将不会切换到其他任何状态,线程进入 TERMINATED 状态,意味着线程的整个生命周期结束了,下列情况将会使线程进入到 TERMINATED 状态: 线程运行正常结束,结束生命周期 线程运行出错意外结束 JVM Crash,导致所有的线程都结束 3.线程start方法剖析和模板设计模式应用3.1 start方法源码解析如果直接调用线程的run方法,线程是不会启动的,这相当于调用了一个类的属性方法.只有调用start方法才会启动线程,接下来我们剖析start方法原理: 12345678910111213141516171819public synchronized void start() { if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try { start0(); started = true; } finally { try { if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { } }} start方法源码很简单,核心方法是start0的本地方法.start 方法中会调用 start0方法,而start0方法会调用线程的 run方法,这一点在源码中有注释: 1Causes this thread to begin execution; the Java Virtual Machine calls the run method of this thread. 总结下源码中获得的知识点: Thread 被构造后的 NEW状态,事实上 threadStatus 这个内部属性是0 不能两次启动 Thread,否则就会出现 IllegalThreadStateException 线程启动后会被加入到一个 ThreadGroup 中 线程生命周期结束,即 TERMINATED 状态,再次调用 start 方法是不允许的,即 TERMINATED 状态无法回到 RUNNABLE/RUNNING 状态 4.Runnable接口参考资料 《JAVA与模式》之模板方法模式 Java设计模式：策略模式 代码获取https://github.com/lujiahao0708/LearnJavaConcurrent Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/11/20/%E3%80%8AJava%20%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/chapter1:%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86%E7%BA%BF%E7%A8%8B/"},{"title":"《大话数据结构》第三章 线性表(一) 顺序表","text":"1.线性表定义零个或多个数据元素的有限序列 2.线性表逻辑特性 除第一个和最后一个元素外,每个元素只有一个前驱和一个后继 第一个元素没有前驱元素 最后一个元素没有后继元素 3.线性表抽象数据类型 4.线性表存储结构 顺序存储 链式存储 本文先总结顺序存储及其代码实现,链式存储放在下一篇文章中。 5.顺序存储 用一段地址连续的存储单元一次存储线性表的数据元素 5.1 插入数据 5.2 删除数据 6.代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public class SequenceList&lt;T&gt; { // 默认长度 private final int DEFAULT_SIZE = 16; // 保存数组的长度 private int capacity; // 数组,保存顺序线性表 private Object[] elementData; // 顺序线性表中当前元素个数 private int size = 0; // 默认长度创建空线性表 public SequenceList() { capacity = DEFAULT_SIZE; elementData = new Object[capacity]; } // 以一个初始化元素创建顺序线性表 public SequenceList(T element) { this(); elementData[0] = element; size++; } // 以指定长度创建顺序线性表 public SequenceList(T element, int initSize) { capacity = 1; // 把capacity设置为大于initSize的最小的2的n次方 while (capacity &lt; initSize) { capacity &lt;&lt;= 1; } elementData = new Object[capacity]; elementData[0] = element; size++; } // 获取线性表的大小 public int length() { return size; } // 获取索引i的元素 public T get(int i) { if (i &lt; 0 || i &gt; size - 1) { throw new IndexOutOfBoundsException(\"索引超出线性表范围\"); } return (T) elementData[i]; } // 根据元素查找在线性表中的位置 public int indexOf(T element) { for (int i = 0; i &lt; size; i++) { if (elementData[i].equals(element)) { return i; } } return -1; } // 向顺序表中指定位置插入元素 public void insert(T element, int index) { if (index &lt; 0 || index &gt; size) { throw new IndexOutOfBoundsException(\"索引超出线性表范围\"); } ensureCapacity(size + 1); // 将指定索引处之后的所有元素后移 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } private void ensureCapacity(int minCapacity) { // 如果数组的原有长度小于目前所需的长度 if (minCapacity &gt; capacity) { // 不断的将capacity*2,知道capacity大于minCapacity while (capacity &lt; minCapacity) { capacity &lt;&lt;= 1; } elementData = Arrays.copyOf(elementData, capacity); } } // 在线性表的末端增加一个元素 public void add(T element) { insert(element, size); } // 删除指定索引处的元素 public T delete(int index) { if (index &lt; 0 || index &gt; size - 1) { throw new IndexOutOfBoundsException(\"索引超过线性表范围\"); } T oldValue = (T) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) { System.arraycopy(elementData, index + 1, elementData, index, numMoved); } elementData[--size] = null; return oldValue; } // 删除最后一个元素 public T remove() { return delete(size - 1); } // 判断线性表是否为空 public boolean isEmpty() { return size == 0; } // 清空线性表 public void clear() { Arrays.fill(elementData, null); size = 0; } public String toString(){ if(size == 0){ return \"[]\"; } else{ StringBuilder sb = new StringBuilder(\"[\"); for(int i=0;i&lt;size;i++){ sb.append(elementData[i].toString() + \", \"); } int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); } }} 1234567891011121314151617public class SequenceTest { public static void main(String[] args) { SequenceList&lt;String&gt; sequenceList = new SequenceList&lt;&gt;(); sequenceList.add(\"hello\"); sequenceList.add(\"lu\"); sequenceList.add(\"jia\"); sequenceList.add(\"hao\"); System.out.println(sequenceList.toString()); System.out.println(\"长度:\" + sequenceList.length()); System.out.println(\"获取第一个元素:\" + sequenceList.get(0)); System.out.println(\"查看lu的索引:\" + sequenceList.indexOf(\"lu\")); sequenceList.insert(\"lifan\", 4); System.out.println(\"新的顺序表:\" + sequenceList.toString()); }} 代码详见: GitHub 欢迎大家关注😁","link":"/2019/07/15/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E7%BA%BF%E6%80%A7%E8%A1%A8(%E4%B8%80)%20%E9%A1%BA%E5%BA%8F%E8%A1%A8/"},{"title":"《大话数据结构》第一章 绪论","text":"又开新坑😂,这次是从最基础的知识起,这都是上学时候欠下的债啊!好好把基础打扎实一些,让自己更加有实力,加油! 1.基本概念1.1 数据 描述客观事物的符号,是计算机中可以操作的对象,能被计算机识别,并输入给计算机处理的符号集合. 数据不仅仅包括整型、实型等数值类型,还包括字符及声音、图像、视频等非数值类型。 1.2 数据元素 组成数据的、有一定意义的基本单位,在计算机中通常作为整体主力。也被成为记录。 1.3 数据项 一个数据元素可以由若干个数据项组成 数据项是数据不可分割的最小单位 1.4 数据对象 性质相同的数据元素的集合,是数据的子集 1.5 数据结构 是相互之间存在一种或多种特定关系的数据元素的集合 维基百科定义 2.结构分类2.1 逻辑结构2.1.1 集合结构数据元素除了同属于一个集合外,无任何关系,类似数学中的集合 2.1.2 线性结构数据元素是一对一 2.1.3 树形结构数据元素是一对多,层次关系 2.1.4 图形结构数据元素是多对多 2.2 物理结构2.2.1 顺序存储结构是把数据元素存放在地址连续的存储单元里,其数据间的逻辑关系和物理关系是一致的 2.2.2 链式存储结构是把数据元素存放在任务的存储单元里,这组存储单元可以是连续的,也可以是不连续的 3.抽象数据类型 一个数学模型及定义在该模型上的一组操作,体现了程序设计中问题分解/抽象和信息隐藏的特性. 4.小结本章简单介绍了数据结构的相关概念和整体分类,使得我对数据结构有了大体的认知,为后续内容打下基础。 欢迎大家关注😁","link":"/2019/07/13/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/"},{"title":"《深入理解Java虚拟机》前期准备","text":"为什么要学习 JVM对于 Java 开发来说 JVM 是一个坎，面试大厂必问内容，是一块硬骨头，同时也是 Java 开发的必备技能。 学习 JVM 的目的： 了解 JVM运行原理，不做”CRUD Boy” 个人技能提升( 呸❗️说实话❗️ 为了装B😏) 面试不怂 工欲善其事必先利其器 IDEA Xmind ZEN Google 纸上得来终觉浅，绝知此事要躬行 代码还是要敲的，记录自己的成长历程，你会感谢当时那么努力的自己。 艿艿 在星球里面说要形成自己的“点 -&gt; 线 -&gt; 面”，这其实说的就是知识体系，而思维导图就是生成知识体系的神兵利器。 巨人的肩膀 关于Jvm知识看这一篇就够了 Java【虚拟机】书单整理 学习JVM是如何从入门到放弃的？ 在线 Java 编译网站最后在推荐几个在线 Java 编译网站，不想用重重的 IDE 的时候可以试试看😉 https://www.tutorialspoint.com/compile_java8_online.php https://www.jdoodle.com/online-java-compiler http://www.beta.browxy.com/ https://www.compilejava.net/ 欢迎大家关注 : LF工作室 简书 : https://www.jianshu.com/u/e61935d18b09 掘金 : https://juejin.im/user/59239002570c350069c5f0bb 微信公众号 :头条号 :","link":"/2019/01/10/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/JVM-0-%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87/"},{"title":"《大话数据结构》第二章 算法","text":"1.定义算法是解决特定问题求解步骤的描述,在计算机中表现为指令的有限序列,并且每条指令表示一个或多个操作。 2.算法特性 输入输出 : 算法具有零个或多个输入,算法至少有一个或多个输出。 有穷性 : 算法在执行有限的步骤之后,自动结束而不会出现无限循环,并且每一个步骤在可以接受的时间内完成。 确定性 : 算法的每一步骤都具有确定的含义,不会出现二义性。 可行性 : 算法的每一步都必须是可行的,即每一步都能够通过执行有限次数完成。 3.算法设计要求 正确性 : 指算法至少应该具有输入、输出和加工处理无歧义性、能正确反映问题的需求、能够得到问题的正确答案。 可读性 : 算法设计的另一个目的就是为了便于阅读、理解和交流。 健壮性 : 当输入数据不合法时,算法也能做出相关处理,而不是产生异常或莫名其妙的结果。 时间效率高和存储量低 : 好的算法还应该具备时间效率高和存储量低的特点。 4.度量方法 事后统计 事前分析预估 5.算法时间复杂度5.1 定义在进行算法分析时,语句总的执行次数T(n)是关于问题规模n的函数,进而分析T(n)随n的变化情况并确定T(n)的数量级.算法的时间复杂度,也就是算法的时间量度,记作:T(n)=O(f(n)).它表示随着问题规模n的增大,算法执行时间的增长率和f(n)的增长率相同,称作算法的渐近时间复杂度,简称为时间复杂度.其中f(n)是问题规模n的某个函数 这样用大写O()来体现算法时间复杂度的记法,称之为大O记法。 5.2 推到大O阶方法 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中,只保留最高阶项 如果最高阶项存在且不是1,则去除与这个项相乘的常数 5.3 常见时间复杂度即排序 O(1) : 常数阶 O(logn) : 对数阶 O(n) : 线性阶 O(nlogn) : nlogn阶 O(n²) : 平方阶 O(n³) : 立方阶 O(2ⁿ) : 指数阶 O(n!) : 阶乘阶 O(nⁿ) 从小到大的排序 : O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n²)&lt;O(n³)&lt;O(2ⁿ)&lt;O(n!)&lt;O(nⁿ) 5.4 最坏情况与平均情况最坏情况 定义一类输入，在这类输入下，算法表现出了最坏的运行性能。这类输入的共同性质阻止了算法高效地运行，而不只是针对特定的输入。 计算最坏情况的时间复杂度 一种保证，保证运行时间不会更坏了。 是最重要的需求，通常提到的运行时间都是最坏情况的运行时间。 对实时性要求非常高的情况，必须分析最坏情况。 平均情况 平均情况是表示算法在随机给定的数据上期望的执行情况。通俗地说，一些输入可能会在某些特殊情况下耗费程序大量的时间，但是大部分的输入并不会这样。这个衡量标准描述了用户对算法性能的期望。 计算所有情况的平均值 期望的运行时间，是所有情况中最有意义的。 现实中平均运行时间很难通过分析得到，一般是通过运行一定数量的实验数据后估算出来的。 对实时性没有要求的情况，分析平均情况即可。 5.5 空间复杂度通过计算算法所需的存储空间实现,算法空间复杂度的计算公式:S(n) = O(f(n)),其中n为问题的规模,f(n)为语句关于n所占存储空间的函数. 欢迎大家关注😁","link":"/2019/07/14/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E7%AE%97%E6%B3%95/"},{"title":"GitHub Actions 自动部署 Hexo","text":"Github Actions 是 GitHub 官方 CI 工具，与 GitHub 无缝集成。之前博客使用 TravisCI 实现的自动部署，现在转用 GitHub Actions 部署，本文记录部署流程。 简单介绍下 GitHub Actions 中的术语： workflow：表示一次持续集成的过程 job：构建任务，一个 workflow 可以由一个或者多个 job 组成，可支持并发执行 job step：一个 job 由一个或多个 step 组成，按顺序依次执行 action：每个 step 由一个或多个 action 组成，按顺序依次执行 接下来介绍下操作步骤： 1.博客工程GitHub 博客创建步骤非本文重点，请自行搜索。推荐使用 master 分支作为最终部署分支，源码分支可以根据自己喜好创建，我这里创建的是 hexo。 2.生成公私钥源码分支中通过下面命令生成公钥和私钥。 123~ cd github/lujiahao0708.github.io ~ git checkout hexo~ ssh-keygen -t rsa -b 4096 -C &quot;$(git config user.email)&quot; -f github-deploy-key -N &quot;&quot; 目录中生成两个文件： github-deploy-key.pub — 公钥文件 github-deploy-key — 私钥文件 公钥和私钥切记要添加到 .gitignore 中！！！ 3.GitHub 添加公钥在 GitHub 中博客工程中按照 Settings-&gt;Deploye keys-&gt;Add deploy key 找到对应的页面，然后进行公钥添加。该页面中 Title 自定义即可，Key 中添加 github-deploy-key.pub 文件中的内容。 注意：切记不要多复制空格!!!切记要勾选 Allow write access，否则会出现无法部署的情况。 4.GitHub 添加私钥在 GitHub 中博客工程中按照 Settings-&gt;Secrets-&gt;Add a new secrets 找到对应的页面，然后进行私钥添加。该页面中 Name 自定义即可，Value 中添加 github-deploy-key 文件中的内容。 注意：切记不要多复制空格!!! 5.创建编译脚本在博客源码分支(我这里是hexo分支)中创建 .github/workflows/HexoCI.yml 文件，内容如下： 12345678910111213141516171819202122232425262728293031323334name: CIon: push: branches: - hexojobs: build: runs-on: ubuntu-latest steps: - name: Checkout source uses: actions/checkout@v1 with: ref: hexo - name: Use Node.js ${{ matrix.node_version }} uses: actions/setup-node@v1 with: version: ${{ matrix.node_version }} - name: Setup hexo env: ACTION_DEPLOY_KEY: ${{ secrets.HEXO_DEPLOY_PRI }} run: | mkdir -p ~/.ssh/ echo \"$ACTION_DEPLOY_KEY\" &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.email \"lujiahao0708@gmail.com\" git config --global user.name \"lujiahao0708\" npm install hexo-cli -g npm install - name: Hexo deploy run: | hexo clean hexo d 6.Hexo 配置在项目根目录中修改 _config.yml ，增加部署相关内容： 1234deploy: type: git repo: git@github.com:lujiahao0708/lujiahao0708.github.io.git branch: master 这里的repo要填写ssh的形式，使用http形式可能会有问题 7.验证现在 Hexo 已经和 GitHub Actions 已经集成了，接下来在博客源码分支上推送代码即可自动编译部署。具体执行过程可以在 Actions 中查看： 欢迎访问我的博客：https://lujiahao0708.github.io/ Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2020/04/11/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E5%85%B3/GitHub%20Actions%20%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%20Hexo/"},{"title":"《大话数据结构》第三章 线性表(二) 单链表","text":"链式存储线性表的链式存储结构的特点是用一组任意的存储单元出处线性表的数据元素,这组存储单元可以是连续的,也可以是不连续的。 单链表下图是最简单的单向链表: 代码详见: GitHub 欢迎大家关注😁","link":"/2019/07/15/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E7%BA%BF%E6%80%A7%E8%A1%A8(%E4%BA%8C)%20%E5%8D%95%E9%93%BE%E8%A1%A8/"},{"title":"还在用if else？策略模式了解一下！","text":"小编在公司负责的就是订单取消业务，老系统中各种类型订单取消都是通过if else 判断不同的订单类型进行不同的逻辑。在经历老系统的折磨和产品需求的不断变更，小编决定进行一次大的重构：消灭 if else。 接下来就向大家介绍下是如何消灭 if else。 1. if else模式1234567891011121314@Servicepublic class CancelOrderService { public void process(OrderDTO orderDTO) { int serviceType = orderDTO.getServiceType(); if (1 == serviceType) { System.out.println(\"取消即时订单\"); } else if (2 == serviceType) { System.out.println(\"取消预约订单\"); } else if (3 == serviceType) { System.out.println(\"取消拼车订单\"); } }} 若干个月再来看就是这样的感觉 2. 策略模式2.1 策略模式实现的Service123456789101112@Servicepublic class CancelOrderStrategyService { @Autowired private StrategyContext context; public void process(OrderDTO orderDTO) { OrderTypeEnum orderTypeEnum = OrderTypeEnum.getByCode(orderDTO.getServiceType()); AbstractStrategy strategy = context.getStrategy(orderTypeEnum); strategy.process(orderDTO); }} 简洁的有点过分了是不是!!! 2.2 各种类型策略实现及抽象策略类下面选取了即时订单和预约订单的策略. 12345678@Service@OrderTypeAnnotation(orderType = OrderTypeEnum.INSTANT)public class InstantOrderStrategy extends AbstractStrategy { @Override public void process(OrderDTO orderDTO) { System.out.println(\"取消即时订单\"); }} 12345678@Service@OrderTypeAnnotation(orderType = OrderTypeEnum.BOOKING)public class BookingOrderStrategy extends AbstractStrategy { @Override public void process(OrderDTO orderDTO) { System.out.println(\"取消预约订单\"); }} 123public abstract class AbstractStrategy { abstract public void process(OrderDTO orderDTO);} 2.3 策略类型注解每个策略中增加了注解OrderTypeAnnotation,以标注适用于不同类型的策略内容. 1234567@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface OrderTypeAnnotation { OrderTypeEnum orderType();} 2.4 策略处理器类StrategyProcessor和策略上下文StrategyContext其中最为核心的为StrategyProcessor 策略处理器类和StrategyContext 策略上下文, 1234567891011121314151617@Componentpublic class StrategyProcessor implements BeanFactoryPostProcessor { private static final String STRATEGY_PACKAGE = \"com.lujiahao.strategy\"; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException { Map&lt;OrderTypeEnum, Class&gt; handlerMap = Maps.newHashMapWithExpectedSize(3); ClassScanner.scan(STRATEGY_PACKAGE, OrderTypeAnnotation.class).forEach(clazz -&gt; { OrderTypeEnum type = clazz.getAnnotation(OrderTypeAnnotation.class).orderType(); handlerMap.put(type, clazz); }); StrategyContext context = new StrategyContext(handlerMap); configurableListableBeanFactory.registerSingleton(StrategyContext.class.getName(), context); }} 123456789101112131415161718192021222324public class StrategyContext { private Map&lt;OrderTypeEnum, Class&gt; strategyMap; public StrategyContext(Map&lt;OrderTypeEnum, Class&gt; strategyMap) { this.strategyMap = strategyMap; } public AbstractStrategy getStrategy(OrderTypeEnum orderTypeEnum) { if (orderTypeEnum == null) { throw new IllegalArgumentException(\"not fond enum\"); } if (CollectionUtils.isEmpty(strategyMap)) { throw new IllegalArgumentException(\"strategy map is empty,please check you strategy package path\"); } Class clazz = strategyMap.get(orderTypeEnum); if (clazz == null) { throw new IllegalArgumentException(\"not fond strategy for type:\" + orderTypeEnum.getCode()); } return (AbstractStrategy) SpringBeanUtils.getBean(clazz); }} 首先会扫描指定包中标有@OrderTypeAnnotation的类 将符合类的对应的枚举值作为key，对应的类作为value，保存在策略Map中 初始化StrategyContext,并注册到spring容器中,同时将策略Map传入其中 我们使用了枚举作为Map中的key,相信大家很少有人这样操作过,不过可以放心操作.通过下面两篇文章解答大家的疑问. 自定义枚举类 Enum 是否可以作为 HashMap 的key Java 在 Map 中使用复杂数据类型作为 Key 3. 总结策略模式极大的减少if else等模板代码,在提升代码可读性的同时,也大大增加代码的灵活性,添加新的策略即可以满足业务需求.本人在我司业务中对策略模式的应用得到了很好的验证,从此再也不用担心产品改需求.用策略模式一时爽,一直用一直爽😏! 4. 代码完整代码 欢迎大家关注😁","link":"/2019/01/11/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"},{"title":"《深入理解Java虚拟机》第六章 类文件结构","text":"6.1 概述代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，却是编程语言发展的一大步。 6.2 无关性的基石Java虚拟机有两个无关性，即平台无关性和语言无关性。字节码(ByteCode) 是构成平台无关性的基石。在 Java 发展之初，设计者就曾经考虑过并实现了让其他语言运行在 Java 虚拟机之上的可能性，由此 Java 规范拆分成了 Java语言规范《The Java Language Specification》及 Java 虚拟机规范《The Java Virtual Machine Specification》。 In the future, we will consider bounded extensions to the Java virtual machine to provide better support for the other languages. 语言无关性是指虚拟机并不止执行 Java程序，也考虑让其支持其他语言(Groovy/Scala/Kotlin等)的运行。 “一次编写，到处运行”。Java的平台无关性即体现在此处，可以在多个平台上运行。 6.3 Class 类文件的结构Class 文件是一组以8位字节为基础单位的二进制流。Class 文件采用一种类似于 C 语言结构体的伪结构来存储数据 : 无符号数 基本的数据类型 u1 / u2 / u4 / u8 分别代表1个字节 / 2个字节 / 4个字节 / 8个字节 可以用来描述数字 / 索引引用 / 数量值或者按照UTF-8编码构成字符串值 表 复合数据类型 由多个无符号数或者其他表作为数据项构成，习惯以“_info”结尾 用于描述有层次关系的复合结构的数据，整个 Class 文件本质上就是一张表 6.3.1 魔数与 Class 文件的版本每个 Class 文件的头4个字节称为魔数(Magic Number)。唯一作用是确定这个文件是否为一个能被虚拟机接受的 Class 文件。 紧接着魔数的4个字节是 Class 文件的版本号 : 第5和第6个字节是次版本号(Minor Version)，第7和第8个字节是主版本号(Major Version)。 将HelloWorld.java编译成 Class 文件后，使用 Synalyze It 16进制编辑工具查看 也可以使用命令查看 Class 文件的版本号 12345678910# javap -v HelloWorld.class Classfile /Users/lujiahao/HelloWorld.class Last modified 2019-1-12; size 430 bytes MD5 checksum f6fad4e65a952d7f01272063b971c2f8 Compiled from &quot;HelloWorld.java&quot;public class HelloWorld minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER... 同时查看本机 JDK 版本 : 1234# java -version java version &quot;1.8.0_161&quot;Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 通过上述方式我们可以看到 Class 文件的前9个字节的含义。下面是 Class 文件的版本号汇总 : 发布版本号 内部版本号（十六进制） 内部版本号（十进制） 1.5 31 49 1.6 32 50 1.7 33 51 1.8 34 52 Tips 0xCAFEBABE 的由来 Synalyze It 16进制编辑工具 6.3.2 常量池6.3.3 访问标志6.3.4 类索引、父类索引与接口索引集合6.3.5 字段表集合6.3.6 方法表集合6.3.7 属性表集合 欢迎大家关注😁","link":"/2019/01/12/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/"},{"title":"删库勒索比特币!这个六一过的有意思!","text":"没有删库跑路，却有删库勒索比特币！哈哈哈哈😄下面给大家讲述一下今年六一儿童节发生了啥和咋解决的。 1. 事件发生之前在腾讯云买了台基础配置的服务器，平时就部署一些练手项目，朋友偶尔也借用一下部署小项目。昨天朋友突然发消息说数据库查不出数据，让我看看咋回事。我打开Navicat一看，真的是一脸懵逼… 什么情况这是？咋多了一个数据库？其他数据库怎么数据都没了，都是同一张表？一通搜索操作，才知道原来是被黑客勒索。幸亏这个数据库是我和朋友用来测试的，平时都是自己做一些测试用，没有什么有用的数据，这种情况就直接删除镜像重新部署一个吧。 2. 事件复盘这个MySQL实例是使用Docker部署的，从笔记里面找到当时启动命令: 123docker run -d -p 3306:3306 --name mysql_test01 \\-v /mydata/mysql_test01:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=1234 mysql:5.7.6 看我的作死操作: root账户开启 弱口令(密码1234) 端口直接暴露(而且安全策略3306端口开放外网访问) 通过上面一波猛如虎的操作，我这个MySQL实例就是裸奔的节奏😂。 而且腾讯云很早就提醒有异地登录，我一直以为是朋友那边登录的，就没注意。 3. 防范步骤经过一番搜索请教和实践，总结了下面几个防范步骤，供大家参考: 3.1 云服务器后台设置云服务器厂家一般都会提供一些安全策略，建议大家都打开相关配置。例如异地登录等等都是可以提前通知管理员，提早做出风险防范。 3.2 开启MySQL日志12345678910111213141516171819202122232425# vi /usr/local/mysql/etc/my.cnf添加如下内容:#错误日志： -log-errlog-error=/usr/local/mysql-5.7.23-linux-glibc2.12-x86_64/log/error.log#查询日志： -loggeneral-log=ONgeneral-log-file=/usr/local/mysql-5.7.23-linux-glibc2.12-x86_64/log/general.log#慢查询日志: -log-slow-queries# 执行超过1秒的sql会被log下来long_query_time=1# 开启慢查询slow_query_log=on# 将查询执行时间较慢的语句进行记录#log-slow-queries=/usr/local/mysql-5.7.23-linux-glibc2.12-x86_64/log/slow.logslow-query-log-file=/usr/local/mysql-5.7.23-linux-glibc2.12-x86_64/log/slow.log#二进制日志： -log-binserver_id=100log-bin=/usr/local/mysql-5.7.23-linux-glibc2.12-x86_64/log/bin.log重启mysqld服务使配置生效# /etc/init.d/mysqld restart 3.3 MySQL配置鉴权MySQL安装默认需要设置密码，安装时如果设置了弱口令，可通过以下几种方式修改密码: UPDATE user SET password=PASSWORD(‘新密码’) WHERE user=’root’; FLUSH PRIVILEGES; SET PASSWORD FOR root=PASSWORD(‘新密码’); mysqladmin -u root -p 旧密码 新密码 一定要注意不要使用弱口令，推荐数字、字母和字符混合使用。 3.4 避免root和端口暴露 不要在代码中使用root账户，同时注意控制MySQL运行账户权限，尽量让其权限最小 内网系统关闭公网访问，避免默认端口直接暴露 启动参数或配置文件中设置bind-address，绑定内网IP 3.5 备份 备份表结构和数据 备份表结构和数据 备份表结构和数据 重要的事情说三遍!!! 4. 总结想想自己能经历这一次数据库勒索还挺有意思的。这一番折腾确实让我感受到网络安全的重要性，同时也增强自己的安全意识。无论是开发公司项目还是个人练手项目都要严谨一些，习惯是慢慢养成的。敬畏每一行代码! 欢迎大家关注😁","link":"/2019/05/28/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A2%AB%E5%88%A0%E9%99%A4%E5%B9%B6%E8%A2%AB%E5%8B%92%E7%B4%A2%E6%AF%94%E7%89%B9%E5%B8%81!%E7%9C%9F%E6%98%AF%E5%85%AD%E4%B8%80%E5%84%BF%E7%AB%A5%E5%8A%AB%E5%95%8A!/"},{"title":"Volley学习第二篇-缓存流程","text":"前文概要 上篇说道Volley初始化的时候需要创建一个RequestQueue消息队列,下面就来看看这个RequestQueue. RequestQueue 是一个队列管理器,里面维护了两个队列—CacheQueue和NetowrkQueue. Volley类里面的newRequestQueue方法中调用了队列的start()方法,就从这个方法入手. public void start() { stop(); // Make sure any currently running dispatchers are stopped. // Create the cache dispatcher and start it. mCacheDispatcher = new CacheDispatcher(mCacheQueue, mNetworkQueue, mCache, mDelivery); mCacheDispatcher.start(); // 这里默认创建4个线程 // Create network dispatchers (and corresponding threads) up to the pool size. for (int i = 0; i &lt; mDispatchers.length; i++) { NetworkDispatcher networkDispatcher = new NetworkDispatcher(mNetworkQueue, mNetwork, mCache, mDelivery); mDispatchers[i] = networkDispatcher; networkDispatcher.start(); } }这里创建了1个CacheDispatcher和4个NetworkDispatcher.CacheDispatcher和4个NetworkDispatcher都是继承了Thread的两个线程,一个是缓存线程,另一个是网络线程. 其中DEFAULT_NETWORK_THREAD_POOL_SIZE中定义了网络线程的个数,可以根据不同的cpu核数来自定义开多少个网络线程(线程数 = cpu核数 * 2 + 1). CacheDispatcher缓存线程的流程它继承了Thread,所以只需要看它的run()方法就好了. while (true) { try { // Get a request from the cache triage queue, blocking until // at least one is available.从缓存队列中不停的取出request,直到队列中只有一个请求的时候阻塞 final Request request = mCacheQueue.take(); request.addMarker(&quot;cache-queue-take&quot;); // If the request has been canceled, don&apos;t bother dispatching it. if (request.isCanceled()) { request.finish(&quot;cache-discard-canceled&quot;); continue;// 请求取消就不读缓存了 } // Attempt to retrieve this item from cache. 从缓存中获取缓存信息的实体 Cache.Entry entry = mCache.get(request.getCacheKey()); if (entry == null) { request.addMarker(&quot;cache-miss&quot;); // Cache miss; send off to the network dispatcher. mNetworkQueue.put(request);// 缓存木有,将请求添加到网络请求队列 continue; } // If it is completely expired 过期, just send it to the network. if (entry.isExpired()) { request.addMarker(&quot;cache-hit-expired&quot;); request.setCacheEntry(entry); mNetworkQueue.put(request);// 缓存过期,添加到网络请求队列 continue; } // We have a cache hit; parse its data for delivery back to the request. request.addMarker(&quot;cache-hit&quot;); // 解析网络数据 这个是由请求对象request来解析的 // 文档中说道:request对象负责请求和解析网络请求 Response&lt;?&gt; response = request.parseNetworkResponse( new NetworkResponse(entry.data, entry.responseHeaders)); request.addMarker(&quot;cache-hit-parsed&quot;); if (!entry.refreshNeeded()) {// 缓存是否需要刷新 // Completely unexpired cache hit. Just deliver the response. mDelivery.postResponse(request, response);// 无需刷新,直接分发 } else { // Soft-expired cache hit. We can deliver the cached response, // but we need to also send the request to the network for // refreshing. request.addMarker(&quot;cache-hit-refresh-needed&quot;); request.setCacheEntry(entry);// 更新缓存 // Mark the response as intermediate.// 中间 媒介 response.intermediate = true; // Post the intermediate response back to the user and have // the delivery then forward the request along to the network. mDelivery.postResponse(request, response, new Runnable() { @Override public void run() { try { mNetworkQueue.put(request); } catch (InterruptedException e) { // Not much we can do about this. } } }); } } catch (InterruptedException e) { // We may have been interrupted because it was time to quit. if (mQuit) { return; } continue; } }缓存的主体流程就在这个死循环里面,Volley的dispatcher的原理和Handler里面的looper的原理非常相似. 读取缓存分发到主线程Response&lt;?&gt; response = request.parseNetworkResponse(new NetworkResponse(entry.data, entry.responseHeaders)); request.addMarker(&quot;cache-hit-parsed&quot;); if (!entry.refreshNeeded()) { // Completely unexpired cache hit. Just deliver the response. mDelivery.postResponse(request, response); } else { // Soft-expired cache hit. We can deliver the cached response, // but we need to also send the request to the network for // refreshing. request.addMarker(&quot;cache-hit-refresh-needed&quot;); request.setCacheEntry(entry); // Mark the response as intermediate.// 中间 媒介 response.intermediate = true; // Post the intermediate response back to the user and have // the delivery then forward the request along to the network. mDelivery.postResponse(request, response, new Runnable() { @Override public void run() { try { mNetworkQueue.put(request); } catch (InterruptedException e) { // Not much we can do about this. } } }); }详解request.parseNetworkResponse(new NetworkResponse(entry.data, entry.responseHeaders));`entry.data是缓存的原始的byte数组,将byte数组和响应头封装成一个NetworkResponse对象(Volley里面的网络响应的统一对象).parseNetworkResponse()方法将NetworkResponse对象解析成Response供各种泛型的转换. mDelivery.postResponse(request, response);mDelivery对象时在CacheDispatcher的构造方法的时候赋值的,往上找找RequestQueue中的start()方法中mCacheDispatcher = new CacheDispatcher(mCacheQueue, mNetworkQueue, mCache, mDelivery); 继续找 public RequestQueue(Cache cache, Network network, int threadPoolSize,ResponseDelivery delivery) { mCache = cache; mNetwork = network; mDispatchers = new NetworkDispatcher[threadPoolSize]; mDelivery = delivery; }还找 public RequestQueue(Cache cache, Network network, int threadPoolSize) { this(cache, network, threadPoolSize, new ExecutorDelivery(new Handler(Looper.getMainLooper()))); }看mDelivery就是new ExecutorDelivery(new Handler(Looper.getMainLooper())) ExecutorDelivery中构造方法中有一个非常重要的一行 public ExecutorDelivery(final Handler handler) { // Make an Executor that just wraps the handler. mResponsePoster = new Executor() { @Override public void execute(Runnable command) { handler.post(command); } }; }handler将runnable对象post出去,而handler是通过Looper.getMainLooper创建的,这样就是通过我们用主线程创建的Handler将响应发送到主线程中了. 至此,Volley缓存的读取/分发就完成了. 总结官方图解中的绿色的那部分—缓存线程的流程就结束了. 后面我会慢慢肥西网络线程相关的东西.","link":"/2016/05/23/Android/Volley%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AF%87-%E7%BC%93%E5%AD%98%E6%B5%81%E7%A8%8B/"},{"title":"Docker教程(四)---Dockerfile命令详解","text":"深入docker镜像拉取镜像文件到本地 docker pull centos查看本地镜像： docker images 查找镜像 docker search [镜像名称]构建镜像 1. 使用docker commit 命令 用户名:lujiahao docker commit 容器名称/ID lujiahao/centos-tomcat docker commit -m=&quot;describe&quot; --author=&quot;lujiahao&quot; 容器名称/ID lujiahao/centos-tomcat:test docker inspect lujiahao/centos-tomcat:test 2. 使用docker build命令和Dockerfile文件(推荐) docker build -t=“用户名/镜像名称&quot; . docker build -t=&quot;crxy/centos&quot; . 点表示会在当前目录中找Dockerfile文件 建议创建镜像的时候单独一个目录,然后在写Dockerfile,这个目录叫构建目录.如果目录下面有其他文件,会把目录下所有文件发送给docker的守护进程查看构建的步骤和层级 docker history 用户ID/镜像名执行流程 dockerfile中的指令会按照从上到下执行 docker首先从基础镜像运行一个容器 执行一条指令，对容器进行修改 执行类似docker commit的操作，提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 然后执行dockerfile中的下一条指令，直到所有指令都执行完毕 Dockerfile指令详解 所有指令都必须为大写字母 以#开头的都认为是注释 FROM第一条指令必须是`FROM`(指定使用的基础镜像)MAINTAINER指定镜像的作者信息RUN指定镜像被构建时要运行的命令,默认会使用/bin/bash -c 执行RUN 后面指定的命令 也可以使用RUN [&quot;mkdir&quot;,&quot;a.txt&quot;]EXPOSE告诉docker该容器需要对外开放的端口CMD指定一个容器运行时要执行的命令 docker run -i -t lujiahao/cenos-tomcat /bin/bash 等于在Dockerfile中添加 CMD [&quot;/bin/ps&quot;] 注意：使用 docker run 命令可以覆盖CMD指令ENTRYPOINT与CMD类似，但是ENTRYPOINT指定的命令不会被docker run指定的命令覆盖， 它会把docker run命令行中指定的参数传递给ENTRYPOINT指令中指定的命令当作参数。 ENTRYPOINT [&quot;/bin/ps&quot;] docker run -t -i lujiahao/centos -l ENTRYPOINT 还可以和CMD组合一块来用，可以实现，当用户不指定参数的时候使用默认的参数执行，如果用户指定的话就使用用户提供的参数. ENTRYPOINT [&quot;/bin/ps&quot;] CMD [&quot;-h&quot;] 注意：如果确实要覆盖默认的参数的话，可以在docker run中指定--entrypoint进行覆盖WORKDIRWORKDIR /etc RUN touch a.txt WORKDIR /usr/local RUN touch b.txt 注意：可以在docker run命令中使用-w覆盖工作目录，但是不会影响之前在工作目录中执行的命令ENV设置环境变量，在这设置的环境变量可以在后面的指令中使用，使用$引用 并且这个环境变量也会被持久保存到从我们的镜像创建的任何容器中。可以使用env命令查看 也可以使用docker run 命令行的-e参数来传递环境变量，这些变量只在运行时有效 -e JAVA_HOME=/usr/localUSER(了解)可以指定以什么用户去运行这个容器 USER ftp（用户信息：查看/etc/group） 还可以使用其他组合方式 USER 用户名/UID:组/GID（用户名/UID和组/GID可以单独指定或者组合） 不指定的话默认就是root用户ADDADD指令用来将构建目录下的指定文件复制到镜像中(注意只能是构建目录下面的文件) ADD a.txt /etc/a.txt ADD 在添加压缩文件的时候会把压缩文件自动解压。(gzip bzip2 xz),如果目的位置已经存在了和压缩文件同名的文件或者目录，那么这些文件将会被覆盖。COPYCOPY和ADD类似，但是COPY命令不会对压缩文件进行解压，只负责复制。 如果目的位置不存在，docker会自动创建所有需要的目录，就像使用make -p一样 注意：使用COPY和ADD的命令的时候，复制的源文件必须在当前构建环境之内，也就是和Dockerfile同一目录，否则会找不到。ONBUILD这个指令能为镜像添加触发器，当一个镜像被用作其他镜像的基础镜像时， 该镜像中的触发器将会执行。这个触发器所指定的命令会在FROM指令之后执行。 ONBUILD ADD . /usr/local 先在一个镜像中添加这个触发器，再使用这个镜像作为基础镜像创建一个镜像， 会发现在FROM指令之后就开始执行基础镜像中设置的触发器中的指令了。启动一个容器可以查看效果。 注意：触发器只能被继承一次。 有一些命令是不能在ONBUILD中指定的。包括FROM,MAINTAINER,ONBUILD,这样是为了防止在构建过程中产生递归调用的问题。.dockerignore在执行build的时候忽略掉不需要的文件。 在Dockerfile同目录下创建.dockerignore,将要忽略的文件填到里面即可.VOLUME可以理解为设置(共享目录，磁盘挂载),添加到容器中,并没有真正提交到镜像文件中 这个指令用来向基于镜像创建的容器添加卷，一个卷可以存在于一个或者多个容器内的特定的目录。 卷的特点 1：卷可以在容器间共享和重用 2：对卷的修改是立刻生效的 3：对卷的修改不会对更新镜像产生影响 4：卷会一直存在直到没有任何容器再使用它。 卷功能可以让我们将一些数据添加到镜像中而不是将将这个内容提交到镜像中。并且允许我们在多个容器间共享这些内容。 格式：VOLUME [&quot;/usr/projrct&quot;] 还可以一次指定多个VOLUME [&quot;/usr/project&quot;,&quot;/data&quot;] 创建数据卷 VOLUME [&quot;/usr/projrct&quot;] 或者在启动容器的时候创建docker run -it -v /webapp centos /bin/bash 注意：默认情况下，如果只是声明数据卷而没有映射到宿主机上的具体目录，docker会在/var/lib/docker/vfs/dir/ 目录下分配一个具有唯一名字的目录给该数据卷。通过docker inspect 命令可以查看具体路径 指定宿主主机目录作为数据卷 宿主机目录:容器目录 docker run -it -v /usr/local/webapp:/webapp centos /bin/bash 注意：如果容器内部已经存在webapp目录，那么目录中的文件将会被覆盖。 默认情况下，数据卷是具有读写权限，rw权限，可以改为只读权限,ro docker run -it -v /usr/local/webapp:/webapp:ro centos /bin/bash 使用场景: 容器里面的tomcat/webapps/目录和本地宿主机的目录对应上,本地修改代码后, 直接重启容器即可(如果是html连重启都不用了),相当于一个动态部署.镜像操作docker的构建缓存 由于每一步的构建过程都会将结果提交为镜像，所以docker的构建镜像过程就显得非常聪明，它会将之前的镜像层看作缓存。再进行重新构建时会从第一条发生了变化的指令开始，前面的都使用缓存 不使用构建缓存的两种方式: 可以使用 --no-cache 参数来指定不使用缓存功能 一般会在dockerfile中使用ENV指令设置一个时间(ENV CREATE_TIME 2015-01-01),写在FROM下面,这样只要一改了这个就不会使用构建缓存了 容器端口映射默认情况下docker不会自动打开这些端口，必须在运行容器的时候指定-P(大写)参数，这样就可以打开expose指定的所有端口。 会随机映射到宿主机的一个端口上 EXPOSE指令可以同时指定一个或多个需要对外开放的端口 expose 80 8080 6379对外开放端口的两种方式 -P(大写) 这样的话会将dockerfile文件中EXPOSE 指令指定的所有端口一并公开 -p(小写)可以手工指定需要对外公开的端口如果没有使用expose指定需要对外开放的端口，还可以在启动容器的时候动态指定，使用-p(小写)参数 -p 80(docker会在宿主机上随机选择一个位于49000~49900内未被使用的端口来映射到容器中的80端口上) -p 8080:8080(把宿主机上的8080端口映射到容器的8080端口) 前面的表示宿主机 -p 80:80 -p 8080:8080 同时指定多个使用docker ps 可以查看容器的端口分配情况 或者使用docker port 容器ID/名称查看 推送镜像到Docker Hub(需要先登录：docker login)docker push 用户ID/镜像名(docker 1.6以下版本这样使用) docker1.6需要使用下面命令才能推送 docker tag image_id docker.io/login_name/image_name docker push docker.io/login_name/image_name 推送可能会报错，cdn-registry-1.docker.io: no such host 是因为网络问题、重试几次。删除镜像docker rmi 用户ID/镜像名 或者docker rmi `docker images -a -q` 删除所有未打标签的镜像 docker rmi -f $(docker images --filter &apos;dangling=true&apos;)","link":"/2017/02/28/Docker%E6%95%99%E7%A8%8B/Docker%E6%95%99%E7%A8%8B-%E5%9B%9B-Dockerfile%E8%AF%A6%E8%A7%A3/"},{"title":"08.JavaWeb基础-Response-Request","text":"1.Response1.1 响应行setStatus(int status);// 设置状态码1.2 响应头setHeader(String name, String value) 设置指定的头，一般常用。 例如：setHeader(&quot;location&quot;,&quot;http://www.itheima.com&quot;); setDateHeader(String name, long date) 设置时间的 这里使用long的原因是因为 : new Date().getTime()的返回值是long setIntHeader(String name, int value) 设置整型 例如：setIntHeader(&quot;expires&quot;, 1000) 设置过期时间的(缓存页面时间)。0表示不缓存现代浏览器不好使 拓展 : 重定向 方式1： 使用302状态码和location请求头来实现 response.setStatus(302); response.setHeader(&quot;location&quot;, &quot;1.html&quot;); response.setHeader(&quot;location&quot;, &quot;/day08/1.html&quot;); 方式2: response.sendRedirect(&quot;1.html&quot;); 备注: 使用refresh跳转也能实现和重定向相同的效果 两次访问的状态码都是200 （有可能第二个304 读取浏览器缓存） 格式：秒 --&gt; 指定秒数刷新当前页面 response.setHeader(&quot;refresh&quot;, &quot;2&quot;); 格式：秒;url=&quot;&quot; --&gt; 指定秒之后跳转到指定的url response.setHeader(&quot;refresh&quot;, &quot;0;url=1.html&quot;);1.3 响应体Response提供字符流和字节流.一般情况，如果是流，必须关闭流。但servlet中如果使用可以不关闭如果没有关闭流，tomcat在请求结束时，将自动的关闭注意：response 的两个流不能同时使用 1.3.1 字节流ServletOutputStream out = response.getOutputStream(); out.println(&quot;1234&quot;); //out.print(&quot;哈哈&quot;); //异常：不能直接发送中文 out.write(&quot;哈哈&quot;.getBytes(&quot;UTF-8&quot;)); //有可能乱码 -- tomcat发送的字节，tomcat本身没有处理，是否乱码取决于浏览器查看方式编码发送响应体，即发送html源码如果println()将html源码进行回车换行，如果希望页面的显示要换行&lt;br/&gt; tomcat默认编码使用：ISO-8859-1 （英文） 1.3.2 字符流如果发送的字符，tomcat将处理字符，默认使用ISO-8859-1编码处理请求体内容。 2.1 通知tomcat发送的数据编码 -- 注意必须在使用流之前 response.setCharacterEncoding(&quot;UTF-8&quot;); 注意：只通知tomcat，但不控制浏览器行为 2.2 通过tomcat和浏览器 --强制要求浏览器查看编码 方式1：手动方案 response.setHeader(&quot;content-type&quot;, &quot;text/html;charset=UTF-8&quot;); 方式2：使用api【】 response.setContentType(&quot;text/html;charset=UTF-8&quot;); 2.3 通知tomcat，在使用html&lt;meta&gt;通知浏览器 (html源码) 注意：&lt;meta&gt;建议浏览器应该使用编码，不能强制要求。1.3.3 response输出缓存response中使用流向浏览器发送数据，首先数据将写入数据流的缓存中，但缓存大小8k时，将自动刷新到浏览器。 isCommitted() 缓存是否刷新过 flushBuffer() 手动的刷新 输出缓存 getBufferSize() 获得大小 resetBuffer() 清空缓存 // 输出缓存8kb System.out.println(response.isCommitted()); //输出false表示缓存没有提交 for(int i = 0 ; i &lt; 1024 * 8 ; i ++){ response.getOutputStream().print(&quot;a&quot;); } System.out.println(response.isCommitted()); //输出false表示缓存没有提交 // 但是此时缓存已经满了 response.getOutputStream().print(&quot;a&quot;); System.out.println(response.isCommitted());//输出true表示缓存溢出了,提交了 //手动刷新 System.out.println(response.isCommitted()); response.getOutputStream().print(&quot;a&quot;); //response.flushBuffer(); //刷新response 输出缓存 //response.getOutputStream().flush(); //刷新使用的流缓存,也能达到刷新缓存的效果 response.getOutputStream().close(); System.out.println(response.isCommitted());2.Request2.1 相关API实际访问路径 http://localhost:8080/day08/Demo05Servlet?username=jack&amp;password=1234 //1 统一资源标记符 。例如： /day08/Demo05Servlet String uri = request.getRequestURI(); //2统一资源定位符：例如：http://localhost:8080/day08/Demo05Servlet StringBuffer url = request.getRequestURL(); //3 协议和版本 ， 例如： HTTP/1.1 String protocol = request.getProtocol(); //协议，例如： http String scheme = request.getScheme(); //4 主机（域名） , 例如：localhost ，如果使用ip地址，就显示ip String serverName = request.getServerName(); //5 端口 , 例如：8080 int port = request.getServerPort(); //6 发布到tomcat下的项目名称 【】 String contextPath = request.getContextPath(); //7 servlet路径 , 例如：/Demo05Servlet【】 String servletPath = request.getServletPath(); //8 所有请求参数，及？之后所有 ,例如： username=jack&amp;password=1234 String queryString = request.getQueryString(); //9远程主机的ip地址【】 String remoteAddr = request.getRemoteAddr(); jsp中常写的这段代码 String path = request.getContextPath(); String basePath = request.getScheme() + &quot;://&quot; + request.getServerName() + &quot;:&quot; + request.getServerPort() + path + &quot;/&quot;;2.2 Request获取参数// 获取单个参数 String username = request.getParameter(&quot;username&quot;); // 获取一组参数 String[] loves = request.getParameterValues(&quot;loves&quot;); // 获取所有的参数 Map&lt;String, String[]&gt; allDataMap = request.getParameterMap();2.3 乱码处理public class Demo07Servlet extends HttpServlet { public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //get请求 //1 获得内容 String username =request.getParameter(&quot;username&quot;); String userpwd = request.getParameter(&quot;userpwd&quot;); //2 get请求乱码处理 username = new String(username.getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;); userpwd = new String(userpwd.getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;); System.out.println(username); System.out.println(userpwd); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //0处理post请求 乱码 request.setCharacterEncoding(&quot;UTF-8&quot;); //1 获得内容 String username =request.getParameter(&quot;username&quot;); System.out.println(username); String userpwd = request.getParameter(&quot;userpwd&quot;); System.out.println(userpwd); } }这里的乱码处理方式还是非常小儿科的,后面会学习Filter来全局统一处理GET和POST乱码了 2.4 RequestDispatcher 请求调度对象2.4.1 请求转发forward(ServletRequest request, ServletResponse response) A 转发 B，只输出B内容到浏览器。（如果A没有数据发送 response.isComitted = false，将清空缓存） 请求转发只输出最后一个servlet内容 如果 isCommitted = true ，在进行forward将抛异常。一般情况如果输出少量的数据，认为isCommitted=false2.4.2 请求包含include(ServletRequest request, ServletResponse response) A 包含 B，先输出A内容到浏览器，在输出B的内容到浏览器。 请求包含，输出所有servlet 汇总后的内容。2.4 请求转发和重定向对比浏览器发送请求，可能涉及多个页面。示意图 : 请求次数 转发：1次 重定向：2次 浏览器地址栏是否改变 转发：不改变 重定向：改变 request作用域数据是否共享 转发：共享（两个request对象，但数据共享的（克隆）） 重定向：不共享（创建两个新的request对象，且没有关系的） api使用 转发：request.getRequestDispatcher(&quot;....&quot;).forward(request,response); -- 让当次请求继续延续下去。 重定向：请求通过浏览器改变方法。response.sendRedirect(&quot;location&quot;) 使用范围 转发：只能在当前web项目中转发，不能转发到另一个web项目中，/表示web项目根。 例如：D:\\java\\tomcat\\apache-tomcat-7.0.53\\webapps\\day08 request.getRequestDispatcher(&quot;/a/b/oneServlet&quot;).forward() http://localhost:8080/day08/a/b/oneServlet 重定向：改变方向任意。如果重定向到当前tomcat下，/表示web站点 例如：D:\\java\\tomcat\\apache-tomcat-7.0.53\\webapps\\ response.sendRedirect(&quot;/a/b/oneServlet&quot;); http://localhost:8080/a/b/oneServlet 这里如果想要达到和上面的一样的访问路径就需要加上项目名称`/day08/a/b/oneServlet` 3.总结1.web项目根：(context root) 开发：G:\\Workspaces\\hei16\\day08\\WebRoot\\ 运行：D:\\java\\tomcat\\apache-tomcat-7.0.53\\webapps\\day08\\ 2. web站点根： 运行：D:\\java\\tomcat\\apache-tomcat-7.0.53\\webapps\\ 3.编码 页面（html、jsp）、servlet 请求和响应 编码 必须保持一致。 一般情况下：servlet开始2段内容 request.setCharacterEncoding(&quot;UTF-8&quot;); response.setContentType(&quot;text/html;charset=UTF-8&quot;); 4.请求转发特点 * 请求路径没有改变，但可以涉及服务器端多个资源（你和媳妇） * 可以在一次请求中，共享request作用域的数据。 * 一次请求，使用请求转发，tomcat将创建两个request，和一个response对象 两个request对象数据相同的（可以理解成对象被克隆了）","link":"/2016/11/21/JavaWeb%E5%9F%BA%E7%A1%80/08-JavaWeb%E5%9F%BA%E7%A1%80-Request-Response/"},{"title":"11-JavaWeb基础-EL-JSTL","text":"EL表达式EL介绍EL（Expression Language） 目的：为了使JSP写起来更加简单。表达式语言的灵感来自于 ECMAScript 和 XPath 表达式语言，它提供了在 JSP 中简化表达式的方法，让Jsp的代码更加简化。 EL基本语法 el格式： ${ 表达式 } 作用： 获得自定义数据：自定义数据必须在作用域中 执行运算 获得servlet的api 调用java方法 el内置对象：11个 4个作用域：pageScope、requestScope、sessionScope、applicationScope pageContext ，表示的就是jsp PageContext对象 param 一个请求参数 ${param.username} request.getParameter(&quot;username&quot;); paramValues 一组 ${paramValues.loves} request.getParameterValues(&quot;loves&quot;); header 一个头 ${header.referer} request.getHeader(&quot;referer&quot;); headerValues 一组头 ${header.cookie} request.getHeaders(&quot;cookie&quot;); cookie 获得cookie对象 initParam web项目初始化参数， servletContext.getInitParameter(&quot;xxx&quot;); 语法列表 代码详细 : https://github.com/chiahaolu/JavaEEDemo/blob/master/day11_el_jstl_ums/web/el_base.jsp EL函数在JSP页面中引用系统函数库 &lt;%@taglib uri=&quot;http://java.sun.com/jsp/jstl/functions&quot; prefix=&quot;fn&quot; %&gt; 代码 : https://github.com/chiahaolu/JavaEEDemo/blob/master/day11_el_jstl_ums/web/el_function.jsp 自定义EL函数1.确定实现类public class MyFunctions {//如果大于指定长度，截取并显示分隔符 public static String mysub(String str,int length , String split){ if(str == null){ return &quot;&quot;; } if(str.length() &lt;= length){ return str; } return str.substring(0, length) + split; } }2.编写配置文件(WEB-INF目录下编写myfn.tld)&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;taglib xmlns=&quot;http://java.sun.com/xml/ns/j2ee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-jsptaglibrary_2_0.xsd&quot; version=&quot;2.0&quot;&gt; &lt;tlib-version&gt;1.0&lt;/tlib-version&gt; &lt;short-name&gt;myfn&lt;/short-name&gt; &lt;uri&gt;http://www.itheima.com/lt/myfn&lt;/uri&gt; &lt;!-- 定义函数 --&gt; &lt;function&gt; &lt;name&gt;sub&lt;/name&gt;&lt;!-- 访问的名称 --&gt; &lt;!-- 实现类 --&gt; &lt;function-class&gt;com.itheima.b_fn.MyFunctions&lt;/function-class&gt; &lt;!-- 函数签名 String mysub(String str,int length , String split) 签名格式： 返回值 方法名(参数列表)--&gt; &lt;function-signature&gt;java.lang.String mysub(java.lang.String,int,java.lang.String)&lt;/function-signature&gt; &lt;/function&gt; &lt;/taglib&gt;3.jsp页面中引用自定义的函数库&lt;%@taglib uri=&quot;http://www.itheima.com/lt/myfn&quot; prefix=&quot;myfn&quot; %&gt;JSTLJSTL基本介绍 JavaServer Pages Standard Tag Library(JSP标准标签库)，是jsp规范一部分。sun定义规范及接口,apache 对规范进行实现。 导入jar包 myeclipse在发布项目到tomcat时，自动添加jstl.jar包. eclipse需要手动导入jar包. IntellJ将`jstl.jar`和`standard.jar`导入到WEB-INF目录下的lib包下. 使用格式：&lt;前缀:标签名 属性=值 /&gt; 标签库分类: 导入方式: &lt;%@taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt; 标签介绍核心库标签 out标签 将制定内容输出到浏览器,默认支持EL表达式. 主要用途:将html源码进行转义. escapeXml:表示是否转义,默认值:true &lt;c:out value=&quot;abc&quot;&gt;&lt;/c:out&gt;&lt;br/&gt; &lt;c:out value=&quot;${empty user }&quot;&gt;&lt;/c:out&gt;&lt;br/&gt; &lt;c:out value=&quot;&lt;a&gt;你敢点我&lt;/a&gt;&quot; escapeXml=&quot;false&quot;&gt;&lt;/c:out&gt;&lt;br/&gt; set标签 给指定的作用域设置内容 value 设置值 var 属性名称 scope 作用域 (page/request/session/application 这里的名字和el表达式的不一样) 相当于 : pageContext.setAttribute(var,value,scope) &lt;c:set value=&quot;request_屌&quot; var=&quot;dzd&quot; scope=&quot;request&quot; &gt;&lt;/c:set&gt; &lt;c:remove var=&quot;dzd&quot; scope=&quot;page&quot;/&gt; &lt;%--移除作用域内容 如果没写scope就依次移除 --%&gt; ${dzd} &lt;%--依次从四个作用域中获取 page、request、session、application --%&gt; &lt;br/&gt; ${requestScope.dzd } &lt;br/&gt; if标签 if(test){ 标签体 } 登录的案例改进: &lt;c:set var=&quot;loginUser&quot; value=&quot;xxx&quot; scope=&quot;session&quot;&gt;&lt;/c:set&gt; &lt;c:if test=&quot;${not empty sessionScope.loginUser }&quot;&gt; 欢迎，xxx &lt;/c:if&gt; &lt;c:if test=&quot;${empty sessionScope.loginUser }&quot;&gt; &lt;a href=&quot;&quot;&gt;登录&lt;/a&gt; &lt;/c:if&gt; choos标签 &lt;c:choose &gt;相当于 switch &lt;c:when&gt; 相当于 case &lt;c:otherwise&gt; 相当于 default forTokens标签(不常用) 将自定字符串，安装指定符号进行分割，并遍历。 &lt;c:forTokens items=&quot;www.itheima.com&quot; delims=&quot;.&quot; var=&quot;s&quot;&gt; ${s} , &lt;br/&gt; &lt;/c:forTokens&gt; catch标签(不常用) &lt;c:catch&gt; 等效 try{}catch{} url标签(常用) &lt;%-- &lt;c:url valur=&quot;&quot; var=&quot;&quot; scope=&quot;&quot;&gt; value设置url，如果/开头，自动添加项目名。 如果没有设置var，将直接输出到浏览器，如果设置var，将保存到指定(scope)的作用域，默认page --%&gt; &lt;a href=&quot;${pageContext.request.contextPath}/c_core3.jsp&quot;&gt;当前页面&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;&lt;c:url value=&apos;/c_core3.jsp&apos;/&gt;&quot;&gt;当前页面&lt;/a&gt; &lt;br/&gt; &lt;c:url value=&apos;/c_core3.jsp&apos; var=&quot;baseUrl&quot; &gt; &lt;c:param name=&quot;username&quot; value=&quot;凤儿&quot;&gt;&lt;/c:param&gt; &lt;%--自动进行url编码 --%&gt; &lt;/c:url&gt; &lt;a href=&quot;${baseUrl}&quot;&gt;当前页面&lt;/a&gt; &lt;br/&gt; redirect标签 &lt;%--重定向 ，url设置重定向位置 如果/开头，不需要项目名称 &lt;c:redirect url=&quot;/index.jsp&quot;&gt;&lt;/c:redirect&gt; --%&gt; forEach标签 items 用于设置需要遍历的内容 如果字符串，将直接输出 如果数组和List，遍历每一项 如果Map，遍历每一项Map.Entry begin/end 这和items只能存在一组 var 用于存放遍历每一项内容,存放page作用域，只能在循环体中使用。 fmt标签&lt;%--格式化 时间 --%&gt; &lt;% pageContext.setAttribute(&quot;date&quot;, new Date()); //new SimpleDateFormat() %&gt; &lt;fmt:formatDate value=&quot;${date}&quot; pattern=&quot;yyyy-MM-dd hh:mm:ss:SSS&quot;/&gt; &lt;br/&gt; &lt;fmt:formatNumber value=&quot;3.1415926&quot; pattern=&quot;#.##&quot;&gt;&lt;/fmt:formatNumber&gt; &lt;br/&gt; &lt;fmt:formatNumber value=&quot;3&quot; pattern=&quot;#.##&quot;&gt;&lt;/fmt:formatNumber&gt; &lt;br/&gt; &lt;fmt:formatNumber value=&quot;3&quot; pattern=&quot;0.00&quot;&gt;&lt;/fmt:formatNumber&gt; &lt;br/&gt;自定义标签1.编写实现类要求：自定义的类需要实现接口`SimpleTag`或者继承类`SimpleTagSupport` 传统标签：实现接口Tag，继承类TagSupport，功能更强大，但实现繁琐。 简单标签：接口SimpleTag，继承SimpleTagSupport ，在jsp2.0之后提供 提供标记接口父类：JspTag 一般实现类是以Tag结尾的,表明它是一个标签类 例如:MyDateTag public class MyContentTag extends SimpleTagSupport { private boolean show; public void setShow(boolean show) { this.show = show; } @Override public void doTag() throws JspException, IOException { if(show){ this.getJspBody().invoke(null);//执行标签体，并输出到浏览器 } //throw new SkipPageException();//当前标签之后的内容将不再执行 } }2.编写tld配置文件tld是taglib description 的缩写 ， 标签类库的描述文件，是jsp解析程序可以通过配置文件获得相应的实现类 tld文件基于xml文件，扩展名为tld，内容xml tld位置： 1.WEB-INF目录，及子目录，但 classes、lib目录除外 2.WEB-INF/lib/*.jar/META-INF/目录下，jar文件内 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;taglib xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-jsptaglibrary_2_1.xsd&quot; version=&quot;2.1&quot;&gt; &lt;!-- 标签库的版本 --&gt; &lt;tlib-version&gt;1.0&lt;/tlib-version&gt; &lt;!-- 建议使用前缀名称 --&gt; &lt;short-name&gt;my&lt;/short-name&gt; &lt;!-- 引用标签库时，使用名称，建议使用：url作为名称，可以任意 --&gt; &lt;uri&gt;http://www.itheima.com/lt/mytag&lt;/uri&gt; &lt;!-- 配置标签 --&gt; &lt;tag&gt; &lt;!-- 标签访问名称 --&gt; &lt;name&gt;date&lt;/name&gt; &lt;!-- 标签的实现类 --&gt; &lt;tag-class&gt;com.itheima.e_tag.MyDateTag&lt;/tag-class&gt; &lt;!-- 标签体内容设置 --&gt; &lt;body-content&gt;empty&lt;/body-content&gt; &lt;!-- empty 没有标签体 --&gt; &lt;/tag&gt; &lt;tag&gt; &lt;name&gt;date2&lt;/name&gt; &lt;tag-class&gt;com.itheima.e_tag.MyDateTag2&lt;/tag-class&gt; &lt;body-content&gt;empty&lt;/body-content&gt; &lt;!-- &lt;attribute&gt; : 用于设置属性，确定实现类执行的setter方法 &lt;name&gt; ： 属性名称--&gt; &lt;attribute&gt; &lt;name&gt;pattern&lt;/name&gt; &lt;/attribute&gt; &lt;/tag&gt; &lt;tag&gt; &lt;name&gt;content&lt;/name&gt; &lt;tag-class&gt;com.itheima.e_tag.MyContentTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;!-- scriptless：不支持jsp脚本&lt;% %&gt;,支持el函数和其他标签 --&gt; &lt;attribute&gt; &lt;name&gt;show&lt;/name&gt; &lt;!-- 用于配置标签是否支持运行时表达式的。及el表达式 --&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;/tag&gt; &lt;/taglib&gt;3.在jsp中引用配置文件,使用标签&lt;%@taglib uri=&quot;http://www.itheima.com/lt/mytag&quot; prefix=&quot;my&quot; %&gt;简单标签的生命周期 创建标签实例 设置PageContext，执行setJspContext() 每一个属性setter方法，执行 setPattern() 如果有标签体，执行setJspBody() 执行doTag() 执行标签体 this.getJspBody().invoke(null) ; 输出到浏览器。 在doTag()方法体中，throw SkipPageException() 异常 可以阻止当前标签之后内容的输出。","link":"/2016/12/12/JavaWeb%E5%9F%BA%E7%A1%80/11-JavaWeb%E5%9F%BA%E7%A1%80-EL-JSTL/"},{"title":"AJAX笔记","text":"Ajax介绍&amp;编写流程使用异步的方式从浏览器端发送请求，请求服务器端资源，并获得内容一种技术。ajax 不是新技术，是多个技术整合：javascript、html、css、xml，XMLHttpRequest 使用步骤: 1.获得核心类（引擎） 2.编写回调函数，获得响应内容 3.建立连接 4发送请求同步操作 : 访问servlet地址栏改变异步操作 : 访问servlet地址栏不改变 Jsonlib需要导入的jar包: commons-beanutils-1.8.3.jar commons-collections-3.2.1.jar commons-lang-2.6.jar commons-logging-1.1.1.jar ezmorph-1.0.6.jar json-lib-2.4-jdk15.jarJava对象转json: JSONArray.fromObject(javaObject).toString()Json转Java对象: JSONObject obj = JSONObject.fromObject(jsonStr); Bean bean = (Bean) JSONObject.toBean(obj, Bean.class);注意: JsonConfig配置信息,设置排除的字段 User user = new User(&quot;u001&quot;, &quot;jack&quot;, &quot;1234&quot;); // 配置信息 --设置排除 JsonConfig jsonConfig = new JsonConfig(); jsonConfig.setExcludes(new String[]{&quot;username&quot;,&quot;password&quot;}); // java 对象 转换 json --&gt; {&apos;k&apos;:&apos;v&apos;,.....} String str = JSONObject.fromObject(user,jsonConfig).toString(); System.out.println(str);// {&quot;id&quot;:&quot;u001&quot;}XStream需要导入的jar包: xmlpull-1.1.3.1.jar xpp3_min-1.1.4c.jar xstream-1.4.7.jarJava对象转xml: public void demo02(){ User user = new User(&quot;u007&quot;, &quot;路家豪&quot;, &quot;123&quot;); //1 核心类 XStream xStream = new XStream(); // * 设置别名,如果不设置的话会使用User类的全限定类名来作为根元素 xStream.alias(&quot;user&quot;, User.class); //2 转换成xml String xmlData = xStream.toXML(user); System.out.println(xmlData); /* * &lt;user&gt; &lt;id&gt;u007&lt;/id&gt; &lt;username&gt;路家豪&lt;/username&gt; &lt;password&gt;123&lt;/password&gt; &lt;/user&gt; */ } 设置属性的值: public void demo03(){ User user = new User(&quot;u007&quot;, &quot;路家豪&quot;, &quot;123&quot;); //1 核心类 XStream xStream = new XStream(); // * 设置元素别名 xStream.alias(&quot;user&quot;, User.class); // * 设置属性别名 , 三个参数分别标售:指定javabean/property属性名/xml中显示的属性名 xStream.aliasAttribute(User.class, &quot;id&quot;, &quot;id&quot;); //2 转换成xml String xmlData = xStream.toXML(user); System.out.println(xmlData); /* * &lt;user id=&quot;u007&quot;&gt; &lt;username&gt;路家豪&lt;/username&gt; &lt;password&gt;123&lt;/password&gt; &lt;/user&gt; */ } 忽略字段: public void demo06(){ User user = new User(&quot;u007&quot;, &quot;路家豪&quot;, &quot;123&quot;); //1 核心类 XStream xStream = new XStream(); // * 设置元素别名 xStream.alias(&quot;user&quot;, User.class); // * 设置属性别名 , 指定javabean property 使用其他别名 xStream.aliasAttribute(User.class, &quot;id&quot;, &quot;id&quot;); // * 忽略指定的字段 xStream.omitField(User.class, &quot;username&quot;); //2 转换成xml String xmlData = xStream.toXML(user); System.out.println(xmlData); /* * &lt;user id=&quot;u007&quot;&gt; &lt;password&gt;123&lt;/password&gt; &lt;/user&gt; */ }xml转Java对象: public void demo04(){ String str = &quot;&lt;user id=&apos;u007&apos;&gt;&lt;username&gt;路家豪&lt;/username&gt;&lt;password&gt;123&lt;/password&gt;&lt;/user&gt;&quot;; //1 核心类 XStream xStream = new XStream(); // * 设置元素别名 xStream.alias(&quot;user&quot;, User.class); // * 设置属性别名 , 指定javabean property 使用其他别名 xStream.aliasAttribute(User.class, &quot;id&quot;, &quot;id&quot;); //2 xml转换成 javabean User user = (User)xStream.fromXML(str); System.out.println(user); }案例一:判断用户名是否存在html代码: &lt;input id=&quot;name&quot; type=&quot;text&quot; name=&quot;name&quot; onblur=&quot;sendData(this)&quot; onfocus=&quot;document.getElementById(&apos;spanId&apos;).innerHTML=&apos;&apos;&quot;/&gt; &lt;span id=&quot;spanId&quot;&gt;&lt;/span&gt;js代码: &lt;script type=&quot;text/javascript&quot;&gt; function sendData(obj) { // 0.获得输入的数据 var inputValue = obj.value; /* 1 创建核心类 XMLHttpRequest ajax引擎，不同的浏览器对此对象的创建方式不同。存在浏览器兼容问题 * 在所有现代浏览器中（包括 IE 7）： xmlhttp=new XMLHttpRequest() * 在 Internet Explorer 5 和 6 中： xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;) */ var xmlhttp = null; if (window.XMLHttpRequest) {// code for all new browsers xmlhttp = new XMLHttpRequest(); } else if (window.ActiveXObject) {// code for IE5 and IE6 xmlhttp = new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;); } /* 2 设置回调函数，通过属性设置 onreadystatechange * 目的：发送请求之后可以获得服务器响应内容。 * 一般情况使用匿名函数实现 * ajax引擎在不同的阶段都会调用回调函数。 * 属性：readyState 和 stauts 2.1 readyState 返回整形数据，表示当前执行某一个阶段。 * 0 初始化状态。核心对象创建时默认值 * 1 open() 方法已调用，连接创建完成之后，ajax引擎将此状态修改1 * 2 send() 方法已调用，发送请求 * 3 接受中， 所有响应头部都已经接收到。响应体开始接收但未完成。 * 4 响应已经完全接收。【掌握】--服务器发送的所有数据，已经到ajax引擎内部。 2.2 status 表示 响应的http状态码 * 200 正常【掌握】 * 302 重定向 * 304 缓存 * 404 不存在 * 500 服务器异常 */ xmlhttp.onreadystatechange = function () { if (xmlhttp.readyState == 4 &amp;&amp; xmlhttp.status == 200){ // 3.1 接收服务器响应的数据,获得json数据,注意json也是文本 var data = xmlhttp.responseText; // 3.2 将字符串转化成json对象 使用格式:eval(&quot;(&apos;abc&apos;)&quot;); var jsonData = eval(&quot;(&quot;+data+&quot;)&quot;); // 3.3 判断 控制按钮是否可用 var buttonObj = document.getElementById(&quot;buttonId&quot;); var spanObj = document.getElementById(&quot;spanId&quot;); if (jsonData.flag) {// 可用 buttonObj.removeAttribute(&quot;disabled&quot;); spanObj.style.color = &quot;#3D882D&quot;; } else {// 不可用 buttonObj.setAttribute(&quot;disabled&quot;,&quot;disabled&quot;); spanObj.style.color = &quot;#CC0000&quot;; } // 3.4 将信息显示到指定位置 spanObj.innerHTML = jsonData.msg; } }; //3 建立连接 xmlhttp.open(&quot;POST&quot;,&quot;${pageContext.request.contextPath}/CustomerServlet?method=checkName&quot;); // 4 POST请求需要设置编码 xmlhttp.setRequestHeader(&quot;content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); //5 发送请求 格式: name=lujiahao&amp;password=1234 xmlhttp.send(&quot;name=&quot; + inputValue); } &lt;/script&gt;Servlet端代码: /** * Ajax查询用户名是否存在 */ private void checkName(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException{ // 0响应乱码 response.setContentType(&quot;application/json;charset=UTF-8&quot;); try { // 1.获得数据并封装 String name = request.getParameter(&quot;name&quot;); // 2.通知service查询所有 //CustomerServeice customerServeice = new CustomerServiceImpl(); // customerServeice.checkName(name); PrintWriter out = response.getWriter(); if (name == null || &quot;&quot;.equals(name)) { out.print(&quot;{&apos;flag&apos;:false,&apos;msg&apos;:&apos;用户名不能为空&apos;}&quot;); return; } else if (&quot;lujiahao&quot;.equals(name)) { out.print(&quot;{&apos;flag&apos;:false,&apos;msg&apos;:&apos;用户名已经存在&apos;}&quot;); } else { out.print(&quot;{&apos;flag&apos;:true,&apos;msg&apos;:&apos;用户名可用&apos;}&quot;); } } catch (Exception e){ // 1.打印日志 e.printStackTrace(); } }案例二:省市县三级联动","link":"/2016/07/28/JavaWeb%E5%9F%BA%E7%A1%80/AJAX%E7%AC%94%E8%AE%B0/"},{"title":"09.JavaWeb基础-cookie-session","text":"1.会话技术 会话可简单理解为：用户开一个浏览器，点击多个超链接（多次请求），访问服务器多个web资源，然后关闭浏览器，整个过程称之为一个会话。 会话技术： cookie：浏览器端会话技术 session：服务器端会话技术 目的：在一次会话中（多次请求）共享数据。 3 cookie技术 cookie技术不局限java，其他语言也支持。例如：php、javascript等 JavaEE 规范提供工具类对Cookie进行操作。javax.servlet.http.Cookie类 cookie 是什么 1. servlet创建cookie，保存少量数据，发送浏览器。 2. 浏览器获得服务器发送的cookie数据，将自动的保存到浏览器端。 3. 下次访问时，浏览器将自动携带cookie数据发送给服务器。 cookie操作 1.创建cookie：new Cookie(name,value) 2.发送cookie到浏览器：HttpServletResponse.addCookie(Cookie) 3.servlet接收cookie：HttpServletRequest.getCookies() 浏览器发送的所有cookie cookie特点 每一个cookie文件大小：4kb ， 如果超过4kb浏览器不识别 一个web站点（web项目）：发送20个 一个浏览器保存总大小：300个 cookie 不安全，可能泄露用户信息。浏览器支持禁用cookie操作。 默认情况生命周期：与浏览器会话一样，当浏览器关闭时cookie销毁的。—临时cookie  cookie api getName() 获得名称 getValue() 获得值 setValue(java.lang.String newValue) 设置内容 setMaxAge(int expiry) 设置有效时间【】 setPath(java.lang.String uri) 设置路径【】 setDomain(java.lang.String pattern) 设置域名 , 一般无效，有浏览器自动设置，setDomain(&quot;.itheima.com&quot;) www.itheima.com / bbs.itheima.com 都可以访问 a.b.itheima.com无法访问 isHttpOnly() 是否只是http协议使用。只能servlet的通过getCookies()获得，javascript不能获得。 setComment(java.lang.String purpose) (了解) setSecure(boolean flag) (了解) setVersion(int v) (了解)3.1 路径 cookie默认路径：当前访问的servlet 父路径 例如：http://localhost:8080/day09/a/b/c/SendCookieServlet 默认路径： /day09/a/b/c/ 通过 setPath 修改cookie访问路径，一般使用：setPath(“/“) –web站点的根（没有项目名） 设置路径与servlet访问无关。servlet 去获得cookie有关。 如果编写一个servlet 获得cookie GetCookiesServlet –&gt; getCookies() http://localhost:8080/day09/a/b/c/SendCookieServlet1 –》/day09/a/b/c/ http://localhost:8080/day09/a/b/SendCookieServlet2 –》/day09/a/b/ http://localhost:8080/day09/a/SendCookieServlet3 –》/day09/a/ http://localhost:8080/day09/d/SendCookieServlet4 –》/day09/d 如果此获得cookie 访问路径 http://localhost:8080/day09/a/b/c/ ，使用项目之后内容&quot;/day09/a/b/c/&quot;.startWith(....) 访问的servlet路径，必须与cookie本地设置路径 判断。 通过getCookies()获得 cookie1/cookie2/cookie3 通常使用setPath(&quot;/&quot;) 其他servlet &quot;/day09&quot;.startWith(&quot;/&quot;) 肯定都是/开头。所以可以访问 通途：保证在tomcat下所有的web项目可以共享相同的cookie 例如：tieba , wenku , beike 多个项目共享数据。例如用户名。 当前项目访问：setPath(“/day09/“)3.2 有效时间 默认情况：cookie临时，当浏览器关闭销毁的。 setMaxAge 可以修改cookie被浏览器保存的时间。浏览器将cookie信息将保存cookie文件，浏览器关闭后文件仍然存在，直到设置时间过期将被浏览器自动删除。单位：秒 – 持久化cookie（保存文件） 删除cookie：保证域名、路径和cookie名称一致情况下，设置 setMaxAge(0) 将删除。  cookie唯一标识：域名、路径、名称 localhost / demo03_cookie_key baidu.com / mk localhost /day09/a/ cookie_key3.3 发送中文数据 cookie 使用http协议请求头和响应头，http协议不支持中文，cookie本身不支持中文的。 如果cookie value设置中文，服务器将抛异常。 如果cookie需要写入中文，必须手动编码（发送），将编码后结果发送浏览器，之后浏览器返回给服务器仍然编码后的结果，还需要手动解码（获取）。 JDK提供工具，进行编码 URLEncoder：编码 URLDecoder：解码//编码 String str = URLEncoder.encode(“屌中屌”, “UTF-8”); System.out.println(str); //%E5%B1%8C%E4%B8%AD%E5%B1%8C //解码 String value = URLDecoder.decode(str, “UTF-8”); System.out.println(value); 3.4 cookie案例1：记住用户名 表单可以提交（文本框、复选框） —下次浏览时，如果曾经记录应该将记录用户名显示到文本框中。 表单必须是servlet输出，不能是html页面，否则文本框不能显示记录数据。（除非jsp） 点击提交，编写servlet处理（是否勾选） 如果勾选，记录用户名（记录数据下次还可以访问，所以cookie，持久cookie setMaxAge(….)） 如果没有勾选，删除cookie，注意：唯一标识（域名、路径、名称），cookie必须再次发送到浏览器。 扩展：将UrlEncoder 和 UrlDecoder 结合使用（解决中文用户名） 3.5 cookie案例2：历史记录 点击查询所有商品 通过id查询商品详情 – 应该记录浏览记录 查询所有的浏览记录，显示记录数据 4 session 经典应用：用户登录、JD购物车等 一次会话中，服务器用于共享数据技术。 默认情况：session需要基于cookie使用。及没有cookie session无效。 当第一次调用 request.getSession() ，tomcat将创建一个session对象，并将session对象id值，以cookie方式发送给浏览器，之后浏览器再次请求时，将session id 发送服务器，服务器通过request.getSession() 就可以获取之前已经创建好的session对象。 JavaEE规范提供接口：javax.servlet.http.HttpSession 用于描述session对象。 获得session request.getSession() 获得session，如果没有将创建一个新的。等效request.getSession(true) request.getSession(boolean) 获得session，true：没有将创建，false：没有将返回null session属性操作：xxxAttribute session 也是 servlet 域对象。（3个servlet域对象：ServletRequest、HttpSession、ServletContext） session生命周期 创建：第一次调用 getSession()时创建 销毁： 1. 超时，默认30分钟。 web.xml 中配置 30 单位：分钟 2.执行api invalidate() 将session对象销毁了。 setMaxInactiveInterval(int interval) 设置有效时间，单位秒 3.服务器非正常关闭。（自杀，将JVM马上关闭） 如果正常关闭，session将被持久化（写入到文件中） D:\\java\\tomcat\\apache-tomcat-7.0.53\\work\\Catalina\\localhost\\day09\\SESSIONS.ser 当tomcat重新启动的时候这个文件就会被删除 4.1 URL重写 当浏览器将cookie禁用，基于cookie的session将不能正常工作，每次使用request.getSession() 都将创建一个new session。只需要将session id 传递给服务器session就可以工作的。 通过URL将session id 传递给服务器：URL重写 手动方式： url;jsessionid=…. api方式： encodeURL(java.lang.String url) 进行所有URL重写 encodeRedirectURL(java.lang.String url) 进行重定向 URL重写 如果参数url为空字符不同，其他都一样。 如果浏览器禁用cooke，api将自动追加session id ，如果没有禁用，api将不进行任何修改。 注意：如果浏览器禁用cookie，web项目的所有url都需手动重写。否则session将不能正常工作。 5 总结cookie 浏览器会话技术，用于在浏览器缓存内容，达到数据共享的目的 使用 1.服务器创建对象，添加数据 2.服务器将cookie发送给浏览器 3.浏览器自动携带cookie数据，服务器获得数据。 浏览器携带数据，根据cookie路径设置。 api setMaxAge 有效时间，0删除，必须保证路径匹配 setPath 设置访问路径 唯一标识：域名、路径、名称session 服务器端会话技术，用于在服务器共享数据。 session必须使用cookie传递session id，保证多次请求，浏览器可以共享 服务器一个session对象。 如果浏览器禁用cookie，必须进行URL重写。 session生命周期：","link":"/2016/11/28/JavaWeb%E5%9F%BA%E7%A1%80/09-JavaWeb%E5%9F%BA%E7%A1%80-cookie-session/"},{"title":"JDBC笔记一","text":"1. JDBC简单应用public class FirstJDBC { public static void main(String[] args) throws Exception { // 0.准备变量 String driver = &quot;com.mysql.jdbc.Driver&quot;;// mysql驱动实现类 String url = &quot;jdbc:mysql://localhost:3306/day15_db&quot;;// 确定数据库服务器地址,端口号,使用数据库 String user = &quot;root&quot;;// 登录名称 String password = &quot;1234&quot;;// 登录密码 // 1.注册驱动 Class.forName(driver); // 2.获得链接 Connection conn = DriverManager.getConnection(url, user, password); // 3.获得语句执行者 Statement st = conn.createStatement(); // 4.发送sql语句,查询 结果相当于一个set集合,每一个成员表示数据库表中一条记录 ResultSet rs = st.executeQuery(&quot;select * from t_user &quot;); // 5.处理结果 rs.next();// 移动到第一行 // getXxx获取某一行的指定列或字段值 getXxx(int 列数),getXxx(String 字段名) int id = rs.getInt(&quot;id&quot;); String username = rs.getString(&quot;username&quot;); String userPassword = rs.getString(&quot;password&quot;); System.out.printf(&quot;id:&quot;+id+&quot; username:&quot;+username+&quot; password:&quot;+password); // 6.释放资源,优先关闭最后使用的 rs.close(); st.close(); conn.close(); } }2. Junit 测试1.需要导入两个jar包junit.jarhamcrest-core.jar放入libs目录下即可2.类名alt+enter,然后选择需要添加测试的方法即可 测试用例方法，公共 没有返回值 非静态 方法名自定义 没有参数列表方法名建议：test方法名() public class DemoTest { private Demo demo; @Before //测试方法执行前 public void myBefore(){ System.out.println(&quot;之前&quot;); demo = new Demo(); //初始化数据 } @After //测试方法执行后 public void myAfter(){ System.out.println(&quot;之后&quot;); //方法资源 } @Test(timeout=1000) //timeout 设置测试时间，如果超时性能有问题 public void testAdd() { try { Thread.sleep(2000); } catch (Exception e) { } int sum = demo.add(1, 2); //断言 Assert.assertEquals(3, sum); assertEquals(3, sum); //使用静态导入的结果 } @Test public void testMul() { int sum = demo.mul(1, 2); } @BeforeClass public static void myBeforeClass(){ System.out.println(&quot;类之前&quot;); } @AfterClass public static void myAfterClass(){ System.out.println(&quot;类之后&quot;); } }3. JDBC工具类public class JdbcUtils { private static String url; private static String user; private static String password; // 这些配置文件的东西只用加载一次就可以了,写在静态代码块中 static { try { // 参数配置应该放在配置文件中 // 1. 加载properties文件 // 方式1:使用ClassLoader加载资源 //InputStream is = JdbcUtils.class.getClassLoader().getResourceAsStream(&quot;jdbcInfo.properties&quot;); // 方式2:使用Class对象加载,必须加上/,表示src InputStream is = JdbcUtils.class.getResourceAsStream(&quot;/jdbcInfo.properties&quot;); // 2. 解析配置文件 Properties properties = new Properties(); properties.load(is); // 3. 获得配置文件中的数据 String driver = properties.getProperty(&quot;driver&quot;); url = properties.getProperty(&quot;url&quot;); user = properties.getProperty(&quot;user&quot;); password = properties.getProperty(&quot;password&quot;); // 4. 注册驱动 Class.forName(driver); } catch (Exception e){ throw new RuntimeException(e); } } /** * 获得连接 */ public static Connection getConnection(){ try { Connection conn = DriverManager.getConnection(url, user, password); return conn; } catch (Exception e){ // 将编译时异常转换成运行时异常,开发中常见运行时异常 // throw new RuntimeException(e); // 此处可以使用自定义异常 // 类与类之间进行数据交换时可以使用return返回数据. // 也可以使用自定义异常返回值，调用者try{} catch(e){ e.getMessage() 获得需要的数据} throw new MyConnectionException(e); } } /** * 释放资源 */ public static void closeResource(Connection conn, Statement st, ResultSet rs){ try { if (rs != null) { rs.close(); } } catch (Exception e){ throw new RuntimeException(e); } finally { try { if (st != null) { st.close(); } } catch (Exception e){ throw new RuntimeException(e); } finally { try { if (conn != null) { conn.close(); } } catch (Exception e){ throw new RuntimeException(e); } } } } }4. 自定义异常继承RuntimeException 覆写方法将编译时异常转换成运行时异常,开发中常见运行时异常throw new RuntimeException(e);类与类之间进行数据交换时可以使用return返回数据.也可以使用自定义异常返回值，调用者try{} catch(e){ e.getMessage() 获得需要的数据} 5. 模板代码public void demo1(){ Connection conn = null; Statement st = null; ResultSet rs = null; try { conn = JdbcUtils.getConnection(); // .... } catch (Exception e){ throw new RuntimeException(e); } finally { // 释放资源 JdbcUtils.closeResource(conn,st,rs); } }6. Api详解6.1 注册驱动1.0 所有的驱动实现类必须实现规范接口，java.sql.Driver接口 1.1 原始编写方式：DriverManager.registerDriver(new Driver()); 特点：必须导包 import com.mysql.jdbc.Driver; 硬编程，内容写死的，无法扩展，不易于数据变迁(更换) 源码：public class com.mysql.jdbc.Driver implements java.sql.Driver 1.2 建议编写方式：Class.forName(&quot;com.mysql.jdbc.Driver&quot;); 特点：指定类如果有static{} 里面的内容将自动执行。 源码： static { try { java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can&apos;t register driver!&quot;); } } mysql Driver实现类，将自己进行注册。 优点：使用字符串方法加载到内容（注册），之后可以将驱动配置到配置文件中，之后只需要修改配置文件，数据库就更改。 1.3 此行代码可省略，建议不要省略。 mysql驱动 高版本，将自动加载驱动并注册。 文件：mysql-connector-java-5.1.22-bin.jar/META-INF/services/java.sql.Driver 内容：com.mysql.jdbc.Driver 1.4 错误总结 * ClassNotFoundException ，是否导入jar包？驱动名称是否正确？ * java.lang.NoClassDefFoundError 如果配置文件放置位置错误就会报这个异常 1.5 mysql com.mysql.jdbc.Driver 子类 org.gjt.mm.mysql.Driver 源码：public class Driver extends com.mysql.jdbc.Driver6.2 获得连接2.1 介绍 使用连接接口：java.sql.Connection,只有获得连接才可以操作数据库。 通过DriverManager 驱动管理者类获得连接。getConnection(url,user,password) 2.2 url 确定访问数据库位置 格式# 协议:子协议:子名称 协议 固定值 --&gt; jdbc 子协议 --&gt; 确定数据，例如：mysql、oracle 等 子名称 --&gt; localhost主机，3306端口，day15_db数据库名称 参数 --&gt; jdbc:mysql://localhost:3306/day15_db?useUnicode=true&amp;characterEncoding=UTF-8 设置请求编码，安装如果指定UTF-8，不需要设置的。如果安装时设置的编码为ISO8859-1编码，中文乱码需要如上处理。 主机默认localhost，端口默认3306 简写方式 --&gt; jdbc:mysql:///day15_db 2.3 错误总结 * Unknown database &apos;day15_db2&apos; , 表示数据库不存在。 * Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: YES) ， 账号和密码不匹配6.3 Connection提供的不同的操作对象3.1 操作对象 * Statement ， 语句执行者，获得方式 conn.createStatement()【】 * PreparedStatement , 预处理对象，获得方法 conn.prepareStatement(sql)【】 * 必须先提供sql语句，进行预先处理。 * CallableStatement 存储过程， prepareCall(String sql)，将sql语句编写数据库，相当于数据库函数，执行时 只需要传递实际参数 3.2 Statement int executeUpdate(sql) 执行DDL/DML语句，返回影响的行数。【】 ResultSet executeQuery(sql) 执行DQL语句，返回结果集（相当于一个表）【】 boolean execute(sql) 返回值true，表示执行DQL语句，必须通过 getResultSet() 获得结果集 返回值false，表示执行DML/DDL语句，必须通过 getUpdateCount() 获得影响行数 3.3 滚动结果集 （了解） * jdbc规范 默认结果集forward ，只能向前的结果集。 * 滚动结果集：可以向前，也可以向后。mysql 直接支持滚动 * ResultSet api next() 下一个（向前） previous() 上一个（向后） * 结果集ResultSet要滚动，前提Statement必须设置支持的。 * 使用方法：createStatement(int resultSetType, int resultSetConcurrency) resultSetType - 结果集类型， ResultSet.TYPE_FORWARD_ONLY，仅仅只能向前 ResultSet.TYPE_SCROLL_INSENSITIVE，可以滚动，不敏感。滚动中，数据库发生改变，结果集内容不改变的。 数据库的数据是否同步到结果集ResultSet中。 ResultSet.TYPE_SCROLL_SENSITIVE，可以滚动，敏感。滚动中，数据库数据发生改变，结果集内容改变。 resultSetConcurrency - 并发类型 ResultSet.CONCUR_READ_ONLY ，结果集只能读，不能改。 ResultSet.CONCUR_UPDATABLE，结果集可以更新，数据一并更改。 结果集数据同步到数据库 * 操作 获得 getXxx(int)获得指定列号的内容， getXxx(String)获得指定列名(字段)的内容 例如：getString(4) 获得第4列， getString(&quot;username&quot;) 获得字段名称username的值7.SQL注入sql注入 ：用户输入实际参数，作为了sql语句语法的一部分，数据库编译在执行时生效的。 select * from t_user where username = ‘jack’ or 1=1 or 1=’’ and password = ‘12345’ select * from t_user where username = ‘jack’ –’ and password = ‘12345’解决方案： 1. 手动方式：\\转义单引号 2. 使用预处理对象，防止sql注入 1) 先提供sql语句，将实际参数使用占位符?替换。 例如：select * from t_user where username = ? and password = ? 2) 获得预处理对象，获得对象时必须提供sql语句，让sql语句预先进行编译。 3) 设置实际参数 PreparedStatement 提供 setXxx(int , Object) 参数1：int表示 ?位置，从1开始。 参数2：Object具体类型，如果字符串String等。 3. PreparedStatement 接口 是 Statement接口的子接口。 但是execute(sql) 父类方法，子类使用抛异常。使用的没有参数。 8.预处理对象PreparedStatement特点： sql 易于编写，更佳清晰 提高性能，编译一次，可以执行多次。 编写步骤： 1.提供sql语句，并将实际参数使用？占位符 2.获得预处理对象，注意提供sql语句 3.设置实际参数，将?替换回来 4.执行，注意：不能设置sql语句。 Statement 和 PreparedStatement 对比： 一般情况使用PreparedStatement，之后学习框架DbUtils底层使用PreparedStatement，hibernate底层使用也是。 如果使用Statement，必须保证sql都是自己编写，实际参数都是自己传递的。 PreparedStatement 应用场景 1.防sql注入 2.大数据 大数据类型：blob 字节 、text 字符 3.批处理","link":"/2016/07/04/JavaWeb%E5%9F%BA%E7%A1%80/JDBC%E7%AC%94%E8%AE%B0%E4%B8%80/"},{"title":"JDBC笔记二","text":"1. JDBC批处理Statement 和 PreparedStatement 都提供批处理。 批处理：批量处理sql语句。 Statement的批处理，可以一次性执行不同的sql语句。应用场景：系统初始化（创建数据库，创建不同表） PreparedStatement 的批处理，只能执行一条sql语句，实际参数可以批量。应用场景：数据的初始化 1.1 StatementaddBatch(sql) ,给批处理缓存中添加sql语句。 clearBatch(); 清空批处理缓存。 executeBatch() , 执行批处理缓存所有的sql语句。注意：执行完成之后缓存中的内容仍然存在。1.2 PreparedStatementaddBatch() , 将实际参数批量设置缓存中。注意：获得预处理之前必须提供sql语句。 mysql 默认没开启批处理。 通过URL之后参数开启， ?rewriteBatchedStatements = true2. 事务2.1 什么是事务 事务：一组业务逻辑操作，要么全部成功，要么全部不成功。 事务特性：ACID 原子性：一个事务是不可划分的一个整体。要么成功，要么不成功。 一致性：事务操作前后数据一致。（数据完整）。转账前后，两个人和一样的。 隔离性：多个事务对同一个内容并发操作。 持久性：事务提交，操作成功了。不能改变了。保存到数据库中了。 隔离问题 脏读：一个事务 读到 另一个 事务 没有提交的数据。 不可重复读：一个事务 读到 另一个事务 已经提交的数据。（update更新） 虚读(幻读)：一个事务 读到 另一个事务 已经提交的数据。（insert插入） –理论时 事务隔离级别：用于解决隔离问题 读未提交：read uncommitted，一个事务读到另一个事务没有提交的数据。存放问题：3个 读已提交：read committed，一个事务读到另一个事务提交的数据。解决：脏读，存在2个问题 可重复读：repeatable read ，一个事务中读到数据重复的。及时另一个事务已经提交。解决：脏读、不可重复读，存放1个问题。 串行化，serializable，单事务，同时只能一个事务在操作。另一个事务挂起(暂停)。解决：3个问题。 默认隔离级别mysql默认隔离级别：repeatable readoracle默认隔离级别：read committed对比：性能：read uncommitted &gt; read committed &gt; repeatable read &gt; serializable 安全：read uncommitted &lt; read committed &lt; repeatable read &lt; serializable 2.2 事务操作 mysql 命令操作 开启事务：mysql&gt; start transaction; –开启相当于关闭自动提交 提交事务：mysql&gt; commit; –全部成功 回滚事务：mysql&gt; rollback; –保证全部不成功 jdbc java代码操作【掌握】– JDBC中必须使用Connection连接进行事务操作。 开启事务：conn.setAutoCommit(false); 提交事务：conn.commit(); 回滚事务：conn.rollback(); mysql 默认事务提交的，及每执行一条sql语句就是一个事务。扩展：oracle事务默认不提交，需要手动提交。 2.3 保存点Savepoint 保存点，用于记录程序执行位置，方便可以随意回滚指定的位置。spring 事务的传播行为AB整体（必须），CD整体（可选） Savepoint savepoint = null; try{ // 1 开启事务 conn.setAutoCommit(false); A B // 记录保存点 savepoint = conn.setSavepoint(); C D //2 提交ABCD conn.commit(); } catch(){ if(savepoint != null){ //CD 有异常，回滚到CD之前 conn.rollback(savepoint); // 提交AB conn.commit(); } else { //AB有异常 ,回滚到最开始处 conn.rollback(); } }2.4 丢失更新案例A 查询数据，username = ‘jack’ ,password = ‘1234’B 查询数据，username=”jack”, password=”1234”A 更新用户名 username=”rose”,password=’1234’ –&gt; username=”rose”,password=”1234”B 更新密码 password=”9999” ,username=”jack” –&gt; username=”jack”,password=’9999’丢失更新：最后更新数据，将前面更新的数据覆盖了。 解决方案：采用锁机制。乐观锁：丢失更新肯定不会发生。 给表中添加一个字段（标识），用于记录操作版本。 username=&quot;jack&quot;,password=&quot;1234&quot;,version=&quot;1&quot; ，比较版本号，如果一样，修改版本自动+1.。如果不一样，必须先查询，再更新。悲观锁：丢失更新肯定会发生。采用数据库锁机制。 读锁：共享锁，大家可以一起读。 select .... from .... lock in share mode; 写锁：排他锁，只能一个进行写，不能有其他锁（写、读），所有更新update操作丢将自动获得写锁。 select ... from ... for update;注意：数据库的锁，必须在事务中使用。只要事务操作完成（commit|rollback|超时）自动释放锁 3. 事务实例4. 连接池1.为什么使用连接池：连接Connection 创建与销毁 比较耗时的。为了提供性能，开发连接池。2.什么是连接池 javaee规范规定：连接池必须实现接口，javax.sql.DataSource (数据源) 为了获得连接 getConnection() 连接池给调用者提供连接，当调用者使用，此链接只能供调动者是使用，其他人不能使用。 当调用者使用完成之后，必须归还给连接池。连接必须重复使用。3.自定义连接池4.第三方连接池 DBCP，apache C3P0 ，hibernate 整合 tomcat 内置（JNDI）4.1 DBCP1.Apache提供的2.导入jar包 commons-dbcp-1.4.jar 核心包 commons-pool-1.6.jar 依赖包3.核心类 public class BasicDataSource implements DataSource4.手动调用 //1 创建核心类 BasicDataSource dataSource = new BasicDataSource(); //2 配置4个基本参数 dataSource.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;); dataSource.setUrl(&quot;jdbc:mysql:///day16_db&quot;); dataSource.setUsername(&quot;root&quot;); dataSource.setPassword(&quot;1234&quot;); //3 管理连接配置 dataSource.setMaxActive(30); //最大活动数 dataSource.setMaxIdle(20); //最大空闲数 dataSource.setMinIdle(10); //最小空闲数 dataSource.setInitialSize(15); //初始化个数5.配置调用 DBCP采用properties文件，key=value ，key为 BasicDataSource属性（及setter获得） //0 读取配置文件 InputStream is = TestDBCP.class.getClassLoader().getResourceAsStream(&quot;dbcpconfig.properties&quot;); Properties properties = new Properties(); properties.load(is); //1 加载配置文件，获得配置信息 DataSource dataSource = BasicDataSourceFactory.createDataSource(properties);6.配置文件 dbcpconfig.properties #连接设置 driverClassName=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/day16_db username=root password=1234 #&lt;!-- 初始化连接 --&gt; initialSize=10 #最大连接数量 maxActive=50 #&lt;!-- 最大空闲连接 --&gt; maxIdle=20 #&lt;!-- 最小空闲连接 --&gt; minIdle=5 #&lt;!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 --&gt; maxWait=60000 #JDBC驱动建立连接时附带的连接属性属性的格式必须为这样：[属性名=property;] #注意：&quot;user&quot; 与 &quot;password&quot; 两个属性会被明确地传递，因此这里不需要包含他们。 connectionProperties=useUnicode=true;characterEncoding=gbk #指定由连接池所创建的连接的自动提交（auto-commit）状态。 defaultAutoCommit=true #driver default 指定由连接池所创建的连接的只读（read-only）状态。 #如果没有设置该值，则“setReadOnly”方法将不被调用。（某些驱动并不支持只读模式，如：Informix） defaultReadOnly= #driver default 指定由连接池所创建的连接的事务级别（TransactionIsolation）。 #可用值为下列之一：（详情可见javadoc。）NONE,READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE defaultTransactionIsolation=READ_UNCOMMITTED4.2 C3P01.第三方提供,非常优秀2.导入jar包 c3p0-0.9.2-pre5.jar 核心包 mchange-commons-java-0.2.3.jar 依赖包 c3p0-oracle-thin-extras-0.9.2-pre5.jar 使用oracle的依赖3.核心类 ComboPooledDataSource4.手动调用 //1 核心类 (日志级别：debug info warn error) ComboPooledDataSource dataSource = new ComboPooledDataSource(); //2 基本4项 dataSource.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;); dataSource.setJdbcUrl(&quot;jdbc:mysql:///day16_db&quot;); dataSource.setUser(&quot;root&quot;); dataSource.setPassword(&quot;1234&quot;); //3 优化 dataSource.setMaxPoolSize(30); //最大连接池数 dataSource.setMinPoolSize(10); //最小连接池数 dataSource.setInitialPoolSize(15); //初始化连接池数 dataSource.setAcquireIncrement(5); //每一次增强个数5.配置调用 加载位置：WEB-INF/classes (classpath , src) 配置文件名称：c3p0-config.xml //1 c3p0...jar 将自动加载配置文件。打包后从WEB-INF/classes (src)目录加载名称为c3p0-config.xml的文件 //ComboPooledDataSource dataSource = new ComboPooledDataSource(); //自动从配置文件 &lt;default-config&gt; ComboPooledDataSource dataSource = new ComboPooledDataSource(&quot;itheima&quot;); //手动指定配置文件 &lt;named-config name=&quot;itheima&quot;&gt; 6.配置文件 c3p0-config.xml &lt;c3p0-config&gt; &lt;!-- 默认配置，如果没有指定则使用这个配置 --&gt; &lt;default-config&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql:///day16_db&lt;/property&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;1234&lt;/property&gt; &lt;property name=&quot;checkoutTimeout&quot;&gt;30000&lt;/property&gt; &lt;property name=&quot;idleConnectionTestPeriod&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxStatements&quot;&gt;200&lt;/property&gt; &lt;user-overrides user=&quot;test-user&quot;&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;maxStatements&quot;&gt;0&lt;/property&gt; &lt;/user-overrides&gt; &lt;/default-config&gt; &lt;!-- 命名的配置 --&gt; &lt;named-config name=&quot;itheima&quot;&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql:///day16_db&lt;/property&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;1234&lt;/property&gt; &lt;!-- 如果池中数据连接不够时一次增长多少个 --&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;5&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;20&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;40&lt;/property&gt; &lt;property name=&quot;maxStatements&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;maxStatementsPerConnection&quot;&gt;5&lt;/property&gt; &lt;/named-config&gt; &lt;/c3p0-config&gt; 4.3 JNDI tomcat管理连接池 JNDI(Java Naming and Directory Interface,Java命名和目录接口)是SUN公司提供的一种标准的Java命名系统接口，用于存放java任意对象，给对象进行命名（使用目录结构）。例如：/a/b/c 作用：在多个项目之间共享数据，只需要传递名称，就可以获得对象。 理解：JNDI 就是一个容器，用于存放任意对象。 tomcat 将连接池存放 JNDI容器，可以获得使用。使用前提必须通知tomcat进行存放，默认情况下tomcat没有存放。 配置:1.给tomcat配置数据源（连接池），使用 标签 方式1：%tomcat%/conf/server.xml --&gt; 在&lt;Host&gt;标签下添加&lt;Context&gt; 方式2：%tomcat%/conf/Catalina/localhost/day16.xml ---&gt; &lt;Context&gt; day16/META-INF/Context.xml 在项目的META-INF下创建Context.xml,会自动发布到“方法2”指定位置 Context.xml中的内容: &lt;Context&gt; &lt;!-- name 存放进去名称 auth 存放位置 type 确定存放内容，tomcat将通过指定接口创建实例，底层使用DBCP 其他都是DBCP属性设置 --&gt; &lt;Resource name=&quot;jdbc/itheima&quot; auth=&quot;Container&quot; type=&quot;javax.sql.DataSource&quot; maxActive=&quot;100&quot; maxIdle=&quot;30&quot; maxWait=&quot;10000&quot; username=&quot;root&quot; password=&quot;1234&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://localhost:3306/day16_db&quot;/&gt; &lt;/Context&gt;2 从JNDI容器获取，在当前项目web.xml配置 &lt;!-- 给当前项目配置，从JNDI容器获得指定名称内容 --&gt; &lt;resource-ref&gt; &lt;res-ref-name&gt;jdbc/itheima&lt;/res-ref-name&gt; &lt;res-type&gt;javax.sql.DataSource&lt;/res-type&gt; &lt;res-auth&gt;Container&lt;/res-auth&gt; &lt;/resource-ref&gt;3.使用 //0 包名：javax.naming //1 初始化JNDI容器 Context context = new InitialContext(); //2 获得数据源 固定 “java:/comp/env” DataSource dataSource = (DataSource)context.lookup(&quot;java:/comp/env/jdbc/itheima&quot;);","link":"/2016/07/09/JavaWeb%E5%9F%BA%E7%A1%80/JDBC%E7%AC%94%E8%AE%B0%E4%BA%8C/"},{"title":"MySql笔记","text":"1.数据库知识分类: 网状型数据库 层次型数据库 关系型数据库 Oracle ： 甲骨文，oracle公司，大型数据，收费 db2 ： IBM，大型数据，收费 Sql server ： 微软，中性数据，收费。(access office 小型) Mysql ： 免费。小型。（开源） –oracle 2.Mysql安装 设置数据库存放目录 选择配置类型 选择服务类型 选择数据库类型 设置并发连接数 配置网络参数 设置字符集 设置服务和环境静变量 设置数据库密码 测试 C:\\Users\\xxxxx&gt;mysql --version mysql Ver 14.14 Distrib 5.5.27, for Win64 (x86) 3.Mysql登录&amp;修改数据库密码mysql -h 主机(ip地址) -u 账号 -p 密码 use mysql; update user set password=password(&apos;1234&apos;) where user=&apos;root&apos;;4.常用命令 显示当前数据库服务器中的数据库列表 : show databases; 使用数据库 : use 数据库名; 显示数据库中的数据表 : show tables; 显示当前所使用的数据库名称 : select database(); 显示当前数据库的状态 : status; 显示某个表的表结构 : desc 表名; 显示所有支持的字符集 : show character set; 查看创建表的sql语句 : show create table 表名; 5.SQL语句5.1 DDL数据定义语言(了解)&gt; 操作数据库或表结构5.1.1 数据库操作 创建数据库 : create database 数据库名称; 查询数据库创建语句 : show create database 数据库名称; 删除数据库 : drop database [if exists] 数据库名称; 修改数据 : alter database 数据库名 character set 字符集 collate 比较方式不建议修改。 5.1.2 表结构&gt; 操作表之前,必须先切换数据库. 创建表 : create table 表名(字段描述,字段描述,...); create table users( id varchar(32), name varchar(50), age int ); 删除表 : drop table 表名; 修改字段类型 : alter table 表名 modify 字段名称 新类型; 修改字段名称 : alter table 表名 change 旧字段 新字段 新字段类型; 添加字段 : alter table 表名 add column 字段名称 字段类型; 删除字段 : alter table 表名 drop column 字段名称; 重命名表名 : alter table 表名 rename [to] 新表明; 5.1.3 数据类型字符串 char(n) 固定字符串，例如：char(5) 表示可以存放5个字符，且必须是5个。 如果插入 “abc”,结果“abc ” 右边自动添加空格。 varchar(n) 可变长字符串，例如：varchar(5),表示最多存放5个字符，如果不够就原样存放。 如果插入“abc”，结果“abc”数字 bit 比特 tinyint byte mediumint short int int 【】 bigint long float float double(m,d) double 【】 --m数字长度，d精度及小数位 numeric Number 所有数字 例如：double(5,2) 5表示整个数字为5位，2表示小数位2个。最大值。999.99时间日期 ** 之后使用java日期时间类型：java.util.Date 。如果要使用java.sql..类型，只能存放dao层 date 日期 java.sql.Date datetime 日期时间 --- time 时间 java.sql.Time timestamp 时间戳 java.sql.Timestamp sql转util ： java.util.Date date = new java.sql.Date(long); util转sql ： new java.sql.Date( new java.util.Date().getTime() )大数据 字节：存放二进制 （java.sql.Blob ：Binary Large Object 二进制大对象） TINYBLOB 255 blob 64k longblob 4G 字符：存放文本 （java.sql.Clob ：Character Large Object 字符大对象） TINYTEXT 255 text 64k longtext 4G5.2 DML数据操作语言(掌握)&gt; 对表中的数据进行增删改的操作5.2.1 插入数据insert into 表名(字段列表) values(字段对应值);注意: 多个字段之间使用逗号分隔 字段值必须使用引号(建议单引号),如果是整形数据引号可以省略 字段默认值为null5.2.2 更新数据update 表名 set 字段名=字段值,字段名=字段值,...; update 表名 set 字段名=字段值,字段名=字段值,...where 条件;5.2.3 删除数据delete from 表名 [where 条件];注意: delete from users; 删除表中的所有数据.进行删除操作留心,一般情况应用系统不进行数据删除,提供一个标记字段,逻辑删除(0表示已删除,1表示没有删除).5.3 约束 给字段添加规则，约定内容编写。最终作用保证数据的完整性，一致性等。 5.3.1 主键约束关键字:primary key 要求:数据唯一,不能为null.1.定义表:声明字段时,定义主键.(primary key)只能修饰一个字段. create table pk01( id varchar(32) primary key , content varchar(50) );2.定义表，声明字段之后，在约束区域定义主键。—特点 constraint primary key (字段1,字段2,….) 可以设置多个字段 create table pk02( id varchar(32), content varchar(50), constraint primary key (id) );3.定义表，声明字段，表创建之后。修改表结构添加约束。–特点：也可以设置多个字段，更灵活。 create table pk03( id varchar(32), content varchar(50) ); alter table pk03 add constraint primary key (id); 5.3.2 唯一约束关键字:unique 要求:被修饰的字段不能重复1.定义表，声明字段时，定义唯一约束。— 特点：unique只能修饰一个字段 create table un01( id varchar(32), content varchar(50) unique );2.定义表，声明字段之后，在约束区域定义唯一约束。—特点 constraintunique (字段1,字段2,….) 可以设置多个字段 create table un02( id varchar(32), content varchar(50), constraint unique (content) );3.定义表，声明字段，表创建之后。修改表结构添加唯一约束。–特点：也可以设置多个字段，更灵活。 create table un03( id varchar(32), content varchar(50) ); alter table un03 add constraint unique (content); 5.3.3 非空约束关键字:not null 要求:被修饰的字段不能为null1.定义表，声明字段时，添加约束。 create table nn01( id varchar(32), content varchar(50) not null ); create table nn02( id varchar(32), content varchar(50) not null default ‘dzd’ ); 总结: 主键 = 唯一 + 非空 5.3.4 自动增长(mysql特有)定义: 关键字:auto_increment mysql特有的一个特殊的关键字,被修饰的字段将自动的累加(oracle没有,但提供徐磊sequence) 注意: 1.字段类型必须是整型,一般使用int 2.必须是key(主键/唯一),一般使用主键primary key 3.被auto_increment修饰的字段,不需要手动维护数据,mysql将自动维护代码示例: create table ai01( id varchar(32) auto_increment, # 错误代码 不能用于字符串 content varchar(50) ); create table ai02( id int auto_increment, # 错误代码 必须是primary key content varchar(50) ); create table ai03( id int primary key auto_increment, # 正确代码 content varchar(50) );面试题: drop table ai03; #删除表，数据和表都不存在了。 delete from ai03; #删除所有数据，表仍然存在。表中计数器没有重置。 truncate table ai03; #清空所有数据，表中的计数器将重置归0。 delete 和 truncate 对比 delete 将数据删除了 truncate 先删除了表，再创建表。 5.3.5 外键约束关键字:foreign key5.3.6 删除约束删除主键：mysql&gt; `alter table 表名 drop primary key;` 删除唯一：修改列 删除外键：mysql&gt; `alter table 表名 drop foreign key 名称;`5.3.7 cmd命令行中文乱码处理set names gbk;5.4 DQL数据查询语言(掌握)5.4.1 无条件查询查询所有: select * from users; select id,name,age from user;查询部分字段: select id,name from user;合并查询条件: select id,concat(firstname,secondname),age from users;字段别名: select id,concat(firstname,secondname) as `姓名`,age from users;特殊字符或者关键字使用重音符 `` 5.4.2 带条件查询查询分数等于60的: select * from users where count=&apos;60&apos;;查询年龄大于18的学生: select * from users where age &gt; 18;查询分数在60-80之间: select * from users where count &gt;= 60 and count &lt;= 80; select * from users where count between 60 and 80;查询年龄是18或20的学生: select * from users where age = 18 or age = 20;模糊查询,不完全匹配: 字段:like 符号: %匹配多个数据 &apos;云&apos; 只能匹配一个云 &apos;%云&apos; 匹配以云结尾的 &apos;云%&apos; 匹配以云开头的 &apos;%云%&apos; 包含云 _匹配一个数据查询分数等于60 或者 分数大于90并且年龄大于23 select * from users where count = 60 or count &gt; 90 and age &gt; 23; select * from users where count = 60 or (count &gt; 90 and age &gt; 23); ### 运算符优先级 and 优先 or查询没有考试的学生 select * from users where count is null;查询所有考试的学生 select * from users where count is not null;运算符 不相等 != &lt;&gt; 5.4.3 聚合函数聚合函数：对表中的数据进行统计，显示一个数据（一行一列的数据） 聚合函数不统计 null值。有多少条记录 count(* | 字段) select count(*) from users; select count(id) from users; #7 select count(count) from users; #6平均成绩 avg select avg(count) from users; #不精准（没有null） select sum(count)/count(id) from users; #精准（计算null）最高成绩 max select max(count) from users;最小年龄 min select min(age) from users;班级总成绩 sum select sum(count) from users;查询所有的年龄数(排序) 去重复 distinct 排序 select..... order by 字段1 关键字, 字段2 关键字,.... ### 关键字 asc 升序 ， desc 降序 select distinct age from users order by age desc; # age asc 等效 age [asc] 5.4.4 分组查询添加班级字段（classes） alter table users add column classes varchar(3); update users set classes = 1; update users set classes = 2 where id=&apos;u005&apos; or id =&apos;u006&apos; or id =&apos;u007&apos;; update users set classes = 2 where id in (&apos;u005&apos;,&apos;u006&apos;,&apos;u007&apos;);查询1班和2班的平均成绩 分组 select ... group by 分组字段; select classes,avg(count) from users group by classes; select classes,sum(count)/count(id) from users group by classes;查询班级，平均成绩不及格的，班级成员信息 (查询2班，成员信息) select * from users where classes = 2;多表操作select * from A,B where A.classes = B.classes and avg &lt; 60; 表的别名select ... from 表名 [as] 别名子查询，一条select语句，作为另一个select一部分。select * from users,( select classes,sum(count)/count(id) as cavg from users group by classes) as Bwhere users.classes = B.classes and cavg &lt; 60; 子查询特点#查询结果一行一列，可以使用 select id,(xxx) from select ... from ... where id= (xxxx) #查询结果一行多列(查询多个值)，使用关键字 in ，all 等 #查询结果多行多列，可以当另一个表使用","link":"/2016/06/30/JavaWeb%E5%9F%BA%E7%A1%80/MySql%E7%AC%94%E8%AE%B0/"},{"title":"Redis学习笔记","text":"Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。 1.简介1.1 定义高性能的kv缓存和数据库.存储结构就是kv，形式如下： 1.2 应用场景 用来做缓存(ehcache/memcached)——redis的所有数据是放在内存中的（内存数据库） 可以在某些特定应用场景下替代传统数据库 在一些大型系统中，巧妙地实现一些特定的功能：session共享、购物车只要你有丰富的想象力，redis可以用在各种官网说明上没有提到的场景。。。。。 1.3 redis的特性 redis数据访问速度快（数据在内存中） redis的数据有持久化 持久化机制有两种： 1、定期将内存数据dump到磁盘 2、aof持久化机制——用记日志的方式记录每一条数据更新操作，一旦出现灾难事件，可以通过日志重放来恢复整个数据库 redis还支持集群模式（容量可以线性扩展） redis相比其他缓存工具（ehcach/memcached），有一个鲜明的优势：支持丰富的数据结构 1.4 Redis安装TODO:windows版本已经总结了linux版本的安装总结到那篇笔记中 2. Redis存储的数据结构2.1 String1.插入/读取数据 set sessionid-0001 &quot;zhangsan&quot; get sessionid-0001 2.对string类型数据进行增减（前提是这条数据的value可以看成数字） DECR key 减去1 INCR key 加上1 DECRBY key decrement 减去decrement INCRBY key increment 加上increment3.一次性插入或者获取多条数据 MSET key1 value1 key2 value2 ... 插入多条数据 MGET key1 key2 获取多条数据2.2 List1.从头部插入数据 LPUSH key value1 value2 value3 2.从尾部插入数据 RPUSH key value1 value2 value3 3.读取list中的values LRANGE key start end lrange task-queue 0 -1 读取整个list4.从头部弹出一个元素 LPOP key5.从尾部弹出一个元素 RPOP key6.从一个list的尾部弹出一个元素插入到另一个list RPOPLPUSH key1 key2案例: 任务调度系统(详见后面笔记) 2.3 HashRedis中的Hashes类型可以看成具有String Key和String Value的map容器 1.插入一条hash类型的数据 hset key field value2.获取一条hash类型数据的value 取出一条hash类型数据中所有field-value对 hgetall key 取出hash数据中所有fields hkeys value 取出hash数据中所有的value hvals key 取出hash数据中一个指定field的值 hget key field3.为hash数据中指定的一个field的值进行增减 hincrby key field increment hincrby user001:zhangsan xiaomi 14.从hash数据中删除一个字段field及其值 hdel key field hdel user001:zhangsan iphone2.4 Set1.插入一条set数据 sadd key value value value ... sadd frieds:zhangsan bingbing baby fengjie furong ruhua feifei2.显示set数据的个数 scard key3.获取一条set数据的所有members smembers frieds:zhangsan 1) &quot;fengjie&quot; 2) &quot;baby&quot; 3) &quot;furong&quot; 4) &quot;bingbing&quot; 5) &quot;feifei&quot; 6) &quot;ruhua&quot; 4.判断一个成员是否属于某条指定的set数据 redis 127.0.0.1:6379&gt; sismember frieds:zhangsan liuyifei #如果不是，则返回0 (integer) 0 redis 127.0.0.1:6379&gt; sismember frieds:zhangsan baby #如果是，则返回1 (integer) 1 5.求两个set数据的差集 求差集 redis 127.0.0.1:6379&gt; sdiff frieds:zhangsan friends:xiaotao 1) &quot;furong&quot; 2) &quot;fengjie&quot; 3) &quot;ruhua&quot; 4) &quot;feifei&quot; 求差集，并将结果存入到另一个set redis 127.0.0.1:6379&gt; sdiffstore zhangsan-xiaotao frieds:zhangsan friends:xiaotao (integer) 46.求交集，求并集 求交集 redis 127.0.0.1:6379&gt; sinterstore zhangsan^xiaotao frieds:zhangsan friends:xiaotao (integer) 2 求并集 redis 127.0.0.1:6379&gt; sunion frieds:zhangsan friends:xiaotao 1) &quot;fengjie&quot; 2) &quot;tangwei&quot; 3) &quot;liuyifei&quot; 4) &quot;bingbing&quot; 5) &quot;ruhua&quot; 6) &quot;feifei&quot; 7) &quot;baby&quot; 8) &quot;songhuiqiao&quot; 9) &quot;furong&quot; 10) &quot;yangmi&quot; 2.5 SortedSet1.往redis库中插入一条sortedset数据 redis 127.0.0.1:6379&gt; zadd nanshen:yanzhi:bang 70 liudehua 90 huangbo 100 weixiaobao 250 yanggang 59 xiaotao (integer) 52.从sortedset中查询有序结果 #正序结果 redis 127.0.0.1:6379&gt; zrange nanshen:yanzhi:bang 0 4 1) &quot;xiaotao&quot; 2) &quot;liudehua&quot; 3) &quot;huangbo&quot; 4) &quot;weixiaobao&quot; 5) &quot;yanggang&quot; #倒序结果 redis 127.0.0.1:6379&gt; zrevrange nanshen:yanzhi:bang 0 4 1) &quot;yanggang&quot; 2) &quot;weixiaobao&quot; 3) &quot;huangbo&quot; 4) &quot;liudehua&quot; 5) &quot;xiaotao&quot; 3.查询某个成员的名次 在正序榜中的名次 redis 127.0.0.1:6379&gt; zrank nanshen:yanzhi:bang xiaotao (integer) 0 在倒序榜中的名次 redis 127.0.0.1:6379&gt; zrevrank nanshen:yanzhi:bang xiaotao (integer) 4 4.修改成员的分数 redis 127.0.0.1:6379&gt; zincrby nanshen:yanzhi:bang 300 xiaotao &quot;359&quot; redis 127.0.0.1:6379&gt; zrevrank nanshen:yanzhi:bang xiaotao (integer) 0 3. 实例3.1 List实例–任务调度系统生产者不断产生任务，放入task-queue排队消费者不断拿出任务来处理，同时放入一个tmp-queue暂存，如果任务处理成功，则清除tmp-queue，否则，将任务弹回task-queue上述机制是一个简化版，真实版的任务调度系统会更加复杂，如下所示：（增加了一个专门用来管理暂存队列的角色，以便就算消费者程序失败退出，那些处理失败的任务依然可以被弹回task-queue） 代码: /** * 使用redis模拟任务调度 * Created by lujiahao on 2016/7/7. */ public class TaskSchedulerSystem { /** * 模拟一个生产者 */ public static class TaskProducer implements Runnable { Jedis jedis = new Jedis(&quot;127.0.0.1&quot;,6379); @Override public void run() { Random random = new Random(); while (true) { try { Thread.sleep(random.nextInt(600) + 600); // 生成一个任务 UUID taskid = UUID.randomUUID(); // 将任务插入任务队列:task-queue jedis.lpush(&quot;task-queue&quot;,taskid.toString()); System.out.println(taskid+&quot;任务被插入&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } } } /** * 模拟一个消费者 */ public static class TaskConsumer implements Runnable{ Jedis jedis = new Jedis(&quot;127.0.0.1&quot;,6379); @Override public void run() { Random random = new Random(); while (true){ try { // 从任务队列中获取一个任务,并将任务放入暂存队列tmp-queue jedis.rpoplpush(&quot;task-queue&quot;, &quot;tmp-queue&quot;); // 模拟处理任务--sleep---业务逻辑 Thread.sleep(1000); // 模拟成功和失败的偶然情况 if (random.nextInt(13) % 7 == 0){ // 失败,将任务从暂存队列tmp-queue弹回到任务队列task-queue String taskid = jedis.rpoplpush(&quot;tmp-queue&quot;, &quot;task-queue&quot;); System.out.println(taskid+&quot;任务处理失败,弹回任务队列&quot;); } else { // 成功,将任务从暂存队列中清除 String taskid = jedis.rpop(&quot;tmp-queue&quot;); System.out.println(taskid+&quot;任务处理成功,从暂存队列中清除&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } } } } public static void main(String[] args) throws InterruptedException { // 启动一个生产者线程,产生模拟任务 new Thread(new TaskProducer()).start(); Thread.sleep(500); // 启动一个消费者线程,模拟任务的处理 new Thread(new TaskConsumer()).start(); // 让主线程休眠 Thread.sleep(Integer.MAX_VALUE); } }3.2 SortedSet实例–LOL英雄数据排行榜/** * LOL盒子英雄数据排行榜的模拟实现 * Created by lujiahao on 2016/7/7. */ public class LOLHerosTopN { private static class PlayerTask implements Runnable { String[] heros = {&quot;压缩&quot;, &quot;剑圣&quot;, &quot;蛮王&quot;, &quot;男枪&quot;, &quot;女警&quot;, &quot;阿狸&quot;, &quot;猴子&quot;, &quot;赵信&quot;, &quot;盖伦&quot;}; Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379); @Override public void run() { Random random = new Random(); while (true) { String hero = heros[random.nextInt(heros.length)]; try { Thread.sleep(1000); jedis.zincrby(&quot;lol:hero:rank&quot;, 1, hero); } catch (InterruptedException e) { e.printStackTrace(); } } } } private static class ViewerTask implements Runnable { Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379); int i = 1; @Override public void run() { while (true) { System.out.println(&quot;第&quot;+i+&quot;次获取榜单:&quot;); try { Thread.sleep(2000); Set&lt;Tuple&gt; herosAndScore = jedis.zrevrangeWithScores(&quot;lol:hero:rank&quot;, 0, -1); for (Tuple tuple : herosAndScore) { System.out.println(tuple.getElement()+&quot;:&quot;+tuple.getScore()); } i++; } catch (InterruptedException e) { e.printStackTrace(); } } } } public static void main(String[] args) throws InterruptedException { new Thread(new PlayerTask()).start(); Thread.sleep(1000); new Thread(new ViewerTask()).start(); Thread.sleep(Long.MAX_VALUE); } }","link":"/2020/04/11/Redis/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"03-Shiro自定义Realm及加密","text":"Shiro的ini方式配置用户名密码，灵活性差，安全性不佳。本文介绍自定义Realm及加密，可以安全的获取数据认证。 Shiro从Realm获取安全数据(如用户、角色、权限)，就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法。也需要从Realm得到用户相应的角色 / 权限进行验证用户是否能进行操作，可以把Realm看成 DataSource，即安全数据源。 1. 自定义Realm1.1 新建MyRealm类新建MyRealm并继承AuthorizingRealm，重写getName，doGetAuthorizationInfo，doGetAuthenticationInfo三个方法。 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 自定义realm实现 * * @author lujiahao * @date 2019/10/14 */public class MyRealm extends AuthorizingRealm { @Override public String getName() { return \"myRealm\"; } /** * 用户权限和角色 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { return null; } /** * 用户认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { // 获取用户信息 String username = (String) token.getPrincipal(); // 模拟从数据库获取用户名和密码 String dbUsername = \"lujiahao\"; String dbPassword = \"123\"; // 验证用户 if (!dbUsername.equals(username)) { return null; } // 参数列表依次是： 用户名 密码 当前realm名字 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, dbPassword, getName()); return info; }} 1.2 配置文件新建shiro-realm.ini配置文件 1234# 声明一个realmmyRealm=com.lujiahao.realms.MyRealm# 指定securitymanager的realms实现securityManager.realms=$myRealm 1.3 测试类123456789101112131415161718192021222324252627282930/** * 测试自定义realm */@Testpublic void testCustomRealm() { // 1.加载配置文件，创建SecurityManger工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(\"classpath:shiro-realm.ini\"); // 2.获得SecurityManager实例对象 SecurityManager securityManager = factory.getInstance(); // 3.将SecurityManger绑定到当前运行环境中 SecurityUtils.setSecurityManager(securityManager); // 4.创建当前登录主体 Subject currentUser = SecurityUtils.getSubject(); // 5.绑定主体登录的身份凭证（即账户密码） UsernamePasswordToken token = new UsernamePasswordToken(\"lujiahao222\", \"123\"); // 6.主体登录 try { currentUser.login(token); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated()); } catch (UnknownAccountException e) { System.out.println(\"账户信息错误：无此账户信息\"); } catch (IncorrectCredentialsException e) { System.out.println(\"密码错误！\"); } catch (Exception e) { e.printStackTrace(); } // 7.注销登录 currentUser.logout(); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated());} 2. 加密Shiro提供了base64和16进制字符串编码 / 解码的API支持，方便一些编码解码操作。Shiro内部的一些数据的存储及表示都使用 base64和16进制字符串。散列算法是一种不可逆的算法，一般用于存储密码之类的数据，常见的散列算法如MD5、SHA等等。 2.1 新建EncryRealm类套路同上😏 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 加密 * @author lujiahao * @date 2019/10/14 */public class EncryRealm extends AuthorizingRealm { @Override public String getName() { return \"encryRealm\"; } /** * 用户权限和角色 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { return null; } /** * 用户认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { // 获取用户信息 String username = (String) token.getPrincipal(); // 模拟从数据库获取用户名和密码 String dbUsername = \"lujiahao\"; // 模拟db中的密码：密码+盐+散列次数 String dbPassword = \"6b74111749b5409fa32e05b02816b760\"; // 验证用户 if (!dbUsername.equals(username)) { return null; } // 参数列表依次是： 用户名 密码 盐 当前realm名字 // 这里传入的密码一定是经过md5的，不然会报异常 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, dbPassword, ByteSource.Util.bytes(username), getName()); return info; }} 2.2 配置文件新建shiro-encry-realm.ini配置文件 1234567891011121314[main]#定义凭证匹配器credentialsMatcher = org.apache.shiro.authc.credential.HashedCredentialsMatcher#散列算法credentialsMatcher.hashAlgorithmName = md5#散列次数credentialsMatcher.hashIterations = 2# 声明一个realmmyRealm=com.lujiahao.realms.EncryRealm#将凭证匹配器设置到realmmyRealm.credentialsMatcher = $credentialsMatcher# 指定securitymanager的realms实现securityManager.realms=$myRealm 2.3 测试类123456789101112131415161718192021222324252627282930/** * 测试自定义加密realm */@Testpublic void testCustomEncryRealm() { // 1.加载配置文件，创建SecurityManger工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(\"classpath:shiro-encry-realm.ini\"); // 2.获得SecurityManager实例对象 SecurityManager securityManager = factory.getInstance(); // 3.将SecurityManger绑定到当前运行环境中 SecurityUtils.setSecurityManager(securityManager); // 4.创建当前登录主体 Subject currentUser = SecurityUtils.getSubject(); // 5.绑定主体登录的身份凭证（即账户密码） UsernamePasswordToken token = new UsernamePasswordToken(\"lujiahao\", \"123\"); // 6.主体登录 try { currentUser.login(token); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated()); } catch (UnknownAccountException e) { System.out.println(\"账户信息错误：无此账户信息\"); } catch (IncorrectCredentialsException e) { System.out.println(\"密码错误！\"); } catch (Exception e) { e.printStackTrace(); } // 7.注销登录 currentUser.logout(); System.out.println(\"用户身份验证：\" + currentUser.isAuthenticated());} Tips12SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, dbPassword, ByteSource.Util.bytes(username), getName()); 中的第二个参数需要是经过md5加密的字符串，不然会报异常，异常信息如下： 1234567891011121314151617181920212223242526272829org.apache.shiro.authc.AuthenticationException: Authentication failed for token submission [org.apache.shiro.authc.UsernamePasswordToken - lujiahao, rememberMe=false]. Possible unexpected error? (Typical or expected login exceptions should extend from AuthenticationException). at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.shiro.authc.AbstractAuthenticator.authenticate(AbstractAuthenticator.java:214) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at org.apache.shiro.mgt.AuthenticatingSecurityManager.authenticate(AuthenticatingSecurityManager.java:106) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at org.apache.shiro.mgt.DefaultSecurityManager.login(DefaultSecurityManager.java:274)...Caused by: java.lang.IllegalArgumentException: Odd number of characters. at org.apache.shiro.codec.Hex.decode(Hex.java:128) at org.apache.shiro.codec.Hex.decode(Hex.java:107) at org.apache.shiro.codec.Hex.decode(Hex.java:95) at org.apache.shiro.authc.credential.HashedCredentialsMatcher.getCredentials(HashedCredentialsMatcher.java:353) at org.apache.shiro.authc.credential.HashedCredentialsMatcher.doCredentialsMatch(HashedCredentialsMatcher.java:380) at org.apache.shiro.realm.AuthenticatingRealm.assertCredentialsMatch(AuthenticatingRealm.java:600) at org.apache.shiro.realm.AuthenticatingRealm.getAuthenticationInfo(AuthenticatingRealm.java:581) at org.apache.shiro.authc.pam.ModularRealmAuthenticator.doSingleRealmAuthentication(ModularRealmAuthenticator.java:180) at org.apache.shiro.authc.pam.ModularRealmAuthenticator.doAuthenticate(ModularRealmAuthenticator.java:267) at org.apache.shiro.authc.AbstractAuthenticator.authenticate(AbstractAuthenticator.java:198) ... 26 more 参考资料 http://shiro.apache.org/10-minute-tutorial.html https://blog.csdn.net/weixin_38278878/article/details/81054672 https://blog.csdn.net/qq_35981283/article/details/78559375 https://mrbird.cc/tags/Shiro/ 代码获取https://github.com/lujiahao0708/LearnSpring Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/10/14/Shiro/03-Shiro%E8%87%AA%E5%AE%9A%E4%B9%89Realm%E5%8F%8A%E5%8A%A0%E5%AF%86/"},{"title":"《Elasticsearch技术解析与实战》Chapter 1.1：Elasticsearch入门和倒排索引","text":"1. 简介Elasticsearch是一个机遇Lucene构建的开源、分布式、RESTful接口全文搜索引擎。同时，Elasticsearch还是一个分布式文档数据库，能够扩展至数百个服务器存储以处理PB级数据，通常作为复杂搜索场景的首选利器。 Elasticsearch的优点： 横向可扩展性：只需要增加一台服务器，配置完毕即可加入集群。 分片机制提供更好的分布性：同一个索引分成多个分片，类似于HDFS的块机制，分而治之的方式提升处理效率。 高可用：提供复制机制，一个分片可以设置多个副本，在某台服务器宕机情况下，集群依旧可以工作，并在宕机服务器重启后恢复数据。 使用简单：开箱即用，快速搭建搜索服务。 Elasticsearch wiki:https://zh.wikipedia.org/wiki/Elasticsearch 2. 数据库搜索在数据量少的情况下可以当做搜索服务来使用，然而数据库归根结底是做持久化存储。如果数据量大就需要做搜索服务，底层数据还是关系数据库。我司老系统中有一个订单表，数据量已经高达两亿，客服等后台系统通常带有范围或批量条件等查询，这时数据库基本上就无法响应了，报警根本停不下来。因此，用数据库来实现搜索，性能差，可用性不高。 3. LuceneLucene是一个开源的全文搜索引擎工具包，其目的是为开发者提供一个简单工具包，以快速实现全文检索的功能。 Lucene wiki:https://zh.wikipedia.org/wiki/Lucene 4. 倒排索引倒排索引中的索引对象是文档或者文档集合中的单词等，用来存储这些单词在一个文档或者一组文档中的存储位置，是对文档或者文档集合的一种最常用的索引机制。搜索引擎的关键步骤就是建立倒排索引，下面介绍Lucene是如何建立倒排索引和相应的生成算法。 假设有两篇文章：文章1：Tom lives in Guangzhou, I live in Guangzhou too.文章2：He once lived in Shanghai. 4.1 取得关键词Lucene是基于关键词索引和查询的，首先要进行关键词提取： 分词：英文单词由空格分隔，较好处理；中文词语由于是连在一起的，需要进行特殊的分词处理（后面会介绍分词器相关知识）。 过滤无概念词语：英文中“in”“once”“too”等词没有实际意义；中文中“的”“是”等也无实际意义，这些无概念词语可以过滤掉。 统一大小写：“he”和“HE”表示的含义一样，所以单词需要统一大小写。 语义还原：通常用户查询“live”时希望能将“lives”和“lived”也查询出来，所以需要将“lives”和“lived”还原成“live”。 过滤标点符号 经过以上过滤，得到如下结果： 文章1关键词：tom live guangzhou i live guangzhou 文章2关键词：he live shanghai 4.2 建立倒排索引关键词建立完成后，就可以进行倒排索引建立了。过滤后的关系是：“文章号“对”文章中所有关键词“，倒排索引把这个关系倒过来变成：”关键词“对”拥有关键词的所有文章号“。 通常仅知道关键词在哪些文章中出现还不够，还需要知道关键词在文章中出现的次数和位置，通常有两种位置： 字符位置，即记录该词是文章中第几个字符（优点是显示并定位关键词快）。 关键词位置，即记录该词是文章中的第几个关键词（优点是节约索引空间、词组查询快），Lucene中记录的就是这种位置。 以上就是Lucene索引结构中最核心的部分，关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以使用二元搜索算法快速定位关键词。 4.3 实现Lucene将上面三列分别作为词典文件（Term Dictionary）、频率文件（frequencies）、位置文件（positions）保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。 Lucene中使用了field的概念，用于表达信息所在的位置（如标题中、文章中、url中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息，因为每个关键字一定属于一个或多个field。 4.4 压缩算法为了减小索引文件的大小，Lucene对索引还是用了压缩技术。首先，对词典文件中的关键词进行压缩，关键词压缩为&lt;前缀长度,后缀&gt;，例如：当前词为”阿拉伯语“，上一个词为”阿拉伯“,那么”阿拉伯语“压缩为&lt;3,语&gt;。其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减少数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节），上一文章号是16382，压缩后保存7（只用一个字节）。 压缩算法推荐阅读:https://www.cnblogs.com/dreamroute/p/8484457.html 4.5 实战查询单词”live“，Lucene先对词典二元查找，找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，可以达到毫秒级返回。而用普通的顺序匹配算法，不建立索引，而是对所有文章的内容进行字符串匹配，过程是很缓慢的，当数据量很大时，耗时更加严重。 5. 基础概念5.1 索引词（term）Elasticsearch中能够被索引的精确值。foo、Foo、FOO几个单词是不同的索引词。索引词可以通过term查询进行准确的搜索。 5.2 文本（text）文本会被拆分成一个个索引词存储在索引库中，为后续搜索提供支持。 5.3 分析（analysis）分析是将文本转换为索引词的过程，其结果依赖于分词器。 5.4 集群（cluster）集群由一个或多个节点组成，对外提供服务。Elasticsearch节点如果有相同的集群名称会自动加入到同一个集群，因此如果你拥有多个独立集群，每个集群都要设置不同的名称。 5.5 节点（node）节点是一个逻辑上独立的服务，是集群的一部分，可以存储数据，并参与集群的索引和搜索功能。 5.6 路由（routing）文档存储时是通过散列值进行计算，最终选择存储在主分片中，这个值默认是由文档的ID生成。 5.7 分片（shard）分片是单个Lucene实例，是Elasticsearch管理的比较底层的功能。当索引占用空间很大超过一个节点的物理存储，Elasticsearch将索引切分成多个分片，分散在不同的物理节点上，以解决单物理节点存储空间有限的问题。 5.8 主分片（primary shard）每个文档都存储在一个分片中，存储文档时系统会首先存储在主分片中，然后复制到不同的副本中。默认情况下一个索引拥有5个主分片，分片一旦建立，主分片数量就无法修改。 5.9 副本分片（replica shard）每个主分片有零个或多个副本，是主分片的复制，其主要目的是： 增加高可用性：当主分片失败时，某一副本分片提升为主分片 提高性能：副本分片数量可以动态配置，可以为主分片分担查询压力。 允许水平分割扩展数据 允许分配和并行操作，从而提高性能和吞吐量。 5.10 复制（replica）主分片的数据会复制到副本分片中，这样避免了单点问题，当某个节点发生故障，复制可以对故障进行转移，保证系统的高可用。 5.11 索引（index）索引是具有相同结构的文档合集。 5.12 类型（type）一个索引可以定义一个或多个类型，类型是索引的逻辑分区。 5.13 文档（document）文档是存储在Elasticsearch中的一个JSON格式的字符串，就像关系数据库中表的一行记录。 5.14 映射（mapping）映射像关系数据库中的表结构，每个索引都有一个映射，它定义了索引中的每一个字段类型。映射可以事先被定义，也可以在第一次存储文档时被自动识别。 5.15 字段（field）文档中包含零个或多个字段，字段可以是一个简单的值，也可以是一个数组或对象的嵌套结构。字段类似于关系数据库中表的列，每个字段都对应一个字段类型。 5.16 来源字段（source field）默认情况下源文档将被存储在_source字段中，查询时返回该字段。 5.17 主键（ID）ID是文件的唯一标识，如果未指定，系统会自动生成一个ID，文档的index/type/id必须是唯一的。 5.18 Elasticsearch核心概念 vs. 数据库核心概念 Elasticsearch 数据库 Document row 行 Type table 表 Index database 库 Tips本文同步发表在公众号，欢迎大家关注！😁后续笔记欢迎关注获取第一时间更新！","link":"/2019/04/12/%E3%80%8AElasticsearch%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Chapter%201.1%20Elasticsearch%E5%85%A5%E9%97%A8%E5%92%8C%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"},{"title":"《Java 8 in Action》Chapter 10：用Optional取代null","text":"1965年，英国一位名为Tony Hoare的计算机科学家在设计ALGOL W语言时提出了null引用的想法。ALGOL W是第一批在堆上分配记录的类型语言之一。Hoare选择null引用这种方式，“只是因为这种方法实现起来非常容易”。虽然他的设计初衷就是要“通过编译器的自动检测机制，确保所有使用引用的地方都是绝对安全的”，他还是决定为null引用开个绿灯，因为他认为这是为“不存在的值”建模最容易的方式。很多年后，他开始为自己曾经做过这样的决定而后悔不已，把它称为“我价值百万的重大事物”。实际上，Hoare的这段话低估了过去五十年来数百万程序员为修复空引用所耗费的代价。近十年出现的大多数现代程序设计语言1，包括Java，都采用了同样的设计方式，其原因是为了与更老的语言保持兼容，或者就像Hoare曾经陈述的那样，“仅仅是因为这样实现起来更加容易”。 1. 如何为确实的值建模123456789101112131415public class Person { private Car car; public Car getCar() { return car; } }public class Car { private Insurance insurance; public Insurance getInsurance() { return insurance; }}public class Insurance { private String name; public String getName() { return name; }}public String getCarInsuranceName(Person person) { return person.getCar().getInsurance().getName();} 上面这段代码的问题就在于，如果person没有车，就会造成空指针异常。 1.1 采用防御式检查减少NullPointerException1.1.1 深层质疑简单来说就是在需要的地方添加null检查 1234567891011public String getCarInsuranceName(Person person) { if (person != null) { Car car = person.getCar(); if (car != null) { Insurance insurance = car.getInsurance(); if (insurance != null) { return insurance.getName(); } } return \"Unknown\";} 上述代码不具备扩展性，同时还牺牲了代码的可读性。 1.1.2 过多的退出语句1234567891011121314public String getCarInsuranceName(Person person) { if (person == null) { return \"Unknown\"; } Car car = person.getCar(); if (car == null) { return \"Unknown\"; } Insurance insurance = car.getInsurance(); if (insurance == null) { return \"Unknown\"; } return insurance.getName();} 这种模式中方法的退出点有四处，使得代码的维护异常艰难。 1.2 null带来的种种问题 它是错误之源。 NullPointerException是目前Java程序开发中最典型的异常。它会使你的代码膨胀。 它让你的代码充斥着深度嵌套的null检查，代码的可读性糟糕透顶。 它自身是毫无意义的。 null自身没有任何的语义，尤其是是它代表的是在静态类型语言中以一种错误的方式对缺失变量值的建模。 它破坏了Java的哲学。 Java一直试图避免让程序员意识到指针的存在，唯一的例外是:null指针。 它在Java的类型系统上开了个口子。 null并不属于任何类型，这意味着它可以被赋值给任意引用类型的变量。这会导致问题， 原因是当这个变量被传递到系统中的另一个部分后，你将无法获知这个null变量最初赋值到底是什么类型。 1.3 其他语言中null的替代品 Groovy中的安全导航操作符 Haskell中的Maybe类型 Scala中的Option[T] 2. Optional类入门变量存在时，Optional类只是对类简单封装。变量不存在时，缺失的值会被建模成一个“空”的Optional对象，由方法Optional.empty()返回。Optional.empty()方法是一个静态工厂方法，它返回Optional类的特定单一实例。 引入Optional类的意图并非要消除每一个null引用，相反的是，它的目标是帮助开发者更好地设计出普适的API。 3. 应用Optional的几种模式3.1 创建Optional对象3.1.1 声明一个空的Optional正如前文已经提到，你可以通过静态工厂方法Optional.empty，创建一个空的Optional对象: 1Optional&lt;Car&gt; optCar = Optional.empty(); 3.1.2 依据一个非空值创建Optional你还可以使用静态工厂方法Optional.of，依据一个非空值创建一个Optional对象: 1Optional&lt;Car&gt; optCar = Optional.of(car); 如果car是一个null，这段代码会立即抛出一个NullPointerException，而不是等到你试图访问car的属性值时才返回一个错误。 3.2.3 可接受null的Optional最后，使用静态工厂方法Optional.ofNullable，你可以创建一个允许null值的Optional对象: 1Optional&lt;Car&gt; optCar = Optional.ofNullable(car); 如果car是null，那么得到的Optional对象就是个空对象。 3.2 使用map从Optional对象中提取和转换值从对象中提取信息是一种比较常见的模式。 1234567String name = null; if(insurance != null){ name = insurance.getName(); }为了支持这种模式，Optional提供了一个map方法。Optional&lt;Insurance&gt; optInsurance = Optional.ofNullable(insurance); Optional&lt;String&gt; name = optInsurance.map(Insurance::getName); 3.3 使用flatMap链接Optional对象使用流时，flatMap方法接受一个函数作为参数，这个函数的返回值是另一个流。 这个方法会应用到流中的每一个元素，最终形成一个新的流的流。但是flagMap会用流的内容替换每个新生成的流。换句话说，由方法生成的各个流会被合并或者扁平化为一个单一的流。 12345public String getCarInsuranceName(Optional&lt;Person&gt; person) { return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse(\"Unknown\");} 3.4 默认行为及解引用Optional对象 get()是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量值，否则就抛出一个NoSuchElementException异常。所以，除非你非常确定Optional变量一定包含值，否则使用这个方法是个相当糟糕的主意。此外，这种方式即便相对于嵌套式的null检查，也并未体现出多大的改进。 orElse(T other)是我们在代码清单10-5中使用的方法，正如之前提到的，它允许你在 Optional对象不包含值时提供一个默认值。 orElseGet(Supplier&lt;? extends T&gt; other)是orElse方法的延迟调用版，Supplier 方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作，你应该考虑采用这种方式(借此提升程序的性能)，或者你需要非常确定某个方法仅在 Optional为空时才进行调用，也可以考虑该方式(这种情况有严格的限制条件)。 orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)和get方法非常类似，它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制􏳵希望抛出的异常类型。 ifPresent(Consumer&lt;? super T&gt;)让你能在变量值存在时执行一个作为参数传入的方法，否则就不进行任何操作。 3.5 两个Optional对象的组合1234567public Optional&lt;Insurance&gt; nullSafeFindCheapestInsurance(Optional&lt;Person&gt; person, Optional&lt;Car&gt; car) { if (person.isPresent() &amp;&amp; car.isPresent()) { return Optional.of(findCheapestInsurance(person.get(), car.get())); } else { return Optional.empty(); }} 3.6 使用filter剔除特定的值filter方法接受一个谓词作为参数。如果Optional对象的值存在，并且它符合谓词的条件， filter方法就返回其值;否则它就返回一个空的Optional对象。 12345678Insurance insurance = ...;if(insurance != null &amp;&amp; \"CambridgeInsurance\".equals(insurance.getName())){ System.out.println(\"ok”);}Optional&lt;Insurance&gt; optInsurance = ...;optInsurance.filter(insurance -&gt; \"CambridgeInsurance\".equals(insurance.getName())) .ifPresent(x -&gt; System.out.println(\"ok\")); Optional类中的方法进行了分类和概括: 4. 使用Optional的实战示例4.1 用Optional封装可能为null的值1Optional&lt;Object&gt; value = Optional.ofNullable(map.get(\"key\")); 每次你希望安全地对潜在为null的对象进行转换，将其替换为Optional对象时，都可以考虑使用这种方法。 4.2 异常与Optional的对比1234567public static Optional&lt;Integer&gt; stringToInt(String s) {try {return Optional.of(Integer.parseInt(s)); } catch (NumberFormatException e) { return Optional.empty(); }} 我们的建议是，你可以将多个类似的方法封装到一个工具类中，让我们称之为OptionalUtility。通过这种方式，你以后就能直接调用OptionalUtility.stringToInt方法，将String转换为一个Optional对象，而不再需要记得你在其中封装了笨拙的 try/catch的逻辑了。 4.3 把所有内容结合起来12345678910111213141516171819public int readDuration(Properties props, String name) { String value = props.getProperty(name); if (value != null) { try { int i = Integer.parseInt(value); if (i &gt; 0) { return i; } } catch (NumberFormatException nfe) { } } return 0; }// 优化版本public int readDuration(Properties props, String name) { return Optional.ofNullable(props.getProperty(name)) .flatMap(OptionalUtility::stringToInt) .filter(i -&gt; i &gt; 0) .orElse(0);} 5. 小结这一章中，你学到了以下的内容。 null引用在上被引入到程序设计语言中，目的是为了表示变量值的。 Java 8中引入了一个新的类java.util.Optional，对存在或缺失的变量值进行建模。 你可以使用静态工厂方法Optional.empty、Optional.of以及Optional.ofNullable创建Optional对象。 Optional类支持多种方法，比如map、flatMap、filter，它们在概念上与Stream类中对应的方法十分相似。 使用Optional会使你更积极地解引用Optional对象，以应对变量值缺失的问题，最终，你能更有效地止代码中出现不而至的空指针异常。 使用Optional能帮助你设计更好的API，用户只需要阅读方法签名，就能了解该方法是否接受一个Optional类型的值。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/22/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%2010%EF%BC%9A%E7%94%A8Optional%E5%8F%96%E4%BB%A3null/"},{"title":"《Java 8 in Action》Chapter 2：通过行为参数化传递代码","text":"你将了解行为参数化，这是Java 8非常依赖的一种软件开发模式，也是引入 Lambda表达式的主要原因。行为参数化就是可以帮助你处理频繁变更的需求的一种软件开发模式。一言以蔽之，它意味 着拿出一个代码块，把它准备好却不去执行它。这个代码块以后可以被你程序的其他部分调用。本章通过筛选苹果这个实际需求来一步步引出Lambda表达式，同时我也会把代码贴出来，读完你会看到代码是如何一步一步的向Lambda转化。多代码来袭，保护我方ADC！！ 代码演化1.实习生版本12345678910111213141516171819202122232425package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 筛选绿色苹果 * @author lujiahao * @date 2019-02-19 18:28 */public class FilterAppleV0 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); List&lt;Apple&gt; greenAppleList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { if (\"green\".equals(apple.getColor())) { greenAppleList.add(apple); } } System.out.println(\"原集合:\" + appleList); System.out.println(\"绿苹果集合:\" + greenAppleList); }} 这种之所以称之为实习生版本，是因为此种写法比较初级，所有代码在一个方法中实现。没有进行方法的抽取，不符合面向对象的理念，希望大家在编码工作时避免这种写法。 2.方法抽取版本1234567891011121314151617181920212223242526272829303132333435package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 筛选绿色苹果 * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV1 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filterGreenApples(appleList); System.out.println(\"绿苹果集合:\" + filterGreenApples); } /** * 筛选绿色苹果 * @param appleList * @return */ public static List&lt;Apple&gt; filterGreenApples(List&lt;Apple&gt; appleList) { List&lt;Apple&gt; resultList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { if (\"green\".equals(apple.getColor())) { resultList.add(apple); } } return resultList; }} 此版本对筛选绿色苹果的方法进行了简单的抽取，相较于上个版本有了很大的提升。然而，如果需求方改变想法，想筛选红色的苹果。复制filterGreenApples() 方法并将其中的绿色筛选条件改为红色，确实可以实现。但是，这样有太多重复的模板代码，不是良好的编码规范。因此，我们将筛选条件颜色进一步抽象化。 3.筛选条件作为参数传入1234567891011121314151617181920212223242526272829303132333435363738package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 需要判断的属性作为参数传入 * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV2 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filterApples(appleList, \"green\"); System.out.println(\"筛选绿色苹果:\" + filterGreenApples); List&lt;Apple&gt; filterRedApples = filterApples(appleList, \"red\"); System.out.println(\"筛选红色苹果:\" + filterRedApples); } /** * 筛选特定颜色苹果 * @param appleList * @return */ public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; appleList, String color) { List&lt;Apple&gt; resultList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { if (color.equals(apple.getColor())) { resultList.add(apple); } } return resultList; }} 满足了颜色的筛选条件，然而需求方又灵光一闪，筛选大于150克的苹果。无论是复制filterApples() 方法，还是增加重量作为参数传入，都是不推荐的编码习惯。第一种方法复制了大部分的代码来实现遍历，它打破了DRY（Don’t Repeat Yourself）的软件工程原则；第二种方法并不能考虑到所有情况，并且每次修改都对原有代码产生了影响，无法做到修改对外封闭的原则。 4.行为参数化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 行为参数化 * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV3 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filterApples(appleList, new AppleGreenColorPredicate()); System.out.println(\"筛选绿色苹果:\" + filterGreenApples); List&lt;Apple&gt; filterHeavyApples = filterApples(appleList, new AppleHeavyWeightPredicate()); System.out.println(\"筛选重量大于150苹果:\" + filterHeavyApples); } /** * 筛选绿色苹果 * @param appleList * @return */ public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; appleList, ApplePredicate predicate) { List&lt;Apple&gt; resultList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { // 谓词对象封装了条件 if (predicate.filter(apple)) { resultList.add(apple); } } return resultList; } public interface ApplePredicate { boolean filter(Apple apple); } public static class AppleHeavyWeightPredicate implements ApplePredicate { @Override public boolean filter(Apple apple) { return apple.getWeight() &gt; 150; } } public static class AppleGreenColorPredicate implements ApplePredicate { @Override public boolean filter(Apple apple) { return \"green\".equals(apple.getColor()); } }} 我们对苹果的所有属性进行更高一个层次的抽象建模，通过定义ApplePredicate 接口，AppleHeavyWeightPredicate 和 AppleGreenColorPredicate 分别实现该接口来达到进行不同的筛选功能。客户端调用中创建不同的实现类，对于filterApple() 方法而言，是传入了不同的行为，即行为参数化。行为参数化：让方法接受多种行为(或战略)作为参数，并在内部使用，来完成不同的行为。其原理如下图所示： 5.匿名内部类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 使用匿名类 * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV4 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filterApples(appleList, new ApplePredicate() { @Override public boolean filter(Apple apple) { return \"green\".equals(apple.getColor()); } }); System.out.println(\"筛选绿色苹果:\" + filterGreenApples); List&lt;Apple&gt; filterHeavyApples = filterApples(appleList, new ApplePredicate() { @Override public boolean filter(Apple apple) { return apple.getWeight() &gt; 150; } }); System.out.println(\"筛选重量大于150苹果:\" + filterHeavyApples); } /** * 筛选绿色苹果 * @param appleList * @return */ public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; appleList, ApplePredicate predicate) { List&lt;Apple&gt; resultList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { // 谓词对象封装了条件 if (predicate.filter(apple)) { resultList.add(apple); } } return resultList; } public interface ApplePredicate { boolean filter(Apple apple); }} 当每次有新的查询需求提出，都要新建一个实现类，随着条件越来越多，实现类的数量也在急剧上升。此时，通过使用匿名内部类的方式，来减少实现类过多的模板代码。然而，匿名内部类并非完美，第一，它往往很笨重，因为它占用了很多空间；第二，很多程序员觉得它用起来很让人费解。 6.使用 Lambda 表达式12345678910111213141516171819202122232425262728293031323334353637383940414243package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.List;/** * 使用Lambda表达式 * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV5 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filterApples(appleList, (Apple apple) -&gt; \"green\".equals(apple.getColor())); System.out.println(\"筛选绿色苹果:\" + filterGreenApples); List&lt;Apple&gt; filterHeavyApples = filterApples(appleList, (Apple apple) -&gt; apple.getWeight() &gt; 150); System.out.println(\"筛选重量大于150苹果:\" + filterHeavyApples); } /** * 筛选绿色苹果 * @param appleList * @return */ public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; appleList, ApplePredicate predicate) { List&lt;Apple&gt; resultList = new ArrayList&lt;&gt;(); for (Apple apple : appleList) { // 谓词对象封装了条件 if (predicate.filter(apple)) { resultList.add(apple); } } return resultList; } public interface ApplePredicate { boolean filter(Apple apple); }} 不得不承认这代码看上去比先前干净很多，而且它看起来更像是在陈述问题本身，更加通俗易懂。 7.List 类型抽象化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.lujiahao.learnjava8.chapter2;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.function.*;/** * List类型抽象话 * * @author lujiahao * @date 2019-02-19 18:30 */public class FilterAppleV6 { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); List&lt;Apple&gt; filterGreenApples = filter(appleList, (Apple apple) -&gt; \"green\".equals(apple.getColor())); System.out.println(\"筛选绿色苹果:\" + filterGreenApples); System.out.println(\"=============================================\"); List&lt;Integer&gt; numberList = Arrays.asList(1, 2, 3); System.out.println(\"原集合:\" + numberList); List&lt;Integer&gt; numbers = filter(numberList, (Integer i) -&gt; i % 2 == 0); System.out.println(\"能被2整除的数:\" + numbers); } /** * 筛选绿色苹果 */ public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; predicate) { List&lt;T&gt; resultList = new ArrayList&lt;&gt;(); for (T t : list) { // 谓词对象封装了条件 if (predicate.filter(t)) { resultList.add(t); } } return resultList; } public interface Predicate&lt;T&gt; { boolean filter(T t); }} 在通往抽象的路上，我们还可以更进一步。目前，filterApples方法还只适用于Apple。还可以将List类型抽象化，从而支持所有类型。 8.演化小结这一路演化中我们可以看出代码是如何一步一步转化的更加简洁更加优雅，对此我们进行总结： 实例1.用 Comparator 排序123456789101112131415161718192021222324252627package com.lujiahao.learnjava8.chapter2;import java.util.Comparator;import java.util.List;/** * 用 Comparator 排序 * @author lujiahao * @date 2019-03-02 18:34 */public class ComparatorDemo { public static void main(String[] args) { List&lt;Apple&gt; appleList = DataUtil.generateApples(); System.out.println(\"原集合:\" + appleList); appleList.sort(new Comparator&lt;Apple&gt;() { @Override public int compare(Apple o1, Apple o2) { return o1.getWeight().compareTo(o2.getWeight()); } }); System.out.println(\"按重量升序:\" + appleList); appleList.sort((Apple a1, Apple a2) -&gt; a1.getColor().compareTo(a2.getColor())); System.out.println(\"按颜色字典排序:\" + appleList); }} 2.用 Runnable 执行代码块123456789101112131415161718192021222324252627package com.lujiahao.learnjava8.chapter2;/** * 用 Runnable 执行代码块 * @author lujiahao * @date 2019-03-02 18:42 */public class RunnableDemo { public static void main(String[] args) { Thread t = new Thread(new Runnable() { @Override public void run() { System.out.println(\"Hello Java 8!\"); } }); t.start(); Thread t1 = new Thread(() -&gt; System.out.println(\"Hello Lambda!\")); t1.start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } }} 3.GUI 事件处理12345678Button button = new Button(“Send”);button.setOnAction(new EventHandler&lt;ActionEvent&gt;() { public void handle(ActionEvent event) { lable.setText(“Send!!”); }}button.setOnAction((ActionEvent event) -&gt; lable.setText(“Send!!”)); 小猿之前搞安卓开发的，各种控件的监听都是这个样子，想想以前各种代码啊啊啊~ 总结以下是你应从本章中学到的关键概念。 行为参数化，就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力。 行为参数化可让代码更好地适应不断变化的要求，减轻未来的工作量。 传递代码，就是将新行为作为参数传递给方法。但在Java 8之前这实现起来很啰嗦。为接口声明许多只用一次的实体类而造成的啰嗦代码，在Java 8之前可以用匿名类来减少。 Java API包含很多可以用不同行为进行参数化的方法，包括排序、线程和GUI处理。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/03/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%202%EF%BC%9A%E9%80%9A%E8%BF%87%E8%A1%8C%E4%B8%BA%E5%8F%82%E6%95%B0%E5%8C%96%E4%BC%A0%E9%80%92%E4%BB%A3%E7%A0%81/"},{"title":"《Java 8 in Action》Chapter 6：用流收集数据","text":"1. 收集器简介collect() 接收一个类型为 Collector 的参数，这个参数决定了如何把流中的元素聚合到其它数据结构中。Collectors 类包含了大量常用收集器的工厂方法，toList() 和 toSet() 就是其中最常见的两个，除了它们还有很多收集器，用来对数据进行对复杂的转换。 指令式代码和函数式对比： 要是做多级分组，指令式和函数式之间的区别就会更加明显:由于需要好多层嵌套循环和条件，指令式代码很快就变得更难阅读、更难维护、更难修改。相比之下，函数式版本只要再加上 一个收集器就可以轻松地增强 预定义收集器，也就是那些可以从Collectors类提供的工厂方法(例如groupingBy)创建的收集器。它们主要提供了三大功能: 将流元素归约和汇总为一个值 元素分组 元素分区 2. 使用收集器在需要将流项目重组成集合时，一般会使用收集器(Stream方法collect 的参数)。再宽泛一点来说，但凡要把流中所有的项目合并成一个结果时就可以用。这个结果可以是任何类型，可以复杂如代表一棵树的多级映射，或是简单如一个整数。 3. 收集器实例3.1 流中最大值和最小值Collectors.maxBy和 Collectors.minBy，来计算流中的最大或最小值。这两个收集器接收一个Comparator参数来比较流中的元素。你可以创建一个Comparator来根据所含热量对菜肴进行比较： 123456System.out.println(\"找出热量最高的食物:\");Optional&lt;Dish&gt; collect = DataUtil.genMenu().stream().collect(Collectors.maxBy(Comparator.comparingInt(Dish::getCalories)));collect.ifPresent(System.out::println);System.out.println(\"找出热量最低的食物:\");Optional&lt;Dish&gt; collect1 = DataUtil.genMenu().stream().collect(Collectors.minBy(Comparator.comparingInt(Dish::getCalories)));collect1.ifPresent(System.out::println); 3.2 汇总求和Collectors类专门为汇总提供了一个工厂方法:Collectors.summingInt。它可接受一个把对象映射为求和所需int的函数，并返回一个收集器;该收集器在传递给普通的collect方法后即执行我们需要的汇总操作。举个例子来说，你可以这样求出菜单列表的总热量: 123456Integer collect = DataUtil.genMenu().stream().collect(Collectors.summingInt(Dish::getCalories));System.out.println(\"总热量:\" + collect);Double collect1 = Arrays.asList(0.1, 0.2, 0.3).stream().collect(Collectors.summingDouble(Double::doubleValue));System.out.println(\"double和:\" + collect1);Long collect2 = Arrays.asList(1L, 2L, 3L).stream().collect(Collectors.summingLong(Long::longValue));System.out.println(\"long和:\" + collect2); 3.3 汇总求平均值Collectors.averagingInt，averagingLong和averagingDouble可以计算数值的平均数： 123456Double collect = DataUtil.genMenu().stream().collect(Collectors.averagingInt(Dish::getCalories));System.out.println(\"平均热量:\" + collect);Double collect1 = Arrays.asList(0.1, 0.2, 0.3).stream().collect(Collectors.averagingDouble(Double::doubleValue));System.out.println(\"double 平均值:\" + collect1);Double collect2 = Arrays.asList(1L, 2L, 3L).stream().collect(Collectors.averagingLong(Long::longValue));System.out.println(\"long 平均值:\" + collect2); 3.4 汇总合集你可能想要得到两个或更多这样的结果，而且你希望只需一次操作就可以完成。在这种情况下，你可以使用summarizingInt工厂方法返回的收集器。例如，通过一次summarizing操作你可以就数出菜单中元素的个数，并得到热量总和、平均值、最大值和最小值: 123456IntSummaryStatistics collect = DataUtil.genMenu().stream().collect(Collectors.summarizingInt(Dish::getCalories));System.out.println(\"int:\" + collect);DoubleSummaryStatistics collect1 = Arrays.asList(0.1, 0.2, 0.3).stream().collect(Collectors.summarizingDouble(Double::doubleValue));System.out.println(\"double:\" + collect1);LongSummaryStatistics collect2 = Arrays.asList(1L, 2L, 3L).stream().collect(Collectors.summarizingLong(Long::longValue));System.out.println(\"long:\" + collect2); 3.5 连接字符串joining工厂方法返回的收集器会把对流中每一个对象应用toString方法得到的所有字符串连接成一个字符串。 1String collect = DataUtil.genMenu().stream().map(Dish::getName).collect(Collectors.joining()); 请注意，joining在内部使用了StringBuilder来把生成的字符串逐个追加起来。幸好，joining工厂方法有一个重载版本可以接受元素之间的分界符，这样你就可以得到一个都好分隔的名称列表: 1String collect1 = DataUtil.genMenu().stream().map(Dish::getName).collect(Collectors.joining(\",\")); 4. 广义的归约汇总所有收集器，都是一个可以用reducing工厂方法定义的归约过程的特殊情况而已。Collectors.reducing工厂方法是所有这些特殊情况的一般化。它需要三个参数: 第一个参数是归约操作的起始值，也是流中没有元素时的返回值，所以很显然对于数值和而言0是一个合适的值。 第二个参数就是你在6.2.2节中使用的函数，将菜肴转换成一个表示其所含热量的int。 第三个参数是一个BinaryOperator，将两个项目累积成一个同类型的值。这里它就是对两个int求和。 下面两个是相同的操作： 12Optional&lt;Dish&gt; collect = DataUtil.genMenu().stream().collect(Collectors.maxBy(Comparator.comparingInt(Dish::getCalories)));Optional&lt;Dish&gt; mostCalorieDish = menu.stream().collect(reducing((d1, d2) -&gt; d1.getCalories() &gt; d2.getCalories() ? d1 : d2)); 5. 分组用Collectors.groupingBy工厂方法返回的收集器就可以轻松地完成任务： 1Map&lt;Dish.Type, List&lt;Dish&gt;&gt; collect = DataUtil.genMenu().stream().collect(Collectors.groupingBy(Dish::getType)); 给groupingBy方法传递了一个Function(以方法引用的形式)，它提取了流中每 一道Dish的Dish.Type。我们把这个Function叫作分类函数，因为它用来把流中的元素分成不同的组。分组操作的结果是一个Map，把分组函数返回的值作为映射的键，把流中所有具有这个分类值的项目的列表作为对应的映射值。 5.1 多级分组要实现多级分组，我们可以使用一个由双参数版本的Collectors.groupingBy工厂方法创建的收集器，它除了普通的分类函数之外，还可以接受collector类型的第二个参数。那么要进行二级分组的话，我们可以把一个内层groupingBy传递给外层groupingBy，并定义一个为流中项目分类的二级标准： 12345678910Map&lt;Dish.Type, Map&lt;CaloricLevel, List&lt;Dish&gt;&gt;&gt; collect1 = DataUtil.genMenu().stream().collect( Collectors.groupingBy(Dish::getType, Collectors.groupingBy(dish -&gt; { if (dish.getCalories() &lt;= 400) { return CaloricLevel.DIET; } else if (dish.getCalories() &lt;= 700) { return CaloricLevel.NORMAL; } else return CaloricLevel.FAT; }))); 5.2 按子组收集数据传递给第一个groupingBy的第二个收集器可以是任何类型，而不一定是另一个groupingBy。例如，要数一数菜单中每类菜有多少个，可以传递counting收集器作为groupingBy收集器的第二个参数: 1Map&lt;Dish.Type, Long&gt; collect2 = DataUtil.genMenu().stream().collect(Collectors.groupingBy(Dish::getType, Collectors.counting())); 还要注意，普通的单参数groupingBy(f)(其中f是分类函数)实际上是groupingBy(f, toList())的简便写法。把收集器返回的结果转换为另一种类型，你可以使用 Collectors.collectingAndThen工厂方法返回的收集器，接受两个参数：要转换的收集器以及转换函数，并返回另一个收集器。 12345Map&lt;Dish.Type, Dish&gt; collect3 = DataUtil.genMenu().stream().collect(Collectors.groupingBy(Dish::getType, Collectors.collectingAndThen( Collectors.maxBy(Comparator.comparingInt(Dish::getCalories)), Optional::get ))); 这个操作放在这里是安全的，因为reducing收集器永远都不会返回Optional.empty()。 常常和groupingBy联合使用的另一个收集器是mapping方法生成的。这个方法接受两个参数:一个函数对流中的元素做变换，另一个则将变换的结果对象收􏰁起来。其目的是在累加之前对每个输入元素应用一个映射函数，这样就可以让接受特定类型元素的收􏰁器适应不同类型的对象。我们来看一个使用这个收集器的实际例子。比方说你想要知道，对于每种类型的Dish， 菜单中都有哪些CaloricLevel。 1234567891011Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; collect4 = DataUtil.genMenu().stream().collect(Collectors.groupingBy( Dish::getType, Collectors.mapping( dish -&gt; { if (dish.getCalories() &lt;= 400) { return CaloricLevel.DIET; } else if (dish.getCalories() &lt;= 700) { return CaloricLevel.NORMAL; } else return CaloricLevel.FAT; }, Collectors.toSet() ))); 6. 分区分区是分组的特殊情况:由一个谓词(返回一个布尔值的函数)作为分类函数，它称分类函数。分区函数返回一个布尔值，这意味着得到的分组Map的键类型是Boolean，于是它最多可以 分为两组——true是一组，false是一组。例如，如果想要把菜按照素食和非素食分开: 123456Map&lt;Boolean, List&lt;Dish&gt;&gt; collect = DataUtil.genMenu().stream().collect(Collectors.partitioningBy(Dish::isVegetarian));System.out.println(collect.get(true));partitioningBy 工厂方法有一个重载版本，可以像下面这样传递第二个收集器:Map&lt;Boolean, Map&lt;Dish.Type, List&lt;Dish&gt;&gt;&gt; collect1 = DataUtil.genMenu().stream().collect(Collectors.partitioningBy( Dish::isVegetarian, Collectors.groupingBy(Dish::getType))); 分区看作分组一种特殊情况。 7. Collectors类的静态工厂方法 8. 收集器接口1234567public interface Collector&lt;T, A, R&gt; { Supplier&lt;A&gt; supplier(); BiConsumer&lt;A, T&gt; accumulator(); Function&lt;A, R&gt; finisher(); BinaryOperator&lt;A&gt; combiner(); Set&lt;Characteristics&gt; characteristics();} 本列表适用以下定义: T是流中要收集的项目的泛型。 A是累加器的类型，累加器是在收集过程中用于累积部分结果的对象。 R是手机操作得到的对象(通常但并不一定是集合)的类型。 8.1 建立新的结果容器:supplier方法supplier方法必须返回一个结果为空的Supplier，也就是一个无参数函数，在调用时它会创建一个空的累加器实例，供数据收集过程使用。 8.2 将元素添加到结果容器:accumulator方法accumulator方法会返回执行归约操作的函数。当遍历到流中第n个元素时，这个函数执行时会有两个参数:保存归约结果的累加器(已收集了流中的前n-1个项目)，还有第n个元素本身。该函数将返回void，因为累加器是原位更新，即函数的执行改变了它的内部状态以体现遍历的元素的效果。 8.3 对结果容器应用最终转换:finisher方法在遍历完流后，finisher方法必须返回在累积过程的最后要调用的一个函数，以便将累加器对象转换为整个集合操作的最终结果。顺序归约过程的逻辑步骤: 8.4 合并两个结果容器:combiner方法四个方法中的最后一个——combiner方法会返回一个供归约操作使用的函数，它定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器要如何合并: 原始流会以递归方式拆分为子流，直到定义流是否需要进一步拆分的一个条件为非(如果分布式工作单位太小，并行计算往往比顺序计算要慢，而且要是生成的并行任务比处理器内核数多很多的话就毫无意义了)。 现在，所有的子流都可以并行处理，即对每个子流应用图6-7所示的顺序归约算法。 最后，使用收集器combiner方法返回的函数，将所有的部分结果两两合并。这时会把原始流每次拆分时得到的子流对应的结果合并起来 8.5 characteristics方法最后一个方法——characteristics会返回一个不可变的Characteristics集合，它定义了收集器的行为——尤其是关于流是否可以并行归约，以及可以使用哪些优化的提示。Characteristics是一个包含三个项目的枚举。 UNORDERED——归约结果不受流中项目的遍历和累积顺序的影响。 CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行归约流。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可以并行归约。 IDENTITY_FINISH——这表明完成器方法返回的函数是一个恒等函数，可以跳过。这种情况下，累加器对象将会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查地转换为结果R是安全的。 9. 小结 collect是一个终端操作，它接受的参数是将流中元素累积到汇总结果的各种方式(称为收集器)。 预定义收集器包括将流元素归约和汇总到一个值，例如计算最小值、最大值或平均值。这些收集器总结在表6-1中。 预定义收集器可以用groupingBy对流中元素进行分组，或用partitioningBy进行分区。 收集器可以高效地复合起来，进行多级分组、分区和归约。 你可以实现Collector接口中定义的方法来开发你自己的收集器。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/16/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%206%EF%BC%9A%E7%94%A8%E6%B5%81%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE/"},{"title":"《Java 8 in Action》Chapter 3：Lambda表达式","text":"1. Lambda简介可以把Lambda表达式理解为简洁地表示可传递的匿名函数的一种方式：它没有名称，但它有参数列表、函数主体、返回类型，可能还有一个可以抛出的异常列表。 匿名——我们说匿名，是因为它不像普通的方法那样有一个明确的名称:写得少而想得多! 函数——我们说它是函数，是因为Lambda函数不像方法那样属于某个特定的类。但和方法一样，Lambda有参数列表、函数主体、返回类型，还可能有可以抛出的异常列表。 传递——Lambda表达式可以作为参数传递给方法或存储在变量中。 简洁——无需像匿名类那样写很多模板代码。 2. Lambda写法(parameters) -&gt; expression 或 (parameters) -&gt; { statements; }eg：(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());Lambda表达式有三个部分: 参数列表——这里它采用了Comparator中compare方法的参数，两个Apple。 箭头——箭头-&gt;把参数列表与Lambda主体分隔开。 Lambda主体——比较两个Apple的重量。表达式就是Lambda的返回值了。 3. 函数式接口和函数描述符函数式接口就是只定义一个抽象方法的接口。接口上标有@FunctionalInterface表示该接口会设计成 一个函数式接口，如果你用@FunctionalInterface定义了一个接口，而它却不是函数式接口的话，编译器将返回一个提示原因的错误。接口现在还可以拥有默认方法(即在类没有对方法进行实现时， 其主体为方法提供默认实现的方法)。哪怕有很多默认方法，只要接口只定义了一个抽象方法，它就仍然是一个函数式接口。 函数式接口的抽象方法的签名就是Lambda表达式的签名。我们将这种抽象方法叫作：函数描述符。例如，Runnable接口可以看作一个什么也不接受什么也不返回(void)的函数的签名，因为它只有一个叫作run的抽象方法，这个方法什么也不接受，什么也不返回(void)。 4. 三种常用的函数式接口4.1 Predicate1234567891011121314151617/** * Represents a predicate (boolean-valued function) of one argument. * &lt;p&gt;This is a &lt;a href=\"package-summary.html\"&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * @param &lt;T&gt; the type of the input to the predicate * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t);} Predicate的英文示意是：谓词。Predicate接口定义了一个名叫test的抽象方法，它接受泛型T对象，并返回一个boolean。 4.2 Consumer1234567891011121314151617/*** Represents an operation that accepts a single input argument and returns no* result. Unlike most other functional interfaces, {@code Consumer} is expected* to operate via side-effects.* &lt;p&gt;This is a &lt;a href=\"package-summary.html\"&gt;functional interface&lt;/a&gt;* whose functional method is {@link #accept(Object)}.* @param &lt;T&gt; the type of the input to the operation* @since 1.8*/@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * @param t the input argument */ void accept(T t);} Consumer的英文示意是：消费者。Consumer接口定义了一个名叫accept的抽象方法，它接受泛型T对象，并没有返回任何值。 4.3 Function1234567891011121314151617/*** Represents a function that accepts one argument and produces a result.* &lt;p&gt;This is a &lt;a href=\"package-summary.html\"&gt;functional interface&lt;/a&gt;* whose functional method is {@link #apply(Object)}.* @param &lt;T&gt; the type of the input to the function* @param &lt;R&gt; the type of the result of the function* @since 1.8*/@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * @param t the function argument * @return the function result */ R apply(T t);} Function的英文示意是：功能。Function接口定义了一个名叫apply的抽象方法，它接受泛型T对象，并返回一个泛型R的对象。 Java还有一个自动装箱机制来帮助程序员执行这一任务:装箱和拆箱操作是自动完成的。但这在性能方面是要付出代价的。装箱后的值本质上就是把原始类型包裹起来，并保存在堆里。因此，装箱后的值需要更多的内存，并需要额外的内存搜索来获取被包裹的原始值。Java 8为我们前面所说的函数式接口带来了一个专门的版本，以便在输入和输出都是原始类型时避免自动装箱的操作。 4.4 Java 8中的常用函数式接口 5. 类型检查、类型推断以及限制5.1 类型检查Lambda的类型是从使用Lambda的上下文推断出来的。上下文(比如，接受它传递的方法的参数，或接受它的值的局部变量)中Lambda表达式需要的类型称为目标类型。类型检查过程可以分解为如下所示。 首先，你要找出filter方法的声明。 第二，要求它是Predicate(目标类型)对象的第二个正式参数。 第三，Predicate是一个函数式接口，定义了一个叫作test的抽象方法。 第四，test方法描述了一个函数描述符，它可以接受一个Apple，并返回一个boolean. 最后，filter的任何实际参数都必须匹配这个要求。 这段代码是有效的，因为我们所传递的Lambda表达式也同样接受Apple为参数，并返回一个 boolean。请注意，如果Lambda表达式抛出一个异常，那么抽象方法所声明的throws语句也必 须与之匹配。有了目标类型的概念，同一个Lambda表达式就可以与不同的函数式接口联系起来，只要它 们的抽象方法签名能够兼容。比如，前面提到的Callable和PrivilegedAction，这两个接口都代表着什么也不接受且返回一个泛型T的函数。 因此，下面两个赋值是有效的: 12Callable&lt;Integer&gt; c = () -&gt; 42;PrivilegedAction&lt;Integer&gt; p = () -&gt; 42; 特殊的void兼容规则如果一个Lambda的主体是一个语句表达式， 它就和一个返回void的函数描述符兼容(当然需要参数列表也兼容)。例如，以下两行都是合法的，尽管List的add方法返回了一个 boolean，而不是Consumer上下文(T -&gt; void)所要求的void: 1234// Predicate返回了一个boolean Predicate&lt;String&gt; p = s -&gt; list.add(s); // Consumer返回了一个void Consumer&lt;String&gt; b = s -&gt; list.add(s); 5.2 类型推断Java编译器会从上下文(目标类型)推断出用什么函数式接 口来配合Lambda表达式，这意味着它也可以推断出适合Lambda的签名，因为函数描述符可以通过目标类型来得到。这样做的好处在于，编译器可以了解Lambda表达式的参数类型，这样就可以在Lambda语法中省去标注参数类型。 1234// 没有类 型推断Comparator&lt;Apple&gt; c = (Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); // 有类型推断Comparator&lt;Apple&gt; c = (a1, a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); 5.3 使用局部变量Lambda表达式 也允许使用自由变量(不是参数，而是在外层作用域中定义的变量)，就像匿名类一样。 它们被 称作捕获Lambda。Lambda捕获的局部变量必须显式声明为final， 或事实上是final。换句话说，Lambda表达式只能捕获指派给它们的局部变量一次。 第一，实例变量和局部变量背后的实现有一 个关键不同。实例变量都存储在堆中，而局部变量则保存在栈上。如果Lambda可以直接访问局部变量，而且Lambda是在一个线程中使用的，则使用Lambda的线程，可能会在分配该变量的线程将这个变量收回之后，去访问该变量。因此，Java在访问自由局部变量时，实际上是在访问它的副本，而不是访问原始变量。如果局部变量仅仅赋值一次那就没有什么区别了——因此就有了这个限制。 第二，这一限制不鼓励你使用改变外部变量的典型命令式编程模式(我们会在以后的各章中 解释，这种模式会阻碍很容易做到的并行处理)。 6. 方法引用方法引用可以被看作仅仅调用特定方法的Lambda的一种快捷 写法，方法引用看作针对仅仅涉及单一方法的Lambda的语法糖。目标引用放在分隔符::前，方法的名称放在后面。方法引用主要有三类： (1) 指向静态方法的方法引用(例如Integer的parseInt方法，写作Integer::parseInt)。 (2) 指向任意类型实例方法的方法引用(例如String的length方法，写作 String::length)。 (3) 指向现有对象的实例方法的方法引用(假设你有一个局部变量expensiveTransaction 用于存放Transaction类型的对象，它支持实例方法getValue，那么你就可以写expensive- Transaction::getValue)。 1234567对于一个现有构造函数，你可以利用它的名称和关键字new来创建它的一个引用: ClassName::new。它的功能与指向静态方法的引用类似。Supplier&lt;Apple&gt; c1 = Apple::new;Apple a1 = c1.get(); 这就等价于:Supplier&lt;Apple&gt; c1 = () -&gt; new Apple(); // 利用默认构造函数创建 Apple的Lambda表达式Apple a1 = c1.get(); // 调用Supplier的get方法 将产生一个新的Apple 7. 复合Lambda表达式的有用方法7.1 比较器复合1234567Comparator&lt;Apple&gt; c = Comparator.comparing(Apple::getWeight);// 逆序 按重量递 减排序inventory.sort(comparing(Apple::getWeight).reversed());// 比较器链 按重量递减排序;两个苹果一样重时，进一步按国家排序inventory.sort(comparing(Apple::getWeight) .reversed() .thenComparing(Apple::getCountry)); 7.2 谓词复合12345678// 产生现有Predicate 对象redApple的非Predicate&lt;Apple&gt; notRedApple = redApple.negate();// 链接两个谓词来生成另 一个Predicate对象 一个苹果既是红色又比较重Predicate&lt;Apple&gt; redAndHeavyApple = redApple.and(a -&gt; a.getWeight() &gt; 150);// 链接Predicate的方法来构造更复杂Predicate对象 表达要么是重(150克以上)的红苹果，要么是绿苹果Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150) .or(a -&gt; \"green\".equals(a.getColor()));请注意，and和or方法是按照在表达式链中的位置，从左向右确定优 先级的。因此，a.or(b).and(c)可以看作(a || b) &amp;&amp; c。 7.3 函数复合123456789101112131415andThen方法会返回一个函数，它先对输入应用一个给定函数，再对输出应用另一个函数。 比如，Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.andThen(g);int result = h.apply(1);数学上会写作g(f(x))或(g o f)(x)这将返回4compose方法，先把给定的函数用作compose的参数里面给的那个函 数，然后再把函数本身用于结果。Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.compose(g);int result = h.apply(1);数学上会写作f(g(x))或(f o g)(x) 这将返回3 8. 小结以下是你应从本章中学到的关键概念。 Lambda表达式可以理解为一种匿名函数:它没有名称，但有参数列表、函数主体、返回类型，可能还有一个可以抛出的异常的列表。 Lambda表达式让你可以简洁地传递代码。 函数式接口就是仅仅声明了一个抽象方法的接口。 只有在接受函数式接口的地方才可以使用Lambda表达式。 Lambda表达式允许你直接内联，为函数式接口的抽象方法提供实现，并且将整个表达式作为函数式接口的一个实例。 Java 8自带一些常用的函数式接口，放在java.util.function包里，包括Predicate、Function&lt;T,R&gt;、Supplier、Consumer和BinaryOperator，如表3-2所述。 为了避免装箱操作，对Predicate和Function&lt;T, R&gt;等通用函数式接口的原始类型特化:IntPredicate、IntToLongFunction等。 环绕执行模式(即在方法所必需的代码中间，你需要执行点儿什么操作，比如资源分配 和清理)可以配合Lambda提高灵活性和可重用性。 Lambda表达式所需要代表的类型称为目标类型。 方法引用让你重复使用现有的方法实现并直接传递它们。 Comparator、Predicate和Function等函数式接口都有几个可以用来结合Lambda表达式的默认方法。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/07/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%203%EF%BC%9ALambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"《深入理解Java虚拟机》第二章 Java 内存区域与内存溢出异常","text":"著名数学家华罗庚先生说：“读一本书要越读越薄。”书越读越薄的过程，就是在多次重复阅读中不断删除冗余信息的过程，浓缩的主要办法是：列提纲与写梗概。前者必须在认真读的基础上，理清文章的脉络，然后逐段概括内容；后者也必须反复阅读,掌握课文要点，将内容加以高度浓缩。浓缩法就是博学反约，厚积薄发，把厚书读薄，又把薄书积厚的读书方法。 2.1 概述从概念上介绍 Java 虚拟机内存的各个区域，讲解这些区域的作用、服务对象以及其中可能产生的问题，这是翻越虚拟机内存管理这堵围墙的第一步。 2.2 运行时数据区域 JVM 内存结构的布局和相应的控制参数 : 2.2.1 程序计数器 一块较小的内存空间，固定宽度的整数的存储空间 线程私有 当前线程所执行的字节码的行号指示器 Java 虚拟机规范中唯一一个没有规定 OutOfMemoryError 的区域 如果线程正在执行 Java 方法，存储的是正在执行的虚拟机字节码指令的地址；如果正在执行 Native 方法，其值为空(Undefined)。 经典问题扩展 : Java 程序计数器为什么不规定 OutOfMemoryError ？ 2.2.2 Java 虚拟机栈(Java Virtual Machine Stacks) 线程私有，生命周期与线程相同 运行 Java 方法( 字节码 ) 服务 描述的是 Java 方法执行的内存模型 : 栈帧(Stack Frame)，包含：局部变量表、操作数栈、动态链接、方法出口等 StackOverflowError 异常：如果线程请求的栈深度大于虚拟机所允许的深度，抛出此异常 OutOfMemoryError 异常：如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，抛出此异常 2.2.3 本地方法栈(Native Method Stack) 线程私有，生命周期与线程相同 运行 Native方法服务 与Java虚拟机栈相似，也会抛出StackOverflowError异常和OutOfMemoryError异常 2.2.4 Java 堆(Java Heap) JVM 所管理的内存中最大的一块，垃圾回收的主要操作区域 所有线程共享，虚拟机启动时创建 所有对象实例以及数组都要在堆上分配(非绝对，JIT 和逃逸分析技术发展) 物理上不连续的内存空间，逻辑上是连续的 划分为：新生代( Eden空间、From Survivor空间、To Survivor空间 (分配比例 8:1:1) )和老年代 控制参数 -Xms 设置堆的最小空间大小 -Xmx 设置堆的最大空间大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最小空间大小。 OutOfMemoryError异常：如果堆中没有内存完成实例分配，并且堆也无法扩展，抛出此异常 2.2.5 方法区(Method Area) 所有线程共享 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，别名非堆 Non-Heap，包含：类信息、常量、静态变量、即时编译器编译后的代码等数据 HotSpot 虚拟机称为“永久代”(Permanent Generation) 回收效率并不高 OutOfMemoryError异常：当方法区无法满足内存分配需求时，抛出此异常 2.2.6 运行时常量池(Runtime Constant Pool) 方法区一部分，所有线程共享 存储编译期生成的各种字面量和符号引用 OutOfMemoryError 异常：方法区一部分，受到方法区内存限制，当常量池无法再申请到内存时，抛出此异常 扩展 深入解析String#intern 2.2.7 直接内存(Direct Memory) 并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域 OutOfMemoryError 异常：配置虚拟机参数时，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现异常 2.3 HotSpot 虚拟机对象探秘2.3.1 对象的创建 类加载检查：new 类名，根据 new 的参数在常量池中定位一个类的符号引用，如果没有找到这个符号引用,说明类还未加载，则进行类的加载/解析和初始化。 虚拟机为对象分配内存(位于堆中) 将分配的内存初始化为零值(不包括对象头)，如果使用 TLAB ，这一过程可以提前至 TLAB 分配时进行 调用对象的&lt;init&gt;方法 堆内存分配两种方式：指针碰撞(Bump the Pointer) : Java 堆中的内存是规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，分配内存也就是把指针向空闲空间那边移动一段与内存大小相等的距离。例如：Serial、ParNew 等收集器。空闲列表(Free List) : Java 堆中的内存不是规整的，已使用的内存和空闲的内存相互交错，就没有办法简单的进行指针碰撞了。虚拟机必须维护一张列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。例如：CMS 这种基于 Mark-Sweep 算法的收集器。 堆内存分配并发解决方案：对分配内存空间的动作进行同步处理，实际上虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。本地线程分配缓冲 TLAB (Thread Local Allocation Buffer)，把内存分配的动作按照线程划分为在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(TLAB)。哪个线程要分配内存，就在哪个线程的TLAB上分配。只有TLAB用完并分配新的TLAB时，才需要同步锁定。 2.3.2 对象的内存布局 对象头( Header ) 对象自身运行时数据 ( Mark Word )，包含：哈希码 / GC分代年龄 / 锁状态标志 / 线程持有的锁 / 偏向线程ID / 偏向时间戳 类型指针：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例 实例数据( Instance Data ) 对象真正存储的有效信息 程序代码中定义的各种类型的字段内容 HotSpot 虚拟机默认分配策略：longs/doubles/ints/shorts/chars/bytes/booleans/oops(Oridinary Object Pointers) 对齐填充( Padding ),并不是必然存在的，仅仅起着占位符的作用。 2.3.2 对象的访问定位 使用句柄：Java 堆中分配一块内存,reference 中存储的就是对象句柄地址,使用句柄来访问的最大好处就是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中实例数据地址，reference 本身不用改变。如下图所示： 直接指针：Java 堆中分配一块内存，reference 中存储的就是对象实例地址，HostSpot 使用此种方式，节省了一次指针定位的时间开销，提升了速度。如下图所示： 2.4 实战：OutOfMemoryError 异常 MacBook Pro Retina, 2.6 GHz Intel Core i7, 16 GB 2133 MHz LPDDR3, OS X Yosemite JDK 1.8 2.4.1 Java 堆溢出12345678910111213141516171819/** * Java 堆内存溢出 * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError * @author lujiahao * @date 2018-12-21 14:47 */public class HeapOOM { static class OOMObject { } public static void main(String[] args) { List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while (true) { list.add(new OOMObject()); System.out.println(list.size()); } }} 12345678910111213java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid1439.hprof ...Heap dump file created [28440089 bytes in 0.115 secs]Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:265) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231) at java.util.ArrayList.add(ArrayList.java:462) at OutOfMemory.HeapOOM.main(HeapOOM.java:20)Process finished with exit code 1 2.4.2 虚拟机栈和本地方法栈溢出123456789101112131415161718192021222324/** * 虚拟机栈和本地方法栈溢出 * VM Args: -Xss128k * @author lujiahao * @date 2018-12-21 17:02 */public class JavaVMStackSOF { private int stackLength = 1; public void stackLeak() { stackLength++; stackLeak(); } public static void main(String[] args) { JavaVMStackSOF oom = new JavaVMStackSOF(); try { oom.stackLeak(); } catch (Throwable e) { System.out.println(\"stack length:\" + oom.stackLength); throw e; } }} 1234设置128k,启动会报下面的问题The stack size specified is too small, Specify at least 160kError: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit. 12345修改为161k，实现效果stack length:7738Exception in thread \"main\" java.lang.StackOverflowError at OutOfMemory.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:22) at OutOfMemory.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:22) 123456789101112131415161718192021222324252627282930/** * 创建线程导致内存溢出 危险!!! 可能导致死机,我就不轻易尝试了 * VM Args: -Xss2M * @author lujiahao * @date 2018-12-21 17:11 */public class JavaVMStackOOM { private void dontStop() { while (true) { } } public void stackLeakByThread() { while (true) { Thread thread = new Thread(new Runnable() { @Override public void run() { dontStop(); } }); thread.start(); } } public static void main(String[] args) { JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakByThread(); }} 2.4.3 方法区和运行时常量池溢出1234567891011121314151617181920212223/** * 运行时常量池导致内存溢出 * VM Args: -XX:PermSize=10m -XX:MaxPermSize=10M * jdk1.6 * * 使用新版本的jdk会输出: * Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=10m; support was removed in 8.0 * Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=10M; support was removed in 8.0 * * @author lujiahao * @date 2018-12-21 17:33 */public class RuntimeConstantPoolOOM { public static void main(String[] args) { // 使用List保持炸常量池引用,避免Full GC回收常量池行为 List&lt;String&gt; list = new ArrayList&lt;&gt;(); // 10MB的PermSize在Integer范围内足够产生OOM了 int i = 0; while (true) { list.add(String.valueOf(i++).intern()); } }} 1234567891011121314151617181920212223/** * 借助CGLib使方法区出现内存溢出 * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M * @author lujiahao * @date 2018-12-21 17:40 */public class JavaMethodAreaOOM { static class OOMObject{} public static void main(String[] args) { while (true) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { return methodProxy.invokeSuper(objects, args); } }); enhancer.create(); } }} 2.4.4 本机直接内存溢出123456789101112131415161718/** * 本机直接内存溢出(使用unsafe分配本机内存) * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M * @author lujiahao * @date 2018-12-21 17:51 */public class DirectMemoryOOM { public static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception{ Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) { unsafe.allocateMemory(_1MB); } }} 欢迎大家关注😁","link":"/2019/01/11/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%20Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/"},{"title":"19-JavaWeb基础-Filter","text":"1. 介绍当访问资源时，如果不希望此资源被访问，可以使用过滤器进行拦截。访问一个资源，需要路径，过滤器通过路径匹配进行资源拦截。过滤器必须实现接口：javax.servlet.Filter Filter init(FilterConfig):void 初始化 doFilter(ServletRequest,ServletResponse,FilterChain):void 过滤方法 destroy():void 销毁默认情况下过滤器会拦截匹配路径和执行的资源需要手动放行:chain.doFilter(request,response); 2.使用方法详见统计访问次数的案例 3.生命周期3.1 init(FilterConfig) 初始化方法 执行时机：服务器启动时执行 执行者：tomcat FilterConfig：当前过滤器的配置对象 getFilterName():String 过滤名称,相当于&lt;filter-name&gt;标签 getServletContext():ServletContext ServletContext对象引用 getInitParametes(String):String 获得过滤器初始化参数 getInitParameterNames():Enumeration 获得过滤器初始化参数的所有名字 &lt;filter&gt; &lt;filter-name&gt;CountFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.lujiahao.cms.filter.CountFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/filter&gt;3.2 doFilter(ServletRequest,ServletResponse ,FilterChain) 路径匹配一次执行一次。一次请求拦截一次。3.3 destroy() 执行时机：服务器正常关闭时执行 执行者：tomcat4.doFilter方法详解参数1ServletRequest 和参数2 ServletResponse 回顾：Object List ArrayList ServletRequest HttpServletRequest tomcat实现类 结论：可以强转获得Http协议有关对象 HttpServletRequest request = （HttpServletRequest） req; HttpServletResponse request = （HttpServletResponse） res;参数3：FilterChain FilterChain 过滤器链，当请求资源时，多个过滤器都生效，tomcat将生成一个链，用于存放多个过滤器。 第一个过滤器执行完成，并发行时，将执行第二个过滤器，。。。。。当最后一个过滤器放行时，将执行资源。 过滤器链中 过滤器执行顺序 与 映射在web.xml配置顺序一致的。web.xml 先配置先执行 5.&lt;url-pattern&gt;匹配路径回顾：servlet路径配置 1.完全匹配，必须/开头 ，例如：/a/b/c/oneServlet 2.不完全匹配，以/开头 *结尾，例如：/a/b/* , /* 3.通配符匹配. *.开头，例如： *.jsp 、 *.do 、*.action 等 4 缺省 / 以上都没有匹配将执行。过滤器路径编写，与servlet一致的，过滤器过滤的就是指定servlet。 /oneServlet 、 /twoServlet /* 过滤器 将匹配以上两个servlet6.dispatcher配置 用于配置过滤器在何处进行拦截。 取值： REQUEST、 FORWARD、 INCLUDE、ERROR request : 表示在请求开始时拦截。默认值。 forward：表示在请求转发开始时拦截。及 request.getRequestDistacher(..).forward 被调用时。 include：表示在请求包含开始时拦截。及 request.getRequestDistacher(..).include 被调用时。 error ： 表示程序异常，显示友好页面之前拦截。案例〇 : dispatcher配置友好错误页面IE会将500的错误以他自己的方式展现出来,这就不符合需求,所以需要手动配置友好错误页面.如果有多个友好错误界面,不能在每个jsp页面更改状态码,这就需要一个过滤器来统一过滤. 1.创建FriendErrorFilter实现javax.servlet.Filter接口 /** * 友好错误界面过滤器 * Created by lujiahao on 2016/7/27. */ public class FriendErrorFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; // 修改状态码 response.setStatus(200); // 放行 filterChain.doFilter(request,response); } @Override public void destroy() { } }2.配置到tomcat(web.xml) &lt;!--配置友好错误页面过滤器--&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/demo0/frienderror.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;!--友好错误页面过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;FriendErrorFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.lujiahao.filter.FriendErrorFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;FriendErrorFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/frienderror.jsp&lt;/url-pattern&gt; &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;/filter-mapping&gt;3.编写友好错误界面(error.jsp) &lt;html&gt; &lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; 我是友好错误界面&lt;br/&gt; 服务器繁忙,请稍后重试 &lt;/body&gt; &lt;/html&gt;4.模拟服务器500错误 &lt;% int i = 1/0; %&gt;案例一 : 统计访问次数原理:将数据记录到ServletContext 所有用户共享 1.创建CountFilter实现javax.servlet.Filter接口 /** * 统计次数的过滤器 * Created by lujiahao on 2016/7/27. */ public class CountFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; // 获得访问路径 /pages/main/main.jsp String servletPath = request.getServletPath(); String filePath = servletPath.substring(servletPath.lastIndexOf(&quot;/&quot;)+1,servletPath.lastIndexOf(&quot;.&quot;)); // 获得servletContext获取统计数据 ServletContext servletContext = request.getSession().getServletContext(); Integer num = (Integer) servletContext.getAttribute(filePath); if (num == null) { num = 1;// 第一次访问 } else { num ++; } // 存放到ServletContext中 servletContext.setAttribute(filePath,num); // 放行 filterChain.doFilter(request,response); } @Override public void destroy() { } }2.配置到tomcat(web.xml) &lt;!--统计次数的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;CountFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.lujiahao.cms.filter.CountFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CountFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/pages/main/main.jsp&lt;/url-pattern&gt; &lt;/filter-mapping&gt;3.JSP中使用 访问次数:${applicationScope.main}次&lt;br/&gt;案例三 : 自动登录原理图: 1.修改以前的登录逻辑,添加对自动登录的标记 /** * 登录操作 */ private void login(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 1.获取数据并封装 Customer customer = LBeanUtils.populate(Customer.class, request.getParameterMap()); // 2.通知service进行登录 CustomerServeice customerServeice = new CustomerServiceImpl(); Customer loginCustomer = customerServeice.login(customer); // 3.处理 if (loginCustomer != null) { // -------------自动登录start------------- // checkbox选中的话获得的值是on String autologin = request.getParameter(&quot;autologin&quot;); if (autologin != null) { // 勾选了记住密码, 使用cookie将用户的登录名和密码发送到浏览器,并通知浏览器保存(持久化cookie) // 1.创建cookie对象 String username = URLEncoder.encode(loginCustomer.getName(), &quot;UTF-8&quot;); String password = URLEncoder.encode(loginCustomer.getPwd(), &quot;UTF-8&quot;); // 存入需要进行URLEndode编码,不然会报错:http://blog.csdn.net/liuxiao723846/article/details/22155393 Cookie cookie = new Cookie(&quot;autoLoginCookie&quot;, username + &quot;&amp;&quot; + password); // 2.设置有效时间 cookie.setMaxAge(60 * 60);// 1小时 // 3.设置路径 cookie.setPath(&quot;/&quot;); // 4.发送cookie response.addCookie(cookie); } // -------------自动登录end------------- // 成功 -- session记录登录状态,重定向到主页面 // * session作用域保存数据 request.getSession().setAttribute(&quot;loginCustomer&quot;, loginCustomer); response.sendRedirect(request.getContextPath() + &quot;/pages/main/main.jsp&quot;); } else { // 不成功 --- request记录当次请求提示,请求转发到login.jsp 显示数据 request.setAttribute(&quot;msg&quot;, &quot;用户名和密码不匹配&quot;); request.setAttribute(&quot;customer&quot;, customer);// 回显数据 request.getRequestDispatcher(&quot;pages/login/login.jsp&quot;).forward(request, response); } }2.编写自动登录的过滤器 /** * 自动登录的过滤器 * Created by lujiahao on 2016/7/27. */ public class AutoLoginFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; Customer loginCustomer = (Customer) request.getSession().getAttribute(&quot;loginCustomer&quot;); // 1.已经登录 if (loginCustomer != null) { filterChain.doFilter(request,response); return; } // 2.没有登录,获取cookie信息 Cookie[] allCookie = request.getCookies(); String cookieValue = null; if (allCookie != null) { for (Cookie cookie : allCookie) { if (&quot;autoLoginCookie&quot;.equals(cookie.getName())) { cookieValue = cookie.getValue(); break;// 一旦查询到了就跳出循环,提升性能 } } } // 3.没有cookie信息 if (cookieValue == null) { filterChain.doFilter(request,response); return; } // 4.查询到cookie信息,获得用户数据 String username = URLDecoder.decode(cookieValue.split(&quot;&amp;&quot;)[0],&quot;UTF-8&quot;); String password = URLDecoder.decode(cookieValue.split(&quot;&amp;&quot;)[1],&quot;UTF-8&quot;); Customer customer = new Customer(username,password); // 5.查询用户信息 CustomerServeice customerServeice = new CustomerServiceImpl(); loginCustomer = customerServeice.login(customer); // 6.没有查询到用户信息----例如:密码修改 if (loginCustomer == null) { filterChain.doFilter(request,response); // 应该删除cookie Cookie cookie = new Cookie(&quot;autoLoginCookie&quot;,&quot;&quot;); cookie.setMaxAge(0);// 删除 cookie.setPath(&quot;/&quot;);// 保存的时候写的路径要和这里一样 response.addCookie(cookie); return; } // 7.查询到用户信息,执行自动登录 request.getSession().setAttribute(&quot;loginCustomer&quot;,loginCustomer); // 放行 filterChain.doFilter(request,response); } @Override public void destroy() { } }案例四 : GET/POST中文乱码统一处理1.旧的处理方式: public class GetPostServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { /* String username = request.getParameter(&quot;username&quot;); String password = request.getParameter(&quot;password&quot;); //处理编码 username = new String(username.getBytes(&quot;ISO8859-1&quot;),&quot;UTF-8&quot;); password = new String(password.getBytes(&quot;ISO8859-1&quot;),&quot;UTF-8&quot;); System.out.println(&quot;get:&quot;); System.out.println(username); System.out.println(password); */ this.doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //post请求乱码 //request.setCharacterEncoding(&quot;UTF-8&quot;); String username = request.getParameter(&quot;username&quot;); String password = request.getParameter(&quot;password&quot;); System.out.println(&quot;post:&quot;); System.out.println(username); System.out.println(password); } }2.使用过滤器+装饰着模式的处理方式: /** * 处理Get/Post请求乱码的过滤器 * Created by lujiahao on 2016/7/27. */ public class GetPostEncodingFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; //编码设置 另一个filter编写 这个只能解决POST乱码的问题 request.setCharacterEncoding(&quot;UTF-8&quot;); // 这个里面有处理GET乱码 // 使用装饰者模式增强的request MyRequest myRequest = new MyRequest(request); // 放行 filterChain.doFilter(myRequest,response); } @Override public void destroy() { } } /** * 使用装饰者设计模式 * HttpServletRequestWrapper是系统为我们准备好的装饰者的父类,已经完成了相应的工作 * Created by lujiahao on 2016/7/27. */ public class MyRequest extends HttpServletRequestWrapper { private boolean isEncoding = false;// 默认是没有编码的 private HttpServletRequest request; public MyRequest(HttpServletRequest request) { super(request);// 将tomcat的request传入父类,提供给不需要增强的方法使用 this.request = request; } // 需要增强的方法直接覆写父类方法就好了 // 通过名称获得第一个值 @Override public String getParameter(String name) { String[] parameterValues = this.getParameterValues(name); if (parameterValues == null) { return null; } return parameterValues[0]; } // 通过名称获得所有的值 @Override public String[] getParameterValues(String name) { return this.getParameterMap().get(name); } @Override public Map&lt;String, String[]&gt; getParameterMap() { // 1.获得tomcat原始数据 Map&lt;String, String[]&gt; map = request.getParameterMap(); // 2.处理get请求的乱码 if (&quot;GET&quot;.equals(request.getMethod()) &amp;&amp; !isEncoding) { // 3.遍历map for(Map.Entry&lt;String,String[]&gt; entry : map.entrySet()){ // 4.获得所有value数据 String[] value = entry.getValue(); // 处理所有乱码 for (int i = 0; i &lt; value.length; i++) { try { value[i] = new String(value[i].getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;); } catch (UnsupportedEncodingException e) { throw new RuntimeException(e); } } } isEncoding = true;// 已经解决完乱码就不要再次解决了 } return map; } }案例五 : 页面静态化 &amp; 全栈压缩页面静态化原理图:1.装饰者模式增强HttpServletResponse public class MyResponse extends HttpServletResponseWrapper{ private HttpServletResponse response; //提供自定义缓存 private ByteArrayOutputStream baos = new ByteArrayOutputStream(); private PrintWriter pw = null; public MyResponse(HttpServletResponse response) { super(response); this.response = response; } @Override public PrintWriter getWriter() throws IOException { if(pw == null){ pw = new PrintWriter(new OutputStreamWriter(baos , &quot;UTF-8&quot; )); System.out.println(&quot;执行&quot; + pw); } return pw; } /** * 获得自定义缓存内容 * @return */ public byte[] getData(){ return baos.toByteArray(); } }2.过滤器写法 public class PageStaticFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) resp; //1 获得页面位置 //D:\\java\\tomcat\\apache-tomcat-7.0.53\\webapps\\day19_demo\\demo04\\1.html ServletContext sc = request.getSession().getServletContext(); String id= request.getParameter(&quot;id&quot;); String path = &quot;/demo04/&quot;+id+&quot;.html&quot;;// 静态页面存放的位置 String htmlPath = sc.getRealPath(path); //2 文件是否存在 File htmlFile = new File(htmlPath); if(htmlFile.exists()){ //存在就显示 request.getRequestDispatcher(path).forward(request, response); return; } // 自定义response 提供缓存，用于存放 发送到浏览器所有内容 MyResponse myResponse = new MyResponse(response); //放行 chain.doFilter(request, myResponse); //内容已经写入到自定义缓存 byte[] arrayByte = myResponse.getData(); /***写入到文件 start**/ //将指定的内容内容到文件 FileOutputStream out = new FileOutputStream(htmlFile); out.write(arrayByte); out.close(); //手动写入到浏览器 response.getOutputStream().write(arrayByte); /***写入到文件 end**/ /**全站压缩 ， 将需要发送的数据，压缩之后再发给浏览器，节省流量 全站压缩和页面静态化是冲突的,需要一个一个来测试**/ /* // 设置发送的数据位压缩数据 response.setHeader(&quot;content-encoding&quot;, &quot;gzip&quot;); ByteArrayOutputStream baos = new ByteArrayOutputStream(); //存放压缩后的结果 GZIPOutputStream gzipOut = new GZIPOutputStream(baos); //压缩的位置 gzipOut.write(arrayByte); //需要压缩的原始数据 gzipOut.close(); response.getOutputStream().write(baos.toByteArray()); */ } @Override public void destroy() { } }扩展:装饰者设计模式乱码解决的十几分钟的时候讲了这个东西 jar包和war包的区别java项目 压缩 ：jar包web项目 压缩：war包 。 当war添加到tomcat/webapps下将自动解压 jar包和war包压缩格式都是 zip 升级订制版HttpFilter这个非常好,用到的思想和Servlet中的service()方法非常类似,好好总结一下http://www.cnblogs.com/jianjianyang/p/5001471.html","link":"/2017/01/24/JavaWeb%E5%9F%BA%E7%A1%80/19-JavaWeb%E5%9F%BA%E7%A1%80-Filter/"},{"title":"《Java 8 in Action》Chapter 11：CompletableFuture：组合式异步编程","text":"某个网站的数据来自Facebook、Twitter和Google，这就需要网站与互联网上的多个Web服务通信。可是，你并不希望因为等待某些服务的响应，阻塞应用程序的运行，浪费数十亿宝贵的CPU时钟周期。比如，不要因为等待Facebook的数据，暂停对来自Twitter的数据处理。 第7章中介绍的分支/合并框架以及并行流是实现并行处理的宝贵工具;它们将一个操作切分为多个子操作，在多个不同的核、CPU甚至是机器上并行地执行这些子操作。与此相反，如果你的意图是实现并发，而非并行，或者你的主要目标是在同一个CPU上执行几个松耦合的任务，充分利用CPU的核，让其足够忙碌，从而最大化程序的吞吐量，那么你其实真正想做的是避免因为等待远程服务的返回，或者对数据库的查询，而阻塞线程的执行，浪费宝贵的计算资源，因为这种等待的时间很可能相当长。 1. Future接口Future接口在Java 5中被引入，设计初衷是对将来某个时刻会发生的结果进行建模。它建模了一种异步计算，返回一个执行运算结果的引用，当运算结束后，这个引用被返回给调用方。在Future中触发那些潜在耗时的操作把调用线程解放出来，让它能继续执行其他有价值的工作，不再需要等待耗时的操作完成。Future的另一个优点是它比更底层的Thread更易用。要使用Future，通常你只需要将耗时的操作封装在一个Callable对象中，再将它提交给ExecutorService。使用Future以异步的方式执行一个耗时的操作: 线程可以在ExecutorService以并发方式调用另一个线程执行耗时操作的同时，去执行一些其他的任务。接着，如果你已经运行到没有异步操作的结果就无法继续任何有意义的工作时，可以调用它的get方法去获取操作的结果。如果操作已经完成，该方法会立刻返回操作的结果，否则它会阻塞你的线程，直到操作完成，返回相应的结果。如果该长时间运行的操作永远不返回了会怎样?Future提供了一个无需任何参数的get方法，推荐使用重载版本的get方法，它接受一个超时的参数，可以定义线程等待Future结果的最长时间，避免无休止的等待。下图是Future异步执行线程原理图。 2. 使用CompletableFuture构建异步应用Future接口有一定的局限性，比如，我们很难表述Future结果之间的依赖性。因此我们引入了CompletableFuture。接下来通过一个“最佳价格查询器“的应用，它会查询多个在线商店，依据给定的产品或服务找出最低的价格，来展现CompletableFuture实现异步应用。通过此例你能学到这些： 如何编写异步API 如何让使用同步API的代码变为非阻塞代码 如何使用流水线将两个接续的异步操作合并为一个异步计算操作 如何以响应式的方式处理异步操作的完成事件 同步API和异步API： 同步API其实只是对传统方法调用的另一种称呼:你调用了某个方法，调用方在被调用方运行的过程中会等待，被调用方运行结束返回，调用方取得被调用方的返回值并继续运行。即使调用方和被调用方在不同的线程中运行，调用方还是需要等待被调用方结束运行，这就是阻塞式调用这个名词的由来。 异步API会直接返回，或者至少在被调用方计算完成之前，将它剩余的计算任务交给另一个线程去做，该线程和调用方是异步的——这就是非阻塞式调用的由来。执行剩余计算任务的线程会将它的计算结果返回给调用方。返回的方式要么是通过回调函数，要么是由调用方再次执行一个“等待，直到计算完成”的方法调用。 2.1 实战：实现异步API2.1.1 同步方法 同步操作中会为等待同步事件完成而等待1s，这种是无法接受的，对于程序体验来说是非常不好的。 2.1.2 将同步方法转换为异步方法 Java 5引入了java.util.concurrent.Future接口表示一个异步计算(即调用线程可以继续运行，不会因为调用方法而阻塞)的结果。这意味着Future是一个暂时还不可知值的处理器，这个值在计算完成后，可以通过调用它的get方法取得。这种方式下，在进行价格查询的同时，还能执行一些其他的任务，比如查询其他商店中商品的价格，不会阻塞在那里等待第一家商店返回请求的结果。最后，如果所有有意义的工作都已经完成，所有要执行的工作都依赖于商品价格时，再调用Future的get方法。执行了这个操作后，要么获得Future中封装的值(如果异步任务已经完成)，要么发生阻塞，直到该异步任务完成，期望的值能够访问。同时，如果某个商品价格计算发生异常，会将当前线程杀死，从而导致等待get方法返回结果的客户端永久地被阻塞。客户端可以使用重载版本的get方法，设置超时参数来避免。为了让客户端能了解无法提供请求商品价格的原因，你需要使用CompletableFuture的completeExceptionally方法将导致CompletableFuture内发生问题的异常抛出。 2.1.3 使用工厂方法supplyAsync创建CompletableFuture对象 supplyAsync方法接受一个生产者(Supplier)作为参数，返回一个CompletableFuture对象，该对象完成异步执行后会读取调用生产者方法的返回值。生产者方法会交由ForkJoinPool池中的某个执行线程(Executor)运行，但是你也可以使用supplyAsync方法的重载版本，传递第二个参数指定不同的执行线程执行生产者方法。 3. 消除代码阻塞问题3.1 顺序同步请求 3.2 使用并行流对请求进行并行操作 3.3 使用CompletableFuture发起异步请求 CompletableFuture版本的程序似乎比并行流版本的程序还快那么一点儿。但是最后这个版本也不太令人满意。它们看起来不相伯仲，究其原因都一样:它们内部采用的是同样的通用线程池，默认都使用固定数目的线程，具体线程数取决于Runtime.getRuntime().availableProcessors()的返回值。然而，CompletableFuture具有一定的优势，因为它允许你对执行器(Executor)进行配置，尤其是线程池的大小，让它以更适合应用需求的方式进行配置，满足程序的要求，而这是并行流API无法提供的。顺序执行和并行执行的原理对比： 图11-4的上半部分展示了使用单一流水线处理流的过程，我们看到，执行的流程(以虚线标识)是顺序的。事实上，新的CompletableFuture对象只有在前一个操作完全结束之后，才能创建。与此相反，图的下半部分展示了如何先将CompletableFutures对象聚集到一个列表中(即图中以椭圆表示的部分)，让对象们可以在等待其他对象完成操作之前就能启动。 3.4 使用CompletableFuture发起异步请求WithExecutor 3.5 调用结果: 3.6 并行——使用流还是CompletableFutures目前为止，你已经知道对集合进行并行计算有两种方式:要么将其转化为并行流，利用map这样的操作开展工作，要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。 如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的(如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程)。 如果你并行的工作单元还涉及等待I/O的操作(包括网络连接等待)，那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者 W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟性会让我们很难判断到底什么时候触发了等待。 4. 对多个异步任务进行流水线操作4.1 案例通过在shop构成的流上采用流水线方式执行三次map操作，我们得到了结果。 第一个操作将每个shop对象转换成了一个字符串，该字符串包含了该 shop中指定商品的价格和折扣代码。 第二个操作对这些字符串进行了解析，在Quote对象中对它们进行转换。 第三个map会操作联系远程的Discount服务，计算出最终的折扣价格，并返回该价格及提供该价格商品的shop。 代码如图: 原理图： Java 8的CompletableFuture API提供了名为thenCompose的方法，它就是专门为这一目的而设计的，thenCompose方法允许你对两个异步操作进行流水线，第一个操作完成时，将其结果作为参数传递给第二个操作。换句话说，你可以创建两个CompletableFutures对象，对第一个CompletableFuture对象调用thenCompose，并向其传递一个函数。当第一个 CompletableFuture执行完毕后，它的结果将作为该函数的参数，这个函数的返回值是以第一 个CompletableFuture的返回做输入计算出的第二个CompletableFuture对象。thenCompose方法像CompletableFuture类中的其他方法一样，也提供了一个以Async后缀结尾的版本thenComposeAsync。通常而言，名称中不带Async的方法和它的前一个任务一样，在同一个线程中运行;而名称以Async结尾的方法会将后续的任务提交到一个线程池，所以每个任务是由不同的线程处理的。 4.2 thenCombine方法将两个CompletableFuture对象结合起来，无论他们是否存在依赖。thenCombine方法，它接收名为BiFunction的第二参数，这个参数 定义了当两个CompletableFuture对象完成计算后，结果如何合并。同thenCompose方法一样， thenCombine方法也提供有一个Async的版本。这里，如果使用thenCombineAsync会导致BiFunction中定义的合并操作被提交到线程池中，由另一个任务以异步的方式执行。 代码图： 原理图： 4.3 响应CompletableFuture的completion事件Java 8的CompletableFuture通过thenAccept方法提供了这一功能，它接收 CompletableFuture执行完毕后的返回值做参数。thenAccept方法也提供 了一个异步版本，名为thenAcceptAsync。异步版本的方法会对处理结果的消费者进行调度， 从线程池中选择一个新的线程继续执行，不再由同一个线程完成CompletableFuture的所有任 务。因为你想要避免不必要的上下文切换，更重要的是你希望避免在等待线程上浪费时间，尽快响应CompletableFuture的completion事件，所以这里没有采用异步版本。 4.3.1 实战 5. 小结 执行比较操作时,尤其是那些依赖一个或多个远程服务的操作，使用异步任务可以改善程序的性能，加快程序的响应速度。 你应该尽可能地为客户提供异步API。使用CompletableFuture类提供的特性，你能够轻松地实现这一目标。 CompletableFuture类还提供了异常管理的机制，让你有机会抛出/管理异步任务执行中发生的异常。 将同步API的调用封装到一个CompletableFuture中，你能够以异步的方式使用其结果。 如果异步任务之间相互独立，或者它们之间某一些的结果是另一些的输入，你可以将这些异步任务构造或者合并成一个。 你可以为CompletableFuture注册一个回调函数，在Future执行完毕或者它们计算的结果可用时，针对性地执行一些程序。 你可以决定在什么时候结束程序的运行，是等待由CompletableFuture对象构成的列表中所有的对象都执行完毕，还是只要其中任何一个首先完成就中止程序的运行。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/24/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%2011%EF%BC%9ACompletableFuture%EF%BC%9A%E7%BB%84%E5%90%88%E5%BC%8F%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"title":"《Java 8 in Action》Chapter 12：新的日期和时间API","text":"在Java 1.0中，对日期和时间的支持只能依赖java.util.Date类。同时这个类还有两个很大的缺点：年份的起始选择是1900年，月份的起始从0开始。 在Java 1.1中，Date类中的很多方法被废弃，取而代之的是java.util.Calendar类。然而Calendar类也有类似的问题和设计缺陷，导致使用这些方法写出的代码非常容易出错。 DateFormat方法也有它自己的问题。比如，它不是线程安全的。这意味着两个线程如果尝试使用同一个formatter解析日期，你可能会得到无法预期的结果。 1. 使用LocalDate 和LocalTime1.1 LocalDateJava 8提供新的日期和时间API,LocalDate类实例是一个不可变对象，只提供简单的日期并且不含当天时间信息。此外也不附带任何与时区相关的信息。 通过静态工厂方法of创建一个LocalDate实例。LocalDate实例提供了多种方法来读取常用的值，比如年份、月份、星期几等，如下所示。 12345678910111213141516171819202122LocalDate localDate = LocalDate.of(2014, 3, 18);int year = localDate.getYear();Month month = localDate.getMonth();int day = localDate.getDayOfMonth();DayOfWeek dow = localDate.getDayOfWeek();int len = localDate.lengthOfMonth();boolean leap = localDate.isLeapYear();// 使用工厂方法从系统时钟中获取当前的日期LocalDate today = LocalDate.now();System.out.println(String.format(\"year:%s\\nmonth:%s\\nday:%s\\ndow:%s\\nlen:%s\\nleap:%s\", year, month, day, dow, len, leap));System.out.println(today);结果：year:2014month:MARCHday:18dow:TUESDAYlen:31leap:false2019-03-27 Java 8日期-时间类都提供了类似的工厂方法。通过传递TemporalField参数给get方法拿到同样的信息。TemporalField接口定义了如何访问temporal对象某个字段的值。ChronoField枚举实现TemporalField接口,可以使用get方法得到枚举元素的值。 123int year = localDate.get(ChronoField.YEAR);int month = localDate.get(ChronoField.MONTH_OF_YEAR);int day = localDate.get(ChronoField.DAY_OF_MONTH); 1.2 LocalTime使用LocalTime类表示时间,可以使用of重载的两个工厂方法创建LocalTime的实例。 第一个重载函数接收小时和分钟 第二个重载函数同时还接收秒。 LocalTime类也提供了一些get方法访问这些变量的值，如下所示。 12345678910LocalTime localTime = LocalTime.of(13, 45, 20);int hour = localTime.getHour();int minute = localTime.getMinute();int second = localTime.getSecond();System.out.println(String.format(\"hour:%s\\nminute:%s\\nsecond:%s\", hour, minute, second));打印结果：hour:13minute:45second:20 LocalDate和LocalTime都可以通过解析代表它们的字符串创建。使用静态方法parse可以实现： 12LocalDate date = LocalDate.parse(\"2019-03-27\");LocalTime time = LocalTime.parse(\"20:17:08\"); 可以向parse方法传递一个DateTimeFormatter。该类的实例定义了如何格式化一个日期或者时间对象。用来替换老版java.util.DateFormat。如果传递的字符串参数无法被解析为合法的LocalDate或LocalTime对象，这两个parse方法都会抛出一个继承自RuntimeException的DateTimeParseException异常。 2. 合并日期和时间复合类LocalDateTime，是LocalDate和LocalTime的合体。它同时表示了日期和时间，不带有时区信息。可以直接创建，也可以通过合并日期和时间对象构造。 12345678LocalTime time = LocalTime.of(21, 31, 50);LocalDate date = LocalDate.of(2019, 03, 27);LocalDateTime dt1 = LocalDateTime.of(2017, Month.NOVEMBER, 07, 22, 31, 51);LocalDateTime dt2 = LocalDateTime.of(date, time);LocalDateTime dt3 = date.atTime(22, 21, 14);LocalDateTime dt4 = date.atTime(time);LocalDateTime dt5 = time.atDate(date); 创建LocalDateTime对象 直接创建 通过atTime方法向LocalDate传递一个时间对象 通过atDate方法向LocalTime传递一个时间对象 也可以使用toLocalDate或者toLocalTime方法，从LocalDateTime中提取LocalDate或者LocalTime组件： 12LocalDate date1 = dt1.toLocalDate();LocalTime time1 = dt1.toLocalTime(); 3. 机器的日期和时间格式从计算机的角度来看，”2019年03月27日11:20:03”这样的方式是不容易理解的,计算机更加容易理解建模时间最自然的格式是表示一个持续时间段上某个点的单一大整型数。新的java.time.Instant类对时间建模的方式，基本上它是以Unix元年时间（传统的设定为UTC时区1970年1月1日午夜时分）开始所经历的秒数进行计算。 3.1 创建Instant 静态工厂方法ofEpochSecond传递一个代表秒数的值创建一个该类的实例。 静态工厂方法ofEpochSecond还有一个增强的重载版本，它接收第二个以纳秒为单位的参数值，对传入作为秒数的参数进行调整。重载的版本会调整纳秒参数，确保保存的纳秒分片在0到999 999999之间。 123456Instant.ofEpochSecond(3);Instant.ofEpochSecond(3, 0);// 2 秒之后再加上100万纳秒（1秒）Instant.ofEpochSecond(2, 1_000_000_000);// 4秒之前的100万纳秒（1秒）Instant.ofEpochSecond(4, -1_000_000_000); 3.2 工厂方法nowInstant类也支持静态工厂方法now，它能够获取当前时刻的时间戳。 1234Instant now = Instant.now();System.out.println(now);2019-03-27T03:26:39.451Z Instant的设计初衷是为了便于机器使用,它包含的是由秒及纳秒所构成的数字。因此Instant无法处理那些我们非常容易理解的时间单位。 12345int day = Instant.now().get(ChronoField.DAY_OF_MONTH);它会抛出下面这样的异常：Exception in thread \"main\" java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: DayOfMonth但是你可以通过Duration和Period类使用Instant，接下来我们会对这部分内容进行介绍。 4. Duration和Period4.1 Duration所有类都实现了Temporal接口，该接口定义如何读取和操纵为时间建模的对象的值。如果需要创建两个Temporal对象之间的duration,就需要Duration类的静态工厂方法between。可以创建两个LocalTimes对象、两个LocalDateTimes对象，或者两个Instant对象之间的duration： 12345678910111213141516LocalTime time1 = LocalTime.of(21, 50, 10);LocalTime time2 = LocalTime.of(22, 50, 10);LocalDateTime dateTime1 = LocalDateTime.of(2019, 03, 27, 21, 20, 40);LocalDateTime dateTime2 = LocalDateTime.of(2019, 03, 27, 21, 20, 40);Instant instant1 = Instant.ofEpochSecond(1000 * 60 * 2);Instant instant2 = Instant.ofEpochSecond(1000 * 60 * 3);Duration d1 = Duration.between(time1, time2);Duration d2 = Duration.between(dateTime1, dateTime2);Duration d3 = Duration.between(instant1, instant2);// PT1H 相差1小时System.out.println(\"d1:\" + d1);// PT2H 相差2小时System.out.println(\"d2:\" + d2);// PT16H40M 相差16小时40分钟System.out.println(\"d3:\" + d3); LocalDateTime是为了便于人阅读使用，Instant是为了便于机器处理，所以不能将二者混用。如果在这两类对象之间创建duration，会触发一个DateTimeException异常。此外，由于Duration类主要用于以秒和纳秒衡量时间的长短，你不能仅向between方法传递一个LocalDate对象做参数。 4.2 Period使用Period类以年、月或者日的方式对多个时间单位建模。使用该类的工厂方法between，可以使用得到两个LocalDate之间的时长。 123Period period = Period.between(LocalDate.of(2019, 03, 7), LocalDate.of(2019, 03, 17));// 相差10天System.out.println(\"Period between:\" + period); Duration和Period类都提供了很多非常方便的工厂类，直接创建对应的实例。 1234567Duration threeMinutes = Duration.ofMinutes(3);Duration fourMinutes = Duration.of(4, ChronoUnit.MINUTES);Period tenDay = Period.ofDays(10);Period threeWeeks = Period.ofWeeks(3);Period twoYearsSixMonthsOneDay = Period.of(2, 6, 1);Duration类和Period类共享了很多相似的方法，有兴趣的可以参考官网的文档。 截至目前，我们介绍的这些日期-时间对象都是不可修改的，这是为了更好地支持函数式编程，确保线程安全，保持领域模式一致性而做出的重大设计决定。当然，新的日期和时间API也提供了一些便利的方法来创建这些对象的可变版本。比如，你可能希望在已有的LocalDate实例上增加3天。除此之外，我们还会介绍如何依据指定的模式，比如dd/MM/yyyy，创建日期-时间格式器，以及如何使用这种格式器解析和输出日期。 5. 操纵、解析和格式化日期如果已经有一个LocalDate对象，想要创建它的一个修改版，最直接也最简单的方法是使用withAttribute方法。withAttribute方法会创建对象的一个副本，并按照需要修改它的属性。 12345// 这段代码中所有的方法都返回一个修改了属性的对象。它们都不会修改原来的对象！LocalDate date1 = LocalDate.of(2017, 12, 15);LocalDate date2 = date1.withYear(2019);LocalDate date3 = date2.withDayOfMonth(25);LocalDate date4 = date3.with(ChronoField.MONTH_OF_YEAR, 9); 它们都声明于Temporal接口，所有的日期和时间API类都实现这两个方法，它们定义了单点的时间，比如LocalDate、LocalTime、LocalDateTime以及Instant。更确切地说，使用get和with方法，我们可以将Temporal对象值的读取和修改区分开。如果Temporal对象不支持请求访问的字段，它会抛出一个UnsupportedTemporalTypeException异常，比如试图访问Instant对象的ChronoField.MONTH_OF_YEAR字段，或者LocalDate对象的ChronoField.NANO_OF_SECOND字段时都会抛出这样的异常。 12345// 以声明的方式操纵LocalDate对象,可以加上或者减去一段时间LocalDate date1 = LocalDate.of(2014, 10, 19);LocalDate date2 = date1.plusWeeks(1);LocalDate date3 = date2.minusYears(3);LocalDate date4 = date3.plus(6, ChronoUnit.MONTHS); 与我们刚才介绍的get和with方法类似最后一行使用的plus方法也是通用方法，它和minus方法都声明于Temporal接口中。通过这些方法，对TemporalUnit对象加上或者减去一个数字，我们能非常方便地将Temporal对象前溯或者回滚至某个时间段，通过ChronoUnit枚举我们可以非常方便地实现TemporalUnit接口。 6. 使用TemporalAdjuster有时需要进行一些更加复杂的操作，比如，将日期调整到下个周日、下个工作日，或者是本月的最后一天。可以使用重载版本的with方法，向其传递一个提供了更多定制化选择的TemporalAdjuster对象，更加灵活地处理日期。 1234// 对于最常见的用例，日期和时间API已经提供了大量预定义的TemporalAdjuster。可以通过TemporalAdjuster类的静态工厂方法访问。LocalDate date1 = LocalDate.of(2013, 12, 11);LocalDate date2 = date1.with(TemporalAdjusters.nextOrSame(DayOfWeek.MONDAY));LocalDate date3 = date2.with(TemporalAdjusters.lastDayOfMonth()); 使用TemporalAdjuster可以进行更加复杂的日期操作，方法的名称很直观。如果没有找到符合预期的预定义的TemporalAdjuster，可以创建自定义的TemporalAdjuster。TemporalAdjuster接口只声明一个方法（即函数式接口）。实现该接口需要定义如何将一个Temporal对象转换为另一个Temporal对象,可以把它看成一个UnaryOperator。 1234@FunctionalInterfacepublic interface TemporalAdjuster { Temporal adjustInto(Temporal temporal);} 7. 打印输出及解析日期-时间对象新的java.time.format包就是特别为格式化以及解析日期-时间对象而设计的。其中最重要的类是DateTimeFormatter。创建格式器最简单的方法是通过它的静态工厂方法以及常量。所有的DateTimeFormatter实例都能用于以一定的格式创建代表特定日期或时间的字符串。 123456LocalDate date = LocalDate.of(2013, 10, 11);String s1 = date.format(DateTimeFormatter.BASIC_ISO_DATE);String s2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE);201310112013-10-11 通过解析代表日期或时间的字符串重新创建该日期对象，也可以使用工厂方法parse重新创建。 12LocalDate date2 = LocalDate.parse(\"20141007\", DateTimeFormatter.BASIC_ISO_DATE);LocalDate date3 = LocalDate.parse(\"2014-10-07\", DateTimeFormatter.ISO_LOCAL_DATE); DateTimeFormatter实例是线程安全的，老的java.util.DateFormat线程不安全。单例模式创建格式器实例，在多个线程间共享实例是没有问题的。也可以通过ofPattern静态工厂方法，按照某个特定的模式创建格式器。 123DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"dd/MM/yyyy\");String formattedDateStr = date.format(formatter);LocalDate date1 = LocalDate.parse(formattedDateStr, formatter); ofPattern方法也提供了一个重载的版本，可以传入Locale创建格式器。 1234DateTimeFormatter italianFormatter = DateTimeFormatter.ofPattern(\"d. MMMM yyyy\", Locale.ITALIAN);LocalDate date = LocalDate.of(2015, 11, 14);String formattedDate = date.format(italianFormatter);LocalDate date1 = LocalDate.parse(formattedDate, italianFormatter); DateTimeFormatterBuilder类还提供了更复杂的格式器,以提供更加细粒度的控制。同时也提供非常强大的解析功能，比如区分大小写的解析、柔性解析、填充，以及在格式器中指定可选节等等。 通过DateTimeFormatterBuilder自定义格式器 12345678910DateTimeFormatter italianFormatter = new DateTimeFormatterBuilder() .appendText(ChronoField.DAY_OF_MONTH) .appendLiteral(\". \") .appendText(ChronoField.MONTH_OF_YEAR) .appendLiteral(\" \") .appendText(ChronoField.YEAR) .parseCaseInsensitive() .toFormatter(Locale.ITALIAN);LocalDate now = LocalDate.now();String s = now.format(italianFormatter); 8. 处理不同的时区和历法新版日期和时间API新增加的重要功能是时区的处理。新的java.time.ZoneId类替代老版java.util.TimeZone。跟其他日期和时间类一样，ZoneId类也是无法修改的。是按照一定的规则将区域划分成的标准时间相同的区间。在ZoneRules这个类中包含了40个时区实例,可以通过调用ZoneId的getRules()得到指定时区的规则,每个特定的ZoneId对象都由一个地区ID标识。 1ZoneId shanghaiZone = ZoneId.of(\"Asia/Shanghai\"); Java 8的新方法toZoneId将一个老的时区对象转换为ZoneId。地区ID都为“{区域}/{城市}”的格式，地区集合的设定都由英特网编号分配机构（IANA）的时区数据库提供。 1ZoneId zoneId = TimeZone.getDefault().toZoneId(); ZoneId对象可以与LocalDate、LocalDateTime或者是Instant对象整合构造为成ZonedDateTime实例，它代表了相对于指定时区的时间点。 12345678910111213141516LocalDate date = LocalDate.of(2019, 03, 27);ZonedDateTime zdt1 = date.atStartOfDay(shanghaiZone);LocalDateTime dateTime = LocalDateTime.of(2015, 12, 21, 11, 11, 11);ZonedDateTime zdt2 = dateTime.atZone(shanghaiZone);Instant instant = Instant.now();ZonedDateTime zdt3 = instant.atZone(shanghaiZone);通过ZoneId，你还可以将LocalDateTime转换为Instant：LocalDateTime dateTime = LocalDateTime.of(2016, 10, 14, 15, 35);Instant instantFromDateTime = dateTime.toInstant(shanghaiZone);你也可以通过反向的方式得到LocalDateTime对象：Instant instant = Instant.now();LocalDateTime timeFromInstant = LocalDateTime.ofInstant(instant, shanghaiZone); 另一种比较通用的表达时区的方式是利用当前时区和UTC/格林尼治的固定偏差。使用ZoneId的一个子类ZoneOffset，表示的是当前时间和伦敦格林尼治子午线时间的差异： 1ZoneOffset newYorkOffset = ZoneOffset.of(\"-05:00\"); 9. 总结 Java 8之前老版的java.util.Date类以及其他用于建模日期时间的类有很多不一致及设计上的缺陷，包括易变性以及糟糕的偏移值、默认值和命名。 新版的日期和时间API中，日期-时间对象是不可变的。 新的API提供了两种不同的时间表示方式，有效地区分了运行时人和机器的不同需求。 你可以用绝对或者相对的方式操纵日期和时间，操作的结果总是返回一个新的实例，老的日期时间对象不会发生变化。 TemporalAdjuster让你能够用更精细的方式操纵日期，不再局限于一次只能改变它的一个值，并且你还可按照需求定义自己的日期转换器。 你现在可以按照特定的格式需求，定义自己的格式器，打印输出或者解析日期时间对象。这些格式器可以通过模板创建，也可以自己编程创建，并且它们都是线程安全的。 你可以用相对于某个地区/位置的方式，或者以与UTC/格林尼治时间的绝对偏差的方式表示时区，并将其应用到日期时间对象上，对其进行本地化。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/26/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%2012%EF%BC%9A%E6%96%B0%E7%9A%84%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4API/"},{"title":"《Java 8 in Action》Chapter 5：使用流","text":"流让你从外部迭代转向内部迭代，for循环显示迭代不用再写了，流内部管理对集合数据的迭代。这种处理数据的方式很有用，因为你让Stream API管理如何处理数据。这样Stream API就可以在背后进行多种优化。此外，使用内部迭代的话，Stream API可以决定并行运行你的代码。这要是用外部迭代的话就办不到了，因为你只能用单一线程挨个迭代。 1. 筛选和切片1.1 用谓词筛选该操作会接受一个谓词(一个返回 boolean的函数)作为参数，并返回一个包括所有符合谓词的元素的流。筛选出所有素菜 123List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList()); 1.2 筛选各异的元素返回一个元素各异(根据流所生成元素的 hashCode和equals方法实现)的流。筛选出列表中所有的偶数，并确保没有重复。 12345List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream() .filter(i -&gt; i % 2 == 0) .distinct() .forEach(System.out::println); 1.3 截短流流支持limit(n)方法，该方法会返回一个不超过给定长度的流。所需的长度作为参数传递给limit。如果流是有序的，则最多会返回前n个元素。选出热量超过300卡路里的头三道菜 1234List&lt;Dish&gt; dishes = menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .limit(3) .collect(toList()); limit也可以用在无序流上，比如源是一个Set。这种情况下，limit的结果不会以 任何顺序排列。 1.4 跳过元素流还支持skip(n)方法，返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。跳过超过300卡路里的头两道菜，并返回剩下的。 1234List&lt;Dish&gt; dishes = menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .skip(2) .collect(toList()); 2. 映射2.1 对流中每一个元素应用函数流支持map方法，它会接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素。提取流中菜肴的名称： 123List&lt;String&gt; dishNames = menu.stream() .map(Dish::getName) .collect(toList()); 2.2 流的扁平化flatmap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。单个流都被合并起来，即扁平化为一个流。例如，给定单词列表 [“Hello”,”World”]，你想要返回列表[“H”,”e”,”l”, “o”,”W”,”r”,”d”]。 123456List&lt;String&gt; words = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action”);List&lt;String&gt; uniqueCharacters = words.stream() .map(w -&gt; w.split(\"\")) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); 3. 查找和匹配3.1 检查谓词是否至少匹配一个元素anyMatch方法可以回答“流中是否有一个元素能匹配给定的谓词”。anyMatch方法返回一个boolean，因此是一个终端操作。比如，你可以用它来看看菜单里面是否有素食可选择: 123if(menu.stream().anyMatch(Dish::isVegetarian)){System.out.println(\"The menu is (somewhat) vegetarian friendly!!\");} 3.2 检查谓词是否匹配所有元素allMatch方法的工作原理和anyMatch类似，但它会看看流中的元素是否都能匹配给定的谓词。比如，你可以用它来看看菜品是否有利健康(即所有菜的热量都低于1000卡路里): 1boolean isHealthy = menu.stream().allMatch(d -&gt; d.getCalories() &lt; 1000); 和allMatch相对的是noneMatch。它可以确保流中没有任何元素与给定的谓词匹配。比如， 你可以用noneMatch重写前面的例子: 1boolean isHealthy = menu.stream().noneMatch(d -&gt; d.getCalories() &gt;= 1000); anyMatch、allMatch和noneMatch这三个操作都用到了我们所谓的短路，这就是大家熟悉 的Java中&amp;&amp;和||运算符短路在流中的版本。 3.3 查找元素findAny方法将返回当前流中的任意元素。它可以与其他流操作结合使用。比如，你可能想找到一道素食菜肴。你可以结合使用filter和findAny方法来实现这个查询: 123Optional&lt;Dish&gt; dish =menu.stream() .filter(Dish::isVegetarian) .findAny(); Optional类(java.util.Optional)是一个容器类，代表一个值存在或不存在。Optional里面几种可以迫使你显式地检查值是否存在或处理值不存在的情形的方法也不错。 isPresent()将在Optional包含值的时候返回true, 否则返回false。 ifPresent(Consumer block)会在值存在的时候执行给定的代码块。 T get()会在值存在时返回值，否则抛出一个NoSuchElement异常。 T orElse(T other)会在值存在时返回值，否则返回一个默认值。 3.4 查找第一个元素为此有一个findFirst 方法，它的工作方式类似于findany。 例如，给定一个数字列表，下面的代码能找出第一个平方 能被3整除的数: 12345List&lt;Integer&gt; someNumbers = Arrays.asList(1, 2, 3, 4, 5);Optional&lt;Integer&gt; firstSquareDivisibleByThree = someNumbers.stream() .map(x -&gt; x * x) .filter(x -&gt; x % 3 == 0) .findFirst(); // 9 4. 归约归约操作 (将流归约成一个值)。用函数式编程语言的术语来说，这称为折叠(fold)，因为你可以将这个操作看成把一张长长的纸(你的流)反复折叠成一个小方块，而这就是折叠操作的结果。 4.1 元素求和reduce操作是如何作用于一个流的:Lambda反复结合每个元素，直到流被归约成一个值。reduce接受两个参数: 一个初始值，这里是0; 一个BinaryOperator来将两个元素结合起来产生一个新值，这里我们用的是 lambda (a, b) -&gt; a + b。 1int sum = numbers.stream().reduce(0, (a, b) -&gt; a + b); reduce还有一个重载的变体，它不接受初始值，但是会返回一个Optional对象: 1Optional&lt;Integer&gt; sum = numbers.stream().reduce((a, b) -&gt; (a + b)); 4.2 最大值和最小值使用reduce来计算流中的最大值 1Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max); 要计算最小值，你需要把Integer.min传给reduce来替换Integer.max: 1Optional&lt;Integer&gt; min = numbers.stream().reduce(Integer::min); 4.3 小结 5. 实战12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class ExecDemo { public static void main(String[] args) { Trader raoul = new Trader(\"Raoul\", \"Cambridge\"); Trader mario = new Trader(\"Mario\",\"Milan\"); Trader alan = new Trader(\"Alan\",\"Cambridge\"); Trader brian = new Trader(\"Brian\",\"Cambridge\"); List&lt;Transaction&gt; transactions = Arrays.asList( new Transaction(brian, 2011, 300), new Transaction(raoul, 2012, 1000), new Transaction(raoul, 2011, 400), new Transaction(mario, 2012, 710), new Transaction(mario, 2012, 700), new Transaction(alan, 2012, 950) ); System.out.println(\"(1) 找出2011年发生的所有交易，并按交易额排序(从低到高)。\"); List&lt;Transaction&gt; collect = transactions.stream() .filter(t -&gt; t.getYear() == 2011) .sorted(Comparator.comparing(Transaction::getValue)) .collect(Collectors.toList()); System.out.println(collect); System.out.println(\"\\n(2) 交易员都在哪些不同的城市工作过?\"); List&lt;String&gt; collect1 = transactions.stream() .map(transaction -&gt; transaction.getTrader().getCity()) .distinct() .collect(Collectors.toList()); System.out.println(collect1); // [Cambridge, Milan] System.out.println(\"\\n(3) 查找所有来自于剑桥的交易员，并按姓名排序。\"); List&lt;Trader&gt; collect2 = transactions.stream() .map(Transaction::getTrader) .filter(trader -&gt; trader.getCity().equals(\"Cambridge\")) .distinct() .sorted(Comparator.comparing(Trader::getName)) .collect(Collectors.toList()); System.out.println(collect2); System.out.println(\"\\n(4) 返回所有交易员的姓名字符串，按字母顺序排序。\"); String reduce = transactions.stream() .map(transaction -&gt; transaction.getTrader().getName()) .distinct() .sorted() .reduce(\"\", (n1, n2) -&gt; n1 + n2); System.out.println(reduce); System.out.println(\"\\n(5) 有没有交易员是在米兰工作的?\"); boolean b = transactions.stream() .anyMatch(transaction -&gt; transaction.getTrader().getCity().equals(\"Milan\")); System.out.println(b); System.out.println(\"\\n(6) 打印生活在剑桥的交易员的所有交易额。\"); transactions.stream() .filter(transaction -&gt; transaction.getTrader().getCity().equals(\"Cambridge\")) .map(Transaction::getValue) .forEach(System.out::println); System.out.println(\"\\n(7) 所有交易中，最高的交易额是多少?\"); transactions.stream() .map(Transaction::getValue) .reduce(Integer::max) .ifPresent(System.out::println); System.out.println(\"\\n(8) 找到交易额最小的交易。\"); transactions.stream() .map(Transaction::getValue) .reduce(Integer::min) .ifPresent(System.out::println); } 6. 数值流6.1 原始类型流特化Java 8引入了三个原始类型特化流接口来解决这个问题:IntStream、DoubleStream和 LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。 6.1.1 映射到数值流将流转换为特化版本的常用方法是mapToInt、mapToDouble和mapToLong。这些方法和前 面说的map方法的工作方式一样，只是它们返回的是一个特化流，而不是Stream。例如，你 可以像下面这样用mapToInt对menu中的卡路里求和: 123int calories = menu.stream() // 返回一个 Stream&lt;Dish&gt; .mapToInt(Dish::getCalories) // 返回一个 IntStream .sum(); 请注意，如果流是空的，sum默认返回0。IntStream还支持其他的方便方法，如max、min、average等。 6.1.2 转换回对象流要把原始流转换成一般流(每个int都会装箱成一个 Integer)，可以使用boxed方法，如下所示: 12IntStream intStream = menu.stream().mapToInt(Dish::getCalories); //将Stream转换为数值流Stream&lt;Integer&gt; stream = intStream.boxed(); // 将数值流转换为Stream 6.1.3 默认值OptionalInt对于三种原始流特化，也分别有一个Optional原始类 型特化版本:OptionalInt、OptionalDouble和OptionalLong。例如，要找到IntStream中的最大元素，可以调用max方法，它会返回一个OptionalInt: 1OptionalInt maxCalories = menu.stream().mapToInt(Dish::getCalories).max(); 6.2 数值范围Java 8引入了两个可以用于IntStream和LongStream的静态方法，帮助生成这种范围: range和rangeClosed。这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的，而rangeClosed则包含结束值。 12IntStream evenNumbers = IntStream.range(1, 100) .filter(n -&gt; n % 2 == 0); // 一个从1到100的偶数流 表示范围[1, 100)IntStream evenNumbers = IntStream.rangeClosed(1, 100) .filter(n -&gt; n % 2 == 0); // 一个从1到100的偶数流 表示范围[1, 100] 7. 构建流7.1 由值创建流你可以使用静态方法Stream.of，通过显式值创建一个流。它可以接受任意数量的参数。例如，以下代码直接使用Stream.of创建了一个字符串流。然后，你可以将字符串转换为大写，再一个个打印出来: 12Stream&lt;String&gt; stream = Stream.of(\"Java 8 \", \"Lambdas \", \"In \", \"Action\"); stream.map(String::toUpperCase).forEach(System.out::println); 你可以使用empty得到一个空流，如下所示: 1Stream&lt;String&gt; emptyStream = Stream.empty(); 7.2 由数组创建流你可以使用静态方法Arrays.stream从数组创建一个流。它接受一个数组作为参数。例如，你可以将一个原始类型int的数组转换成一个IntStream，如下所示: 12int[] numbers = {2, 3, 5, 7, 11, 13}; int sum = Arrays.stream(numbers).sum(); 7.3 由文件生成流Java中用于处理文件等I/O操作的NIO API(非阻塞 I/O)已更新，以便利用Stream API。 java.nio.file.Files中的很多静态方法都会返回一个流。例如，一个很有用的方法是 Files.lines，它会返回一个由指定文件中的各行构成的字符串流。 7.4 由函数生成流:创建无限流Stream API提供了两个静态方法来从函数生成流:Stream.iterate和Stream.generate。 这两个操作可以创建所谓的无限流:不像从固定集合创建的流那样有固定大小的流。由iterate 2 和generate产生的流会用给定的函数按需创建值，因此可以无穷无尽地计算下去!一般来说， 应该使用limit(n)来对这种流加以限制，以避免打印无穷多个值。 7.4.1 迭代123Stream.iterate(0, n -&gt; n + 2) .limit(10) .forEach(System.out::println); 此操作将生成一个无限流——这个流没有结尾，因为值是按需计算的，可以永远计算下去。我们说这个流是无界的。正如我们前面所讨论的，这是流和集合之间的一个关键区别。我们使用limit方法来显式限制流的大小。这里只选择了前10个偶数。然后可以调用forEach终端操作来消费流，并分别打印每个元素。 7.4.2 生成与iterate方法类似，generate方法也可让你按需生成一个无限流。但generate不是依次 对每个新生成的值应用函数的。它接受一个Supplier类型的Lambda提供新的值。我们先来看一个简单的用法:这段代码将生成一个流，其中有五个0到1之间的随机双精度数。 123Stream.generate(Math::random) .limit(5) .forEach(System.out::println); 8. 小结这一章很长，但是很有收获!现在你可以更高效地处理集合了。事实上，流让你可以简洁地表达复杂的数据处理查询。此外，流可以透明地并行化。以下是你应从本章中学到的关键概念。 Streams API可以表达复杂的数据处理查询。常用的流操作总结在表5-1中。 你可以使用filter、distinct、skip和limit对流做筛选和切片。 你可以使用map和flatMap提取或转换流中的元素。 你可以使用findFirst和findAny方法查找流中的元素。你可以用allMatch、noneMatch和anyMatch方法让流匹配给定的谓词。 这些方法都利用了短路:找到结果就立即停止计算;没有必要处理整个流。 你可以利用reduce方法将流中所有的元素迭代合并成一个结果，例如求和或查找最大元素。 filter和map等操作是无状态的，它们并不存储任何状态。reduce等操作要存储状态才能计算出一个值。sorted和distinct等操作也要存储状态，因为它们需要把流中的所有元素缓存起来才能返回一个新的流。这种操作称为有状态操作。 流有三种基本的原始类型特化:IntStream、DoubleStream和LongStream。它们的操作也有相应的特化。 流不仅可以从集合创建，也可从值、数组、文件以及iterate与generate等特定方法创建。 无限流是没有固定大小的流。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/10/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%205%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%B5%81/"},{"title":"《Java 8 in Action》Chapter 7：并行数据处理与性能","text":"在Java 7之前，并行处理数据集合非常麻烦。第一，你得明确地把包含数据的数据结构分成若干子部分。第二，你要给每个子部分分配一个独立的线程。第三，你需要在恰当的时候对它们进行同步来避免不希望出现的竞争条件，等待所有线程完成，最后把这些部分结果合并起来。Java 7引入了一个叫作分支/合并的框架，让这些操作更稳定、更不易出错。Stream接口让你不用太费力气就能对数据集执行并行操作。它允许你声明性地将顺序流变为并行流。此外，你将看到Java是如何变戏法的，或者更实际地来说， 流是如何在幕后应用Java 7引入的分支/合并框架的。 1. 并行流并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。 12345678910111213public static long sequentialSum(long n) { return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .reduce(0L, Long::sum);}传统写法：public static long iterativeSum(long n) { long result = 0; for (long i = 1L; i &lt;= n; i++) { result += i; } return result;} 1.1 将顺序流转换为并行流可以把流转换成并行流，从而让前面的函数归约过程(也就是求和)并行运行——对顺序流调用parallel方法: 123456public static long parallelSum(long n) { return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .parallel() .reduce(0L, Long::sum);} 在现实中，对顺序流调用parallel方法并不意味着流本身有任何实际的变化。它在内部实际上就是设了一个boolean标志，表示你想让调用parallel之后进行的所有操作都并行执行。类似地，你只需要对并行流调用sequential方法就可以把它变成顺序流。请注意，你可能以为把这两个方法结合起来，就可以更细化地控制在遍历流时哪些操作要并行执行，哪些要顺序执行。 配置并行流使用的线程池看看流的parallel方法，你可能会想，并行流用的线程是从哪来的?有多少个?怎么自定义这个过程呢?并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量，这个值是由Runtime.getRuntime().available- Processors()得到的。但是你可以通过系统属性 java.util.concurrent.ForkJoinPool.common.parallelism来改变线程池大小，如下所示:System.setProperty(“java.util.concurrent.ForkJoinPool.common.parallelism”,”12”);这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。 1.2 测量流性能并行编程可能很复杂，有时候甚至有点违反直觉。如果用得不对(比如采用了一 个不易并行化的操作，如iterate)，它甚至可能让程序的整体性能更差，所以在调用那个看似神奇的parallel操作时，了解背后到底发生了什么是很有必要的。并行化并不是没有代价的。并行化过程本身需要对流做递归划分，把每个子流的归纳操作分配到不同的线程，然后把这些操作的结果合并成一个值。但在多个内核之间移动数据的代价也可能比你想的要大，所以很重要的一点是要保证在内核中并行执行工作的时间比在内核之间传输数据的时间长。总而言之，很多情况下不可能或不方便并行化。然而，在使用 并行Stream加速代码之前，你必须确保用得对;如果结果错了，算得快就毫无意义了。 1.3 正确使用并行流错用并行流而产生错误的首要原因，就是使用的算法改变了某些共享状态。下面是另一种实现对前n个自然数求和的方法，但这会改变一个共享累加器: 123456789public static long sideEffectSum(long n) { Accumulator accumulator = new Accumulator(); LongStream.rangeClosed(1, n).forEach(accumulator::add) return accumulator.total;}public class Accumulator { public long total = 0; public void add(long value) { total += value; }} 这段代码本身上就是顺序的，因为每次访问total都会出现数据竞争。接下来将这段代码改为并行： 123456789101112public static long sideEffectParallelSum(long n) { Accumulator accumulator = new Accumulator(); LongStream.rangeClosed(1, n).parallel().forEach(accumulator::add); return accumulator.total;}System.out.println(\"SideEffect parallel sum done in: \" + measurePerf(ParallelStreams::sideEffectParallelSum, 10_000_000L) +\" msecs\" );Result: 5959989000692Result: 7425264100768Result: 6827235020033Result: 7192970417739Result: 6714157975331Result: 7715125932481SideEffect parallel sum done in: 49 msecs 这回方法的性能无关紧要了，唯一要紧的是每次执行都会返回不同的结果，都离正确值50000005000000差很远。这是由于多个线程在同时访问累加器，执行total += value，而这一句􏱵然看似简单，却不是一个原子操作。问题的根源在于，forEach中调用的方法有副作用，它会改变多个线程共享的对象的可变状态。要是你想用并行Stream又不想引发类似的意外，就必须避免这种情况。现在你知道了，共享可变状态会影响并行流以及并行计算。 1.4 高效使用并行流 如果有疑问，测量。把顺序流转成并行流轻而易举，但却不一定是好事。我们在本节中已经指出，并行流并不总是比顺序流快。此外，并行流有时候会和你的直觉不一致，所以在考虑选择顺序流还是并行流时，第一个也是最重要的建议就是用适当的基准来检查其性能。 留意装箱。自动装箱和拆箱操作会大大降低性能。Java 8中有原始类型流(IntStream、 LongStream、DoubleStream)来避免这种操作，但凡有可能都应该用这些流。 有些操作本身在并行流上的性能就比顺序流差。特别是limit和findFirst等依赖于元素顺序的操作，它们在并行流上执行的代价非常大。例如，findAny会比findFirst性能好，因为它不一定要按顺序来执行。你总是可以调用unordered方法来把有序流变成无序流。那么，如果你需要流中的n个元素而不是专门要前n个的话，对无序并行流调用 limit可能会比单个有序流(比如数据源是一个List)更高效。 还要考虑流的操作流水线的总计算成本。设N是要处理的元素的总数，Q是一个元素通过 流水线的大致处理成本，则N*Q就是这个对成本的一个粗略的定性估计。Q值较高就意味着使用并行流时性能好的可能性比较大。 对于较小的数据量，选择并行流几乎从来都不是一个好的决定。并行处理少数几个元素的好处还抵不上并行化造成的额外开销。 要考虑流背后的数据结构是否易于分解。例如，ArrayList的拆分效􏶲比LinkedList 高得多，因为前者用不着遍历就可以平均拆分，而后者则必须遍历。另外，用range工厂方法创建的原始类型流也可以快速分解。最后，你将在7.3节中学到，你可以自己实现Spliterator来完全掌握分解过程。 流自身的特点，以及流水线中的中间操作修改流的方式，都可能会改变分解过程的性能。例如，一个SIZED流可以分成大小相等的两部分，这样每个部分都可以比较高效地并行处理，但筛选操作可能丢弃的元素个数却无法预测，导致流本身的大小未知。 还要考虑终􏲧操作中合并步骤的代价是大是小(例如Collector中的combiner方法)。 如果这一步代价很大，那么组合每个子流产生的部分结果所付出的代价就可能会超出通过并行流得到的性能提升。 并行流背后使用的基础架构是Java 7中引入的分支/合并框架。 2. 分支/合并框架分支/合并框架的目的是以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。它是ExecutorService接口的一个实现，它把子任务分配给线程池(称为ForkJoinPool)中的工作线程。 2.1 使用RecursiveTask要把任务提交到这个池，必须创建RecursiveTask的一个子类，其中R是并行化任务(以 及所有子任务)产生的结果类型，或者如果任务不返回结果，则是RecursiveAction类型(当然它可能会更新其他非局部机构)。要定义RecursiveTask，只需实现它唯一的抽象方法 compute: 1protected abstract R compute(); 这个方法同时定义了将任务拆分成子任务的逻辑，以及无法再拆分或不方便再拆分时，生成单个子任务结果的逻辑。下图表示了递归任务的拆分过程： 让我们试着用这个框架为一个数字范围(这里用一个 long[]数组表示)求和。如前所述，你需要先为RecursiveTask类做一个实现，就是下面代码清单中的ForkJoinSumCalculator。 12345678910111213141516171819202122232425262728293031323334353637383940public class ForkJoinSumCalculator extends RecursiveTask&lt;Long&gt; { private final long[] numbers; private final int start; private final int end; public static final long THRESHOLD = 10_000; public ForkJoinSumCalculator(long[] numbers) { this(numbers, 0, numbers.length); } public ForkJoinSumCalculator(long[] numbers, int start, int end) { this.numbers = numbers; this.start = start; this.end = end; } @Override protected Long compute() { int length = end - start; if (length &lt;= THRESHOLD) { return computeSequentially(); } ForkJoinSumCalculator leftTask = new ForkJoinSumCalculator(numbers, start, start + length / 2); leftTask.fork(); ForkJoinSumCalculator rightTask = new ForkJoinSumCalculator(numbers, start + length / 2, end); Long rightResult = rightTask.compute(); Long leftResult = leftTask.join(); return leftResult + rightResult; } private long computeSequentially() { long sum = 0; for (int i = start; i &lt; end; i++) { sum += numbers[i]; } return sum; }} 这里用了一个LongStream来生成包含前n个自然数的数组，然后创建一个ForkJoinTask (RecursiveTask的父类)，并把数组传递给代码清单7-2所示ForkJoinSumCalculator的公共构造函数。最后，你创建了一个新的ForkJoinPool，并把任务传给它的调用方法 。在ForkJoinPool中执行时，最后一个方法返回的值就是ForkJoinSumCalculator类定义的任务结果。请注意在实际应用时，使用多个ForkJoinPool是没有什么意义的。正是出于这个原因，一般来说把它实例化一次，然后把实例保存在静态字段中，使之成为单例，这样就可以在软件中任何部分方便地重用了。这里创建时用了其默认的无参数构造函数，这意味着想让线程池使用JVM能够使用的所有处理器。更确切地说，该构造函数将使用Runtime.availableProcessors的返回值来决定线程􏶈使用的线程数。请注意availableProcessors方法虽然看起来是处理器， 但它实际上返回的是可用内核的数量，包括超线程生成的虚拟内核。当把ForkJoinSumCalculator任务传给ForkJoinPool时，这个任务就由􏶈中的一个线程 执行，这个线程会调用任务的compute方法。该方法会检查任务是否小到足以顺序执行，如果不够小则会把要求和的数组分成两半，分给两个新的ForkJoinSumCalculator，而它们也由ForkJoinPool安排执行。因此，这一过程可以递归重复，把原任务分为更小的任务，直到满足不方便或不可能再进一步拆分的条件(本例中是求和的项目数小于等于10000)。这时会顺序计算每个任务的结果，然后由分支过程创建的(隐含的)任务二叉树遍历回到它的根。接下来会合并每个子任务的部分结果，从而得到总任务的结果。这一过程如下图所示。 2.2 使用分支/合并框架的最佳做法 对一个任务调用join方法会阻塞调用方，直到该任务做出结果。因此，有必要在两个子任务的计算都开始之后再调用它。否则，你得到的版本会比原始的顺序算法更慢更复杂，因为每个子任务都必须等待另一个子任务完成才能启动。 不应该在RecursiveTask内部使用ForkJoinPool的invoke方法。相反，你应该始终直接调用compute或fork方法，只有顺序代码才应该用invoke来启动并行计算。 对子任务调用fork方法可以把它排进ForkJoinPool。同时对左边和右边的子任务调用它似乎很自然，但这样做的效􏶲要比直接对其中一个调用compute低。这样做你可以为其中一个子任务重用同一线程，从而避免在线程池中多分配一个任务造成的开销。 调试使用分支/合并框架的并行计算可能有点棘手。特别是你平常都在你喜欢的IDE里面看栈跟踪(stack trace)来找问题，但放在分支-合并并计算上就不行了，因为调用compute的线程并不是概念上的调用方，后者是调用fork的那个。 和并行流一样，你不应理所当然地认为在多核处理器上使用分支/合并框架就比顺序计算快。我们已经说过，一个任务可以分解成多个独立的子任务，才能让性能在并行化时有所提升。所有这些子任务的运行时间都应该比分出新任务所花的时间长;一个惯用方法是把输入/输出放在一个子任务里，计算放在另一个里，这样计算就可以和输入/输出同时进行。此外，在比较同一算法的顺序和并行版本的性能时还有别的因素要考虑。就像任何其他Java代码一样，分支/合并框架需要“预热”或者说要执行几遍才会被JIT编译器优化。这就是为什么在测量性能之前跑几遍程序很重要，我们的测试框架就是这么做的。同时还要知道，编译器内置的优化可能会为顺序版本带来一些优􏲵(例如执行死码分析——删去从未被使用的计算)。 2.3 工作窃取实际中，每个子任务所花的时间可能天差地别，要么是因为划分策略效率低，要么是有不可预知的原因，比如磁盘访问慢，或是需要和外部任务协调执行。分支/合并框架工程用一种称为工作窃取(work stealing)的技术来解决这个问题。在实际应用中，这意味着这些任务差不多被平均分配到ForkJoinPool中的所有线程上。每个线程都为分配给它的任务保存一个双向链式队列，每完成一个任务，就会从队列头上取出下一个任务开始执行。基于前面所述的原因，某个线程可能早早完成了分配给它的所有任务，也就是它的队列已经空了，而其他的线程还很忙。这时，这个线程并没有闲下来，而是随机选了一个别的线程，从队列的尾巴上“偷走”一个任务。这个过程一直继续下去，直到所有的任务都执行完毕，所有的队列都清空。这就是为什么要划成许多小任务而不是少数几个大任务，这有助于更好地在工作线程之间平衡负载。一般来说，这种工作窃取算法用于在池中的工作线程之间重新分配和平衡任务。 3. SpliteratorSpliterator是Java 8中加入的另一个新接口;这个名字代表“可分迭代器”(splitable iterator)。和Iterator一样，Spliterator也用于遍历数据源中的元素，但它是为了并行执行而设计的。 123456public interface Spliterator&lt;T&gt; { boolean tryAdvance(Consumer&lt;? super T&gt; action); Spliterator&lt;T&gt; trySplit(); long estimateSize(); int characteristics();} 与往常一样，T是Spliterator遍历的元素的类型。tryAdvance方法的行为类似于普通的 Iterator，因为它会按顺序一个一个使用Spliterator中的元素，并且如果还有其他元素要遍历就返回true。但trySplit是专为Spliterator接口设计的，因为它可以把一些元素划出去分给第二个Spliterator(由该方法返回)，让它们两个并行处理。Spliterator还可通过 estimateSize方法估计还剩下多少元素要遍历，因为即使不那么确切，能快速算出来是一个值也有助于让拆分均匀一点。 3.1 拆分过程将Stream拆分成多个部分的算法是一个递􏰒过程，如图7-6所示。第一步是对第一个 Spliterator调用trySplit，生成第二个Spliterator。第二步对这两个Spliterator调用 trysplit，这样总共就有了四个Spliterator。这个框架不断对Spliterator调用trySplit直到它返回null，表明它处理的数据结构不能再分割，如第三步所示。最后，这个递归拆分过程到第四步就终止了，这时所有的Spliterator在调用trySplit时都返回了null。 Spliterator的特性 Spliterator接口声明的最后一个抽象方法是characteristics，它将返回一个int，代 表Spliterator本身特性集的编码。 使用Spliterator的客户可以用这些特性来更好地控制和优化它的使用。 表7-2总结了这些特性。(不幸的是，虽然它们在概念上与收集器的特性有重叠，编码却不一样。) 3.2 实现自定义Spliterator略 4. 小结在本章中，你了解了以下内容。 内部迭代让你可以并行处理一个流，而无需在代码中显式使用和􏷡调不同的线程。 虽然并行处理一个流很容易，却不能保证程序在所有情况下都运行得更快。并行软件的行为和性能有时是违反直觉的，因此一定要测量，确保你并没有把程序拖得更慢。 像并行流那样对一个数据集并行执行操作可以提升性能，特别是要处理的元素数量庞大，或处理单个元素特别耗时的时候。 从性能角度来看，使用正确的数据结构，如尽可能利用原始流而不是一般化的流，几乎总是比尝试并行化某些操作更为重要。 分支/合并框架让你得以用递归方式将可以并行的任务拆分成更小的任务，在不同的线程上执行，然后将各个子任务的结果合并起来生成整体结果。 Spliterator定义了并行流如何拆分它要遍历的数据。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/17/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%207%EF%BC%9A%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E6%80%A7%E8%83%BD/"},{"title":"《Java 8 in Action》Chapter 8：重构、测试和调试","text":"我们会介绍几种方法，帮助你重构代码，以适配使用Lambda表达式，让你的代码具备更好的可读性和灵活性。除此之外，我们还会讨论目前比较流行的几种面向对象的设计模式，包括策略模式、模板方法模式、观察者模式、责任链模式，以及工厂模式，在结合Lambda表达式之后变得更简洁的情况。最后，我们会介绍如何测试和调试使用Lambda表达式和Stream API的代码。 1. 为改善可读性和灵活性重构代码1.1 改善代码的可读性Java 8的新特性也可以帮助提升代码的可读性: 使用Java 8，你可以减少冗长的代码，让代码更易于理解 通过方法引用和Stream API，你的代码会变得更直观 利用Lambda表达式、方法引用以及Stream改善程序代码的可读性: 重构代码，用Lambda表达式取代匿名类 用方法引用重构Lambda表达式 用Stream API重构命令式的数据处理 1.2 从匿名内部类到Lambda表达式的转换将实现单一抽象方法的匿名类转换为Lambda表达式 12345678// 传统的方式，使用匿名类Runnable r1 = new Runnable(){ public void run(){ System.out.println(\"Hello\"); }}// 新的方式，使用Lambda表达式Runnable r2 = () -&gt; System.out.println(\"Hello\"); 匿名 类和Lambda表达式中的this和super的含义是不同的。在匿名类中，this代表的是类自身，但是在Lambda中，它代表的是包含类。其次，匿名类可以屏蔽包含类的变量，而Lambda表达式不能(它们会导致编译错误)，如下面这段代码: 1234567891011int a = 10;Runnable r1 = () -&gt; { int a = 2; // 编译错误 System.out.println(a);};Runnable r2 = new Runnable() { public void run() { int a = 2; // 正常 System.out.println(a); }} 在涉及重􏰴的上下文里，将匿名类转换为Lambda表达式可能导致最终的代码更加晦涩。实际上，匿名类的类型是在初始化时确定的，而Lambda的类型取决于它的上下文。通过下面这个例子，我们可以了解问题是如何发生的。我们假设你用与Runnable同样的签名声明了一个函数接口，我们称之为Task: 1234567891011121314interface Task{ public void execute();}public static void doSomething(Runnable r){ r.run(); }public static void doSomething(Task a){ a.execute(); }doSomething(new Task() { public void execute() { System.out.println(\"Danger danger!!\"); }});// doSomething(Runnable) 和 doSomething(Task) 都匹配该类型doSomething(() -&gt; System.out.println(\"Danger danger!!\"));// 使用显式的类型转换来解决这种模棱两可的情况doSomething((Task)() -&gt; System.out.println(\"Danger danger!!\")); 目前大多数的集成开发环境，比如NetBeans和IntelliJ都支持这种重构，它们能自动地帮你检查，避免发生这些问题。 1.3 从Lambda表达式到方法引用的转换12345678Map&lt;CaloricLevel, List&lt;Dish&gt;&gt; dishesByCaloricLevel = menu.stream() .collect( groupingBy(dish -&gt; { if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT;})); 将Lambda表达式的内容抽取到一个单独的方法中，将其作为参数传递给groupingBy方法。变换之后，代码变得更加简洁，程序的意图也更加清晰了。 1Map&lt;CaloricLevel, List&lt;Dish&gt;&gt; dishesByCaloricLevel = menu.stream().collect(groupingBy(Dish::getCaloricLevel)); 1.4 从命令式的数据处理切换到Stream我们建议你将所有使用迭代器这种数据处理模式处理集合的代码都转换成Stream API的方式。为什么呢?Stream API能更清晰地表达数据处理管道的意图。除此之外，通过短路和延迟载入以及利用第7章介绍的现代计算机的多核架构，我们可以对Stream进行优化。 123456789101112// 命令式版本List&lt;String&gt; dishNames = new ArrayList&lt;&gt;(); for(Dish dish: menu){ if(dish.getCalories() &gt; 300){ dishNames.add(dish.getName()); }}// 使用Stream APImenu.parallelStream() .filter(d -&gt; d.getCalories() &gt; 300) .map(Dish::getName) .collect(toList()); 1.5 增加代码的灵活性没有函数式接口就无法使用Lambda表达式，因此代码中需要引入函数式接口。引入函数式接口的两种通用模式： 有条件的延迟执行 环绕执行 2. 使用Lambda重构面向对象的设计模式使用Lambda表达式后，很多现存的略显臃肿的面向对象设计模式能够用更精简的方式实现了。这一节中，我们会针对五个设计模式展开讨论，它们分别是: 策略模式 模板方法 观察者模式 责任链模式 工厂模式 2.1 策略模式策略模式代表了解决一类算法的通用解决方案，你可以在运行时选择使用哪种方案。策略模式包含三部分内容，如图所示。 一个代表某个算法的接口(它是策略模式的接口)。 一个或多个该接口的具体实现，它们代表了算法的多种实现(比如，实体类ConcreteStrategyA或者ConcreteStrategyB)。 一个或多个使用策略对象的客户。 1234567891011121314151617181920212223242526272829303132333435363738public interface ValidationStrategy { boolean execute(String s);}public class IsAllLowerCase implements ValidationStrategy { @Override public boolean execute(String s) { return s.matches(\"[a-z]+\"); }}public class IsNumber implements ValidationStrategy { @Override public boolean execute(String s) { return s.matches(\"\\\\d+\"); }}public class Validator { private final ValidationStrategy strategy; public Validator(ValidationStrategy strategy) { this.strategy = strategy; } public boolean validate(String s) { return strategy.execute(s); }}public class StrategyDemo { public static void main(String[] args) { Validator numericValidator = new Validator(new IsNumber()); boolean b1 = numericValidator.validate(\"aaaa\"); Validator lowerCaseValidator = new Validator(new IsAllLowerCase()); boolean b2 = lowerCaseValidator.validate(\"bbbb\"); System.out.println(b1 + \" \" + b2); Validator numericValidator1 = new Validator((String s) -&gt; s.matches(\"[a-z]+\")); boolean b11 = numericValidator1.validate(\"aaaa\"); Validator lowerCaseValidator1 = new Validator((String s) -&gt; s.matches(\"\\\\d+\")); boolean b21 = lowerCaseValidator.validate(\"bbbb\"); System.out.println(b11 + \" \" + b21); }} 2.2 模板方法模板 方法模式在你“希望使用这个算法，但是需要对其中的某些行进行改进，才能达到希望的效果” 时是非常有用的。 123456789101112131415161718192021222324public abstract class OnlineBanking { public void processCustomer(int id) { Customer c = DataUtil.getCustomerWithId(id); makeCustomerHappy(c); } abstract void makeCustomerHappy(Customer c);}public class OnlineBankingLambda { public void processCustomer(int id, Consumer&lt;Customer&gt; consumer) { Customer c = DataUtil.getCustomerWithId(id); consumer.accept(c); }}public class TemplateMethod { public static void main(String[] args) { new OnlineBanking() { @Override void makeCustomerHappy(Customer c) { System.out.println(c.getName() + \" happy!\"); } }.processCustomer(1); new OnlineBankingLambda().processCustomer(1, (Customer c) -&gt; System.out.println(c.getName() + \" happy!\")); }} 2.3 观察者模式观察者模式是一种比较常见的方案，某些事件发生时(比如状态转变)，如果一个对象(通常我们称之为主题)需要自动地通知其他多个对象(称为观察者)，就会采用该方案。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public interface Observer { void notify(String tweet);}public class NYTime implements Observer { @Override public void notify(String tweet) { if(tweet != null &amp;&amp; tweet.contains(\"money\")){ System.out.println(\"Breaking news in NY! \" + tweet); } }}public class Guardian implements Observer { @Override public void notify(String tweet) { if(tweet != null &amp;&amp; tweet.contains(\"queen\")){ System.out.println(\"Yet another news in London... \" + tweet); } }}public class LeMonde implements Observer { @Override public void notify(String tweet) { if(tweet != null &amp;&amp; tweet.contains(\"wine\")){ System.out.println(\"Today cheese, wine and news! \" + tweet); } }}public interface Subject { void registerObserver(Observer o); void nofityObservers(String tweet);}public class Feed implements Subject { private final List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); @Override public void registerObserver(Observer o) { this.observers.add(o); } @Override public void nofityObservers(String tweet) { observers.forEach(o -&gt; o.notify(tweet)); }}public class ObserverDemo { public static void main(String[] args) { Feed f = new Feed(); f.registerObserver(new NYTime()); f.registerObserver(new Guardian()); f.registerObserver(new LeMonde()); f.nofityObservers(\"The queen said her favourite book is Java 8 in Action!\"); f.registerObserver((String tweet) -&gt; { if (tweet != null &amp;&amp; tweet.contains(\"money\")) { System.out.println(\"Breaking news in NY! \" + tweet); } }); f.registerObserver((String tweet) -&gt; { if (tweet != null &amp;&amp; tweet.contains(\"queen\")) { System.out.println(\"Yet another news in London... \" + tweet); } }); }} 2.4 责任链模式责任链模式是一种创建处理对象序列(比如操作序列)的通用方案。一个处理对象可能需要在完成一些工作之后，将结果传递给另一个对象，这个对象接着做一些工作，再转交给下一个处理对象，以此类推。 12345678910111213141516171819202122232425262728293031323334353637383940public abstract class ProcessingObject&lt;T&gt; { protected ProcessingObject&lt;T&gt; successor; public void setSuccessor(ProcessingObject&lt;T&gt; successor) { this.successor = successor; } public T handle(T input) { T r = handleWork(input); if (successor != null) { return successor.handle(r); } return r; } abstract protected T handleWork(T input);}public class HeaderTextProcessing extends ProcessingObject&lt;String&gt; { @Override protected String handleWork(String input) { return \"From Raoul, Mario and Alan: \" + input; }}public class SpellCheckerProcessing extends ProcessingObject&lt;String&gt; { @Override protected String handleWork(String input) { return input.replaceAll(\"labda\", \"lambda\"); }}public class ChainOfResponsibilityDemo { public static void main(String[] args) { ProcessingObject&lt;String&gt; p1 = new HeaderTextProcessing(); ProcessingObject&lt;String&gt; p2 = new SpellCheckerProcessing(); p1.setSuccessor(p2); String result = p1.handle(\"Aren't labdas really sexy?!!\"); System.out.println(result); UnaryOperator&lt;String&gt; headerProcessing = (String text) -&gt; \"From Raoul, Mario and Alan: \" + text; UnaryOperator&lt;String&gt; spellCheckerProcessing = (String text) -&gt; text.replaceAll(\"labda\", \"lambda\"); Function&lt;String, String&gt; pipeline = headerProcessing.andThen(spellCheckerProcessing); String result1 = pipeline.apply(\"Aren't labdas really sexy?!!\"); System.out.println(result1); }} 2.5 工厂模式使用工厂模式，你无需向客户暴露实例化的逻辑就能完成对象的创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface Product {}@Datapublic class Loan implements Product {}@Datapublic class Stock implements Product {}@Datapublic class Bond implements Product {}public class ProductFactory { public static Product createProduct(String name) { switch (name) { case \"loan\": return new Loan(); case \"stock\": return new Stock(); case \"bond\": return new Bond(); default: throw new RuntimeException(\"No such product \" + name); } } public static void main(String[] args) { Product p = ProductFactory.createProduct(\"loan\"); System.out.println(p); }}public class ProductFactoryLambda { private final static Map&lt;String, Supplier&lt;Product&gt;&gt; map = new HashMap&lt;&gt;(); static { map.put(\"loan\", Loan::new); map.put(\"stock\", Stock::new); map.put(\"bond\", Bond::new); } public static Product createProduct(String name) { Supplier&lt;Product&gt; p = map.get(name); if (p != null) { return p.get(); } throw new IllegalArgumentException(\"No such product \" + name); } public static void main(String[] args) { Product p = ProductFactoryLambda.createProduct(\"loan\"); System.out.println(p); }} 3. 测试Lambda表达式略 4. 调试Lambda表达式4.1 查看栈跟踪123456789101112public class Debugging{ 11 public static void main(String[] args) { List&lt;Point&gt; points = Arrays.asList(new Point(12, 2), null); points.stream().map(p -&gt; p.getX()).forEach(System.out::println); }}运行这段代码会产生下面的栈跟踪:Exception in thread \"main\" java.lang.NullPointerExceptionat Debugging.lambda$main$0(Debugging.java:6)at Debugging$$Lambda$5/284720968.apply(Unknown Source)at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) 我们需要特别注意，涉及Lambda表达式的栈􏱡􏴭可能非常难理解。这是Java编译器未来版本可以改进的一个方面。 4.2 使用日志调试peek的设计初衷就是在流的每个元素恢复运行之前，插入执行一个动作。但是它不像forEach那样恢复整个流的运行，而是在一个元素上完成操作之后，它只会将操作顺承到流水线中的下一个操作。图8-4解释了peek的操作流程。 12345678910111213141516171819202122List&lt;Integer&gt; result = numbers.stream() .peek(x -&gt; System.out.println(\"from stream: \" + x)) .map(x -&gt; x + 17) .peek(x -&gt; System.out.println(\"after map: \" + x)) .filter(x -&gt; x % 2 == 0) .peek(x -&gt; System.out.println(\"after filter: \" + x)) .limit(3) .peek(x -&gt; System.out.println(\"after limit: \" + x)) .collect(toList());输出结果：from stream: 2after map: 19from stream: 3after map: 20after filter: 20after limit: 20from stream: 4after map: 21from stream: 5after map: 22after filter: 22after limit: 22 5. 小结 Lambda表达式能提升代码的可读性和灵活性。 如果你的代码中使用了匿名类，尽量用Lambda表达式替换它们，但是要注意二者间语义的微妙差别，比如关键字this，以及变量隐藏。 Lambda表达式比起来，方法引用的可读性更好。 尽量使用Stream API替换迭代式的集合处理。 Lambda表达式有助于避免使用面向对象设计模式时容易出现的􏳂化的模板代码，典型的比如策略模式、模板方法、观察者模式、责任链模式，以及工厂模式。 即使采用了Lambda表达式，也同样可以进行单元测试，但是通常你应该关注使用了Lambda表达式的方法的行为。 尽量将复杂的Lambda表达式抽象到普通方法中。 Lambda表达式会让栈跟踪的分析变得更为复杂。 流提供的peek方法在分析Stream流水线时，能将中间变量的值输出到日志中，是非常有用的工具。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/18/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%208%EF%BC%9A%E9%87%8D%E6%9E%84%E3%80%81%E6%B5%8B%E8%AF%95%E5%92%8C%E8%B0%83%E8%AF%95/"},{"title":"《Java 8 in Action》Chapter 9：默认方法","text":"传统上，Java程序的接口是将相关方法按照约定组合到一起的方式。实现接口的类必须为接口中定义的每个方法提供一个实现，或者从父类中继承它的实现。但是，一旦类库的设计者需要更新接口，向其中加入新的方法，这种方式就会出现问题。现实情况是，现存的实体类往往不在接口设计者的控制范围之内，这些实体类为了适配新的接口约定也需要进行修改。由于Java 8的API在现存的接口上引入了非常多的新方法，这种变化带来的问题也愈加严重，一个例子就是前几章中使用过的 List 接口上的 sort 方法。想象一下其他备选集合框架的维护人员会多么抓狂吧，像Guava和Apache Commons这样的框架现在都需要修改实现了 List 接口的所有类，为其添加sort 方法的实现。Java 8为了解决这一问题引入了一种新的机制。Java 8中的接口现在支持在声明方法的同时提供实现，通过两种方式可以完成这种操作。其一，Java 8允许在接口内声明静态方法。其二，Java 8引入了一个新功能，叫默认方法，通过默认方法你可以指定接口方法的默认实现。换句话说，接口能提供方法的具体实现。因此，实现接口的类如果不显式地提供该方法的具体实现，就会自动继承默认的实现。这种机制可以使你平滑地进行接口的优化和演进。实际上，到目前为止你已经使用了多个默认方法。两个例子就是你前面已经见过的 List 接口中的 sort ，以及 Collection 接口中的 stream 。 第1章中 List 接口中的 sort 方法是Java 8中全新的方法，它的定义如下： 123default void sort(Comparator&lt;? super E&gt; c){ Collections.sort(this, c);} 请注意返回类型之前的新 default 修饰符。通过它，我们能够知道一个方法是否为默认方法。这里 sort 方法调用了 Collections.sort 方法进行排序操作。由于有了这个新的方法，我们现在可以直接通过调用 sort ，对列表中的元素进行排序。 12List&lt;Integer&gt; numbers = Arrays.asList(3, 5, 1, 2, 6);numbers.sort(Comparator.naturalOrder()); 不过除此之外，这段代码中还有些其他的新东西。我们调用了Comparator.naturalOrder 方法。这是 Comparator 接口的一个全新的静态方法，它返回一个Comparator 对象，并按自然序列对其中的元素进行排序（即标准的字母数字方式排序）。第4章中的 Collection 中的 stream 方法的定义如下： 123default Stream&lt;E&gt; stream() { return StreamSupport.stream(spliterator(), false);} 我们在之前的几章中大量使用了该方法来处理集合，这里 stream 方法中调用了SteamSupport.stream 方法来返回一个流。你注意到 stream 方法的主体是如何调用 spliterator 方法的了吗？它也是 Collection 接口的一个默认方法。接口和抽象类还是有一些本质的区别，我们在这一章中会针对性地进行讨论。简而言之，向接口添加方法是诸多问题的罪恶之源；一旦接口发生变化，实现这些接口的类往往也需要更新，提供新添方法的实现才能适配接口的变化。如果你对接口以及它所有相关的实现有完全的控制，这可能不是个大问题。但是这种情况是极少的。这就是引入默认方法的目的：它让类可以自动地继承接口的一个默认实现。 1. 不断演进的 API1.1 初始版本的 APIResizable 接口的最初版本提供了下面这些方法： 123456789101112131415161718192021222324252627282930313233343536public interface Drawable { void draw();}public interface Resizable extends Drawable { int getWidth(); void setWidth(int width); int getHeight(); void setHeight(int height); void setAbsoluteSize(int width, int height);}用户根据自身的需求实现了 Resizable 接口，创建了 Ellipse 类：public class Ellipse implements Resizable { ...}他实现了一个处理各种 Resizable 形状（包括 Ellipse ）的游戏：public class Square implements Resizable { ...}public class Triangle implements Resizable { ...}public class Game { public static void main(String[] args) { List&lt;Resizable&gt; resizableShapes = Arrays.asList(new Square(), new Triangle(), new Ellipse()); Utils.paint(resizableShapes); }}public class Utils { public static void paint(List&lt;Resizable&gt; list) { list.forEach(r -&gt; { r.setAbsoluteSize(42, 42); r.draw(); }); }} 1.2 第二版 API库上线使用几个月之后，你收到很多请求，要求你更新 Resizable 的实现，让 Square Triangle 以及其他的形状都能支持 setRelativeSize 方法。为了满足这些新的需求，你发布了第二版API。 12345678public interface Resizable extends Drawable { int getWidth(); void setWidth(int width); int getHeight(); void setHeight(int height); void setAbsoluteSize(int width, int height); void setRelativeSize(int wFactor, int hFactor);} 对 Resizable 接口的更新导致了一系列的问题。首先，接口现在要求它所有的实现类添加setRelativeSize 方法的实现。但是用户最初实现的 Ellipse 类并未包含 setRelativeSize方法。向接口添加新方法是二进制兼容的，这意味着如果不重新编译该类，即使不实现新的方法，现有类的实现依旧可以运行。不过，用户可能修改他的游戏，在他的 Utils.paint 方法中调用setRelativeSize 方法，因为 paint 方法接受一个 Resizable 对象列表作为参数。如果传递的是一个 Ellipse 对象，程序就会抛出一个运行时错误，因为它并未实现 setRelativeSize 方法： 1Exception in thread \"main\" java.lang.AbstractMethodError:lambdasinaction.chap9.Ellipse.setRelativeSize(II)V 其次，如果用户试图重新编译整个应用（包括 Ellipse 类），他会遭遇下面的编译错误： 12Error:(9, 8) java: com.lujiahao.learnjava8.chapter9.Ellipse不是抽象的, 并且未覆盖com.lujiahao.learnjava8.chapter9.Resizable中的抽象方法setRelativeSize(int,int) 这就是默认方法试图解决的问题。它让类库的设计者放心地改进应用程序接口，无需担忧对遗留代码的影响，这是因为实现更新接口的类现在会自动继承一个默认的方法实现。 变更对Java程序的影响大体可以分成三种类型的兼容性，分别是: 二进制级的兼容 源代码级的兼容 函数行为的兼容 2. 概述默认方法默认方法由 default 修饰符修饰，并像类中声明的其他方法一样包含方法体。比如，你可以像下面这样在集合库中定义一个名为Sized 的接口，在其中定义一个抽象方法 size ，以及一个默认方法 isEmpty ： 123456public interface Sized { int size(); default boolean isEmpty() { return size() == 0; }} 这样任何一个实现了 Sized 接口的类都会自动继承 isEmpty 的实现。因此，向提供了默认实现的接口添加方法就不是源码兼容的。默认方法在Java 8的API中已经大量地使用了。本章已经介绍过我们前一章中大量使用的 Collection 接口的 stream 方法就是默认方法。 List 接口的 sort 方法也是默认方法。第3章介绍的很多函数式接口，比如 Predicate 、 Function 以及 Comparator 也引入了新的默认方法，比如 Predicate.and 或者 Function.andThen （记住，函数式接口只包含一个抽象方法，默认方法是种非抽象方法）。 3. 默认方法的使用模式3.1 可选方法类实现了接口，不过却刻意地将一些方法的实现留白。我们以Iterator 接口为例来说。 Iterator 接口定义了 hasNext 、 next ，还定义了 remove 方法。Java 8之前，由于用户通常不会使用该方法， remove 方法常被忽略。因此，实现 Interator 接口的类通常会为 remove 方法放置一个空的实现，这些都是些毫无用处的模板代码。采用默认方法之后，你可以为这种类型的方法提供一个默认的实现，这样实体类就无需在自己的实现中显式地提供一个空方法。比如，在Java 8中， Iterator 接口就为 remove 方法提供了一个默认实现，如下所示： 1234567public interface Iterator&lt;E&gt; { ... default void remove() { throw new UnsupportedOperationException(\"remove\"); } ...} 3.2 行为的多继承默认方法让之前无法想象的事儿以一种优雅的方式得以实现，即行为的多继承。这是一种让类从多个来源重用代码的能力。 Java的类只能继承单一的类，但是一个类可以实现多接口。要确认也很简单，下面是Java API中对 ArrayList 类的定义： 123public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {} 3.2.1 类型的多继承这个例子中 ArrayList 继承了一个类，实现了六个接口。因此 ArrayList 实际是七个类型的直接子类，分别是： AbstractList 、 List 、 RandomAccess 、 Cloneable 、 Serializable 、Iterable 和 Collection 。所以，在某种程度上，我们早就有了类型的多继承。由于Java 8中接口方法可以包含实现，类可以从多个接口中继承它们的行为（即实现的代码）。让我们从一个例子入手，看看如何充分利用这种能力来为我们服务。保持接口的精致性和正交性能帮助你在现有的代码基上最大程度地实现代码复用和行为组合。 3.2.2 利用正交方法的精简接口假设你需要为你正在创建的游戏定义多个具有不同特质的形状。有的形状需要调整大小，但是不需要有旋转的功能；有的需要能旋转和移动，但是不需要调整大小。这种情况下，你怎么设计才能尽可能地重用代码？你可以定义一个单独的 Rotatable 接口，并提供两个抽象方法 setRotationAngle 和getRotationAngle ，如下所示： 1234567public interface Rotatable { int getRotationAngle(); void setRotationAngle(int angleInDegrees); default void rotateBy(int angleInDegrees) { setRotationAngle((getRotationAngle() + angleInDegrees) % 360); }} 这种方式和模板设计模式有些相似，都是以其他方法需要实现的方法定义好框架算法。现在，实现了 Rotatable 的所有类都需要提供 setRotationAngle 和 getRotationAngle的实现，但与此同时它们也会天然地继承 rotateBy 的默认实现。类似地，你可以定义之前看到的两个接口 Moveable 和 Resizable 。它们都包含了默认实现。下面是 Moveable 的代码： 1234567891011121314151617181920212223public interface Moveable { int getX(); void setX(int x); int getY(); void setY(int y); default void moveHorizontally(int distance) { setX(getX() + distance); } default void moveVertically(int distance) { setY(getY() + distance); }}下面是 Resizable 的代码：public interface Resizable extends Drawable { int getWidth(); void setWidth(int width); int getHeight(); void setHeight(int height); void setAbsoluteSize(int width, int height); default void setRelativeSize(int wFactor, int hFactor){ setAbsoluteSize(getWidth() / wFactor, getHeight() / hFactor); }} 3.2.3 组合接口通过组合这些接口，你现在可以为你的游戏创建不同的实体类。比如， Monster 可以移动、旋转和缩放。 123public class Monster implements Rotatable, Moveable, Resizable { ...} Monster 类会自动继承 Rotatable 、 Moveable 和 Resizable 接口的默认方法。这个例子中，Monster 继承了 rotateBy 、 moveHorizontally 、 moveVertically 和 setRelativeSize 的实现。你现在可以直接调用不同的方法： 123Monster m = new Monster();m.rotateBy(180);m.moveVertically(10); 像你的游戏代码那样使用默认实现来定义简单的接口还有另一个好处。假设你需要修改moveVertically 的实现，让它更高效地运行。你可以在 Moveable 接口内直接修改它的实现，所有实现该接口的类会自动继承新的代码（这里我们假设用户并未定义自己的方法实现）。通过前面的介绍，你已经了解了默认方法多种强大的使用模式。不过也可能还有一些疑惑：如果一个类同时实现了两个接口，这两个接口恰巧又提供了同样的默认方法签名，这时会发生什么情况？类会选择使用哪一个方法？这些问题，我们会在接下来的一节进行讨论。 4. 解决冲突的规则随着默认方法在Java 8中引入，有可能出现一个类继承了多个方法而它们使用的却是同样的函数签名。这种情况下，类会选择使用哪一个函数？接下来的例子主要用于说明容易出问题的场景，并不表示这些场景在实际开发过程中会经常发生。 12345678910111213141516public interface A { default void hello() { System.out.println(\"Hello from A\"); }}public interface B extends A { default void hello() { System.out.println(\"Hello from B\"); }}public class C implements A, B { public static void main(String[] args) { // 猜猜打印的是什么？ new C().hello(); }} 此外，你可能早就对C++语言中著名的菱形继承问题有所了解，菱形继承问题中一个类同时继承了具有相同函数签名的两个方法。到底该选择哪一个实现呢？ Java 8也提供了解决这个问题的方案。请接着阅读下面的内容。 4.1 解决问题的三条规则如果一个类使用相同的函数签名从多个地方（比如另一个类或接口）继承了方法，通过三条规则可以进行判断。 类中的方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优先级。 如果无法依据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果 B 继承了 A ，那么 B 就比 A 更加具体。 最后，如果还是无法判断，继承了多个接口的类必须通过显式覆盖和调用期望的方法，显式地选择使用哪一个默认方法的实现。 4.2 菱形继承问题 了解即可 5. 小结 Java 8中的接口可以通过默认方法和静态方法提供方法的代码实现。 默认方法的开头以关键字 default 修饰，方法体与常规的类方法相同。 向发布的接口添加抽象方法不是源码兼容的。 默认方法的出现能帮助库的设计者以后向兼容的方式演进API。 默认方法可以用于创建可选方法和行为的多继承。 我们有办法解决由于一个类从多个接口中继承了拥有相同函数签名的方法而导致的冲突。 类或者父类中声明的方法的优先级高于任何默认方法。如果前一条无法解决冲突，那就选择同函数签名的方法中实现得最具体的那个接口的方法。 两个默认方法都同样具体时，你需要在类中覆盖该方法，显式地选择使用哪个接口中提供的默认方法。 资源获取 公众号回复 : Java8 即可获取《Java 8 in Action》中英文版! Tips 欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/03/19/%E3%80%8AJava%208%20in%20Action%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AJava%208%20in%20Action%E3%80%8BChapter%209%EF%BC%9A%E9%BB%98%E8%AE%A4%E6%96%B9%E6%B3%95/"},{"title":"《MySQL必知必会》第6-7章 过滤数据与数据过滤","text":"1. WHERE子句根据WHERE子句中指定的搜索条件进行过滤,WHERE子句在表名之后给出. 12345678mysql&gt; select prod_name,prod_price from products where prod_price = 2.50;+---------------+------------+| prod_name | prod_price |+---------------+------------+| Carrots | 2.50 || TNT (1 stick) | 2.50 |+---------------+------------+2 rows in set (0.02 sec) 在同时使用ORDERBY和WHERE子句时，应该让ORDER BY位于WHERE之后，否则将会产生错误 2. WHERE子句操作符 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 BETWEEN 在指定的两个值之间 3. WHERE子句操作3.1 检索单个值1234567mysql&gt; select prod_name,prod_price from products where prod_name = 'fuses';+-----------+------------+| prod_name | prod_price |+-----------+------------+| Fuses | 3.42 |+-----------+------------+1 row in set (0.00 sec) MySQL在执行匹配时默认不区分大小写，所以fuses与Fuses匹配。 3.2 不匹配检查12345678910111213mysql&gt; select vend_id,prod_name from products where vend_id &lt;&gt; 1003;+---------+--------------+| vend_id | prod_name |+---------+--------------+| 1001 | .5 ton anvil || 1001 | 1 ton anvil || 1001 | 2 ton anvil || 1002 | Fuses || 1005 | JetPack 1000 || 1005 | JetPack 2000 || 1002 | Oil can |+---------+--------------+7 rows in set (0.00 sec) `&lt;&gt;`和`!=`的作用是相同的,上面的语句还可以写作: `select vend_id,prod_name from products where vend_id != 1003;` 如果仔细观察上述WHERE子句中使用的条件，会看到有的值括在单引号内(如前面使用的’fuses’)，而有的值未括起来。单引号用来限定字符串。如果将值与串类型的列进行比较，则需要限定引号。用来与数值列进行比较的值不用引号。 3.3 范围检查检查某个范围的值，可使用BETWEEN操作符。它需要两个值，即范围的开始值和结束值。 1234567891011mysql&gt; select prod_name,prod_price from products where prod_price between 5 and 10;+----------------+------------+| prod_name | prod_price |+----------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || Bird seed | 10.00 || Oil can | 8.99 || TNT (5 sticks) | 10.00 |+----------------+------------+5 rows in set (0.00 sec) 3.4 空值检查NULL 无值(no value)，它与字段包含0、空字符串或仅仅包含空格不同。 12345678mysql&gt; select cust_id from customers where cust_email is null;+---------+| cust_id |+---------+| 10002 || 10005 |+---------+2 rows in set (0.00 sec) 4. 组合WHERE子句4.1 AND操作符通过不止一个列进行过滤，可使用AND操作符给WHERE子句附加条件。用在WHERE子句中的关键字，用来指示检索满足所有给定条件的行。 1234567891011mysql&gt; select prod_id,prod_price,prod_name from products where vend_id = 1003 and prod_price &lt;= 10;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| FB | 10.00 | Bird seed || FC | 2.50 | Carrots || SLING | 4.49 | Sling || TNT1 | 2.50 | TNT (1 stick) || TNT2 | 10.00 | TNT (5 sticks) |+---------+------------+----------------+5 rows in set (0.00 sec) 添加多个过滤条件，每添加一条就要使用一个AND。 4.2 OR操作符OR操作符告诉DBMS匹配任一条件而不是同时匹配两个条件。 123456789101112131415mysql&gt; select prod_name,prod_price from products where vend_id = 1002 or vend_id = 1003;+----------------+------------+| prod_name | prod_price |+----------------+------------+| Detonator | 13.00 || Bird seed | 10.00 || Carrots | 2.50 || Fuses | 3.42 || Oil can | 8.99 || Safe | 50.00 || Sling | 4.49 || TNT (1 stick) | 2.50 || TNT (5 sticks) | 10.00 |+----------------+------------+9 rows in set (0.00 sec) 4.3 计算次序SQL(像多数语言一样)在处理OR操作符前，优先处理AND操作符。 12345678910mysql&gt; select prod_name,prod_price from products where (vend_id = 1002 or vend_id = 1003) and prod_price &gt;=10;+----------------+------------+| prod_name | prod_price |+----------------+------------+| Detonator | 13.00 || Bird seed | 10.00 || Safe | 50.00 || TNT (5 sticks) | 10.00 |+----------------+------------+4 rows in set (0.00 sec) 圆括号具有较AND或OR操作符高的计算次序，DBMS首先过滤圆括号内的OR条件。任何时候使用具有AND和OR操作符的WHERE子句，都应该使用圆括号明确地分组操作符。不要过分依赖默认计算次序，即使它确实是你想要的东西也是如此。使用圆括号没有什么坏处，它能消除歧义。 5. IN操作符IN操作符用来指定条件范围，范围中的每个条件都可以进行匹配。IN取合法值的由逗号分隔的清单，全都括在圆括号中。 123456789101112131415mysql&gt; select prod_name,prod_price from products where vend_id in (1002,1003) order by prod_name;+----------------+------------+| prod_name | prod_price |+----------------+------------+| Bird seed | 10.00 || Carrots | 2.50 || Detonator | 13.00 || Fuses | 3.42 || Oil can | 8.99 || Safe | 50.00 || Sling | 4.49 || TNT (1 stick) | 2.50 || TNT (5 sticks) | 10.00 |+----------------+------------+9 rows in set (0.00 sec) IN操作符 WHERE子句中用来指定要匹配值的清单的关键字，功能与OR相当。 IN操作符的优点: 在使用长的合法选项清单时，IN操作符的语法更清楚且更直观。 在使用IN时，计算的次序更容易管理(因为使用的操作符更少)。 IN操作符一般比OR操作符清单执行更快。 IN的最大优点是可以包含其他SELECT语句，使得能够更动态地建立WHERE子句。第14章将对此进行详细介绍。 6. NOT操作符WHERE子句中的NOT操作符有且只有一个功能，那就是否定它之后所跟的任何条件。 1234567891011mysql&gt; select prod_name,prod_price from products where vend_id not in (1002,1003) order by prod_name;+--------------+------------+| prod_name | prod_price |+--------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || 2 ton anvil | 14.99 || JetPack 1000 | 35.00 || JetPack 2000 | 55.00 |+--------------+------------+5 rows in set (0.00 sec) MySQL支持使用NOT对IN、BETWEEN和 EXISTS子句取反，这与多数其他DBMS允许使用NOT对各种条件取反有很大的差别。 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/12/20/MySQL/%E3%80%8AMySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC6-7%E7%AB%A0%20%E8%BF%87%E6%BB%A4%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%BF%87%E6%BB%A4/"},{"title":"《MySQL必知必会》第1-3章 MySQL介绍","text":"1. 术语介绍 数据库(database) : 保存有组织的数据的容器(通常是一个文件或一组文件) 表(table) : 某种特定类型数据的结构化清单(具有唯一性,同一数据库中表名不能相同,不同数据库可以相同) 模式(schema) : 关于数据库和表的布局及特性的信息 列(column) : 表中的一个字段,所有表都是由一个或多个列组成 数据类型(datatype) : 所容许的数据的类型.每个表列都有相应的数据类型,它限制该列中存储的数据 行(row) : 表中的一个记录 主键(primary key) : 一列(或一组列),其值能够唯一区分表中的每行,主键列不允许NULL值 关键字(key word) : MySQL语言保留字,不可用关键字命名表或列 2. SQL / DBMS / MySQL2.1 SQL优点: SQL不是某个特定数据库供应商的专有语言,几乎所有重要的DBMS都支持SQL SQL简单易学 SQL简单灵活,可以进行分厂复杂和高级的数据库操作 2.2 数据库管理系统DBMS 基于共享文件系统 Microsoft Access / FileMarker 基于客户机-服务器 MySQL / Oracle / Microsoft SQL Server 2.3 MySQL优点 低成本 高性能 可信赖 简单易用 3. MySQL工具3.1 命令行登录命令: 1mysql -h localhost -P 3306 -uroot -p1234 注意 :最后这个-p和密码之间不能有空格其他的-h或者-u和参数间的空格是可有可无的 登录后提示: 123456789101112131415root@c67b08791485:/# mysql -h localhost -P 3306 -u root -p1234mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 5Server version: 5.7.6-m16 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; 3.2 Navicat 其他工具,请自行Google 4. 简单SQL语句4.1 显示所有数据库1234567891011121314mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || eladmin || example || lfstudio || mysql || performance_schema || shiro || shiro2 |+--------------------+18 rows in set (0.01 sec) 我这里有一些自己测试的数据库 4.2 切换到指定数据库12345mysql&gt; use shiro2;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed 4.3 显示当前数据库中所有表123456789mysql&gt; show tables;+-----------------------+| Tables_in_shiro2 |+-----------------------+| base_admin_permission || base_admin_role || base_admin_user |+-----------------------+3 rows in set (0.00 sec) 4.4 显示指定表中所有列12345678910111213mysql&gt; show columns from base_admin_role;+-------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || role_name | varchar(30) | NO | | NULL | || role_desc | varchar(100) | YES | | NULL | || permissions | varchar(20) | YES | | NULL | || create_time | varchar(64) | YES | | NULL | || update_time | varchar(64) | YES | | NULL | || role_status | int(1) | NO | | 1 | |+-------------+--------------+------+-----+---------+----------------+7 rows in set (0.00 sec) 它对每个字段返回一行，行中包含字段名、数据 类型、是否允许NULL、键信息、默认值以及其他信息 12345678910111213mysql&gt; describe base_admin_role;+-------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || role_name | varchar(30) | NO | | NULL | || role_desc | varchar(100) | YES | | NULL | || permissions | varchar(20) | YES | | NULL | || create_time | varchar(64) | YES | | NULL | || update_time | varchar(64) | YES | | NULL | || role_status | int(1) | NO | | 1 | |+-------------+--------------+------+-----+---------+----------------+7 rows in set (0.00 sec) DESCRIBE语句 MySQL支持用DESCRIBE作为SHOW COLUMNS FROM的一种快捷方式。换句话说,DESCRIBE base_admin_role;是 SHOW COLUMNS FROM base_admin_role;的一种快捷方式。 4.5 其他show语句 SHOW STATUS，用于显示广泛的服务器状态信息 SHOW CREATE DATABASE和SHOW CREATE TABLE，分别用来显示创建特定数据库或表的MySQL语句 SHOW GRANTS，用来显示授予用户(所有用户或特定用户)的安全权限 SHOW ERRORS和SHOW WARNINGS，用来显示服务器错误或警告消息 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/12/19/MySQL/%E3%80%8AMySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC1-3%E7%AB%A0%20MySQL%E4%BB%8B%E7%BB%8D/"},{"title":"03.0 Eureka简介","text":"1. Eureka简介Eureka 是 Netflix 的一个子模块，也是核心模块之一。Eureka 是一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。服务注册与发现对于微服务架构来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了。 功能类似于dubbo的注册中心，比如Zookeeper。 Netflix在设计Eureka时遵守的就是AP原则 CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得项目地址 : https://github.com/Netflix/eureka 2. Eureka架构Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来 实现服务注册和发现(请对比Zookeeper)。 Eureka 采用了 C-S 的设计架构。Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用 Eureka 的客户端连接到 Eureka Server并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。SpringCloud 的一些其他模块（比如Zuul）就可以通过 Eureka Server 来发现系统中的其他微服务，并执行相关的逻辑。 请注意和 Dubbo 的架构对比 Eureka 包含两个组件：Eureka Server 和 Eureka Client Eureka Server提供服务注册服务。各个节点启动后，会在EurekaServer中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到 Eureka Client是一个Java客户端。用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除（默认90秒） 3. 三员大将 Eureka Server 提供服务注册和发现 Service Provider 服务提供方将自身服务注册到Eureka，从而使服务消费方能够找到 Service Consumer 服务消费方从Eureka获取注册服务列表，从而能够消费服务 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/23/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/03.0%20Eureka%E7%AE%80%E4%BB%8B/"},{"title":"《MySQL必知必会》第4-5章 SELECT检索与排序","text":"1. SELECT 语句1.1 检索单个列关键字SELECT后写需要查询的列名 123456789mysql&gt; select prod_name from products;+----------------+| prod_name |+----------------+| Fuses || JetPack 1000 || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 多条SQL语句必须使用分号(;)分隔,推荐做法. SQL语句不区分大小写 1.2 检索多个列和检索单列类似,关键字SELECT后写需要查询的列名,逗号分隔 123456789mysql&gt; select prod_id,prod_name,prod_price from products;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| ANV01 | .5 ton anvil | 5.99 || ANV02 | 1 ton anvil | 9.99 || ANV03 | 2 ton anvil | 14.99 |+---------+----------------+------------+14 rows in set (0.00 sec) 1.3 检索所有列使用通配符(*)即可 1select * from products; 最好别使用*通配符,虽然此种写法方便,但是索引不需要的列通常会降低检索和应用程序的性能 1.4 检索不同行并去重使用关键字DISTINCT,指示MySQL只返回不同值,从而达到去重目的. 12345678910111213141516171819202122mysql&gt; select vend_id from products;+---------+| vend_id |+---------+| 1001 || 1002 || 1003 || 1003 || 1005 |+---------+14 rows in set (0.00 sec)mysql&gt; select distinct vend_id from products;+---------+| vend_id |+---------+| 1001 || 1002 || 1003 || 1005 |+---------+4 rows in set (0.01 sec) DISTINCT关键字必须直接放在列名的前面 不能不分使用DISTINCT,即DISTINCT关键字应用于所有列而不仅是前置它的列 1.5 限制结果 Limit使用只返回指定个数的结果,在语句后使用关键字 limit,关键字后加行数即可 12345678mysql&gt; select prod_name from products limit 2;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil |+--------------+2 rows in set (0.00 sec) 指定检索的开始行和行数 limit m,n 12345678mysql&gt; select prod_name from products limit 0,2;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil |+--------------+2 rows in set (0.00 sec) 第一个数为开始位置,第二个数为要检索出来的行数. 上面语句的意思 : 从第0行开始,检索出2行的数据. 在LIMIT中指定要检索的行数为检索的最大行数,如果没有足够的行,MySQL将只返回它能返回的那么多行. 1.6 使用完全限定的表名完全限定的表名可以默认不添加,但是在某些场景下(后续介绍)完全限定的表名还是非常有必须要的. 123456789mysql&gt; select products.prod_name from products;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil |+----------------+14 rows in set (0.00 sec) 2. 排序检索数据2.1 按单个列排序数据默认检索出来的顺序是按照数据最初在表中被添加的顺序,我们可以使用ORDER BY子句来显示的指定排序字段. 1234567891011121314151617181920mysql&gt; select prod_name from products order by prod_name;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Bird seed || Carrots || Detonator || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 此处是按照字典书序排序 2.2 按多个列排序多个列排序,只要指定列名,列名之间用逗号分隔即可.检索三个列,首先按价格排序,然后再按名称排序: 1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price,prod_name;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| FC | 2.50 | Carrots || TNT1 | 2.50 | TNT (1 stick) || FU1 | 3.42 | Fuses || SLING | 4.49 | Sling || ANV01 | 5.99 | .5 ton anvil || OL1 | 8.99 | Oil can || ANV02 | 9.99 | 1 ton anvil || FB | 10.00 | Bird seed || TNT2 | 10.00 | TNT (5 sticks) || DTNTR | 13.00 | Detonator || ANV03 | 14.99 | 2 ton anvil || JP1000 | 35.00 | JetPack 1000 || SAFE | 50.00 | Safe || JP2000 | 55.00 | JetPack 2000 |+---------+------------+----------------+14 rows in set (0.00 sec) 此例中,仅在多个行具有相同的prod_price值时才对产品按prod_name进行排序.如果prod_price列中所有的值都是唯一的,则不会按prod_name排序. 2.3 指定排序方向数据排序分为两种 : 升序(ASC)和降序(DESC). 默认的排序方式是升序. DESC关键字只应用到直接位于其前面的列名,如果想在多个列上进行降序排序,就必须对每个列指定DESC关键字 1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price desc,prod_name desc;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| JP2000 | 55.00 | JetPack 2000 || SAFE | 50.00 | Safe || JP1000 | 35.00 | JetPack 1000 || ANV03 | 14.99 | 2 ton anvil || DTNTR | 13.00 | Detonator || TNT2 | 10.00 | TNT (5 sticks) || FB | 10.00 | Bird seed || ANV02 | 9.99 | 1 ton anvil || OL1 | 8.99 | Oil can || ANV01 | 5.99 | .5 ton anvil || SLING | 4.49 | Sling || FU1 | 3.42 | Fuses || TNT1 | 2.50 | TNT (1 stick) || FC | 2.50 | Carrots |+---------+------------+----------------+14 rows in set (0.00 sec) 在字典排序中,A被视为与a相同,这是MySQL等大多数数据库管理系统默认行为,如果想要更改需要DBA的帮助 2.4 ORDER BY与LIMIT组合ORDER BY与LIMIT组合,可以找出一列中最高或最低的值 1234567mysql&gt; select prod_price from products order by prod_price desc limit 1;+------------+| prod_price |+------------+| 55.00 |+------------+1 row in set (0.00 sec) ORDER BY子句必须在FROM子句之后,LIMIT子句必须在ORDER BY子句之后但是这两个关键字联合使用会有问题,后面会单独讲解. Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/12/19/MySQL/%E3%80%8AMySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC4-5%E7%AB%A0%20SELECT%E6%A3%80%E7%B4%A2%E4%B8%8E%E6%8E%92%E5%BA%8F/"},{"title":"01.SpringCloud入门概述","text":"1. 是什么SpringCloud，基于SpringBoot提供了一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。 SpringCloud利用SpringBoot的开发便利性巧妙地简化了分布式系统基础设施的开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等,它们都可以用SpringBoot的开发风格做到一键启动和部署。 SpringBoot并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过SpringBoot风格进行再封装屏蔽掉了复杂的配置和实现原理， 最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包 1.1 SpringCloud和SpringBoot对比SpringBoot专注于快速方便的开发单个个体微服务。SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot，属于依赖的关系。SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。 1.2 SpringCloud和Dubbo 最大区别：SpringCloud抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。 严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。 品牌机与组装机的区别。很明显，Spring Cloud的功能比DUBBO更加强大，涵盖面更广，而且作为Spring的拳头项目，它也能够与Spring Framework、Spring Boot、Spring Data、Spring Batch等其他Spring项目完美融合，这些对于微服务而言是至关重要的。使用Dubbo构建的微服务架构就像组装电脑，各环节我们的选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果你是一名高手，那这些都不是问题；而Spring Cloud就像品牌机，在Spring Source的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础有足够的了解。 社区支持与更新力度最为重要的是，DUBBO停止了5年左右的更新，虽然2017.7重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网弄出了DubboX），这对于很多想要采用微服务架构的中小软件组织，显然是不太合适的，中小公司没有这么强大的技术能力去修改Dubbo源码+周边的一整套解决方案，并不是每一个公司都有阿里的大牛+真实的线上生产环境测试过。 2. 能干嘛 Distributed/versioned configuration(分布式/版本控制配置) Service registration and discovery(服务注册与发现) Routing(路由) Service-to-service calls(服务到服务的调用) Load balancing(负载均衡配置) Circuit Breakers(断路器) Distributed messaging(分布式消息管理) 等等 3.资料推荐 官网 : http://projects.spring.io/spring-cloud/ GitHub : https://springcloud.cc/spring-cloud-netflix.html SpringCloud中国社区 : http://springcloud.cn/ SpringCloud中文网 : https://springcloud.cc/ 4. 怎么玩SpringCloud主要包含如下技术栈 服务的注册与发现（Eureka） 服务消费者（rest+Ribbon） 服务消费者（Feign） 断路器（Hystrix） 断路器监控(Hystrix Dashboard) 路由网关(Zuul) 分布式配置中心(Spring Cloud Config) 消息总线(Spring Cloud Bus) 服务链路追踪(Spring Cloud Sleuth) 5. SpringCloud国内使用情况详见 : https://github.com/SpringCloud/spring-cloud-document/issues/1 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/21/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/01.SpringCloud%E5%85%A5%E9%97%A8%E6%A6%82%E8%BF%B0/"},{"title":"00.微服务概述","text":"0. 前言 本文为《SpringCloud-尚硅谷》课程文字总结 文章内容来源为课程视频和思维导图 感谢开源 课程视频 : https://www.bilibili.com/video/av64847970 1. 是什么业界大牛马丁.福勒（Martin Fowler）这样描述微服务 : https://martinfowler.com/articles/microservices.html 就目前而言，对于微服务业界并没有一个统一的、标准的定义（While there is no precise definition of this architectural style） 但通常而言，微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行在其独立的自己的进程中，服务之间互相协调、互相配合，为用户提供最终价值。服务之间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）。 每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 微服务化的核心就是将传统的一站式应用,根据业务拆分成一个个的服务,彻底地去耦合,每一个微服务提供单个业务功能,一个服务做一件事,从技术角度看就是一种小而独立的处理过程,类似进程概念,能够自行单独启动或销毁,拥有自己独立的数据库. 2. 微服务与微服务架构微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用,狭意的看,可以看作Eclipse里面的一个个微服务工程/或者Module 微服务架构微服务架构是⼀种架构模式，它提倡将单⼀应⽤程序划分成⼀组⼩的服务，服务之间互相协调、互相配合，为⽤户提供最终价值。每个服务运⾏在其独⽴的进程中，服务与服务间采⽤轻量级的通信机制互相协作（通常是基于HTTP协议的RESTful API）。每个服务都围绕着具体业务进⾏构建，并且能够被独⽴的部署到⽣产环境、类⽣产环境等。另外，应当尽量避免统⼀的、集中式的服务管理机制，对具体的⼀个服务⽽⾔，应根据业务上下⽂，选择合适的语⾔、⼯具对其进⾏构建。 3. 微服务优缺点优点 每个服务足够内聚，足够小，代码容易理解这样能聚焦一个指定的业务功能或业务需求 开发简单、开发效率提高，一个服务可能就是专一的只干一件事 微服务能够被小团队单独开发，这个小团队是2到5人的开发人员组成 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的 微服务能使用不同的语言开发 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如Jenkins, Hudson, bamboo 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果。无需通过合作才能体现价值 微服务允许你利用融合最新技术 微服务只是业务逻辑的代码，不会和HTML,CSS 或其他界面组件混合 每个微服务都有自己的存储能力，可以有自己的数据库。也可以有统一数据库 缺点 开发人员要处理分布式系统的复杂性 多服务运维难度，随着服务的增加，运维的压力也在增大 系统部署依赖 服务间通信成本 数据一致性 系统集成测试 性能监控…… 4. 微服务技术栈 5. 选择SpringCloud的理由 整体解决方案和框架成熟 社区热度高 可维护性好 学习曲线 6.国内各大公司微服务技术 阿里 Dubbo/HSF 京东 JSF 新浪微博 Motan 当当网 DubboX 7. 各微服务框架对比 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/20/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/00.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A6%82%E8%BF%B0/"},{"title":"03.2 Eureka自我保护和服务发现","text":"1. 自我保护1.1 演示先后启动eureka和provider，provider空置一段时间即可看到。 1.2 故障现象 1.3 导致原因什么是自我保护模式？ 默认情况下，如果EurekaServer在一定时间内没有接收到某个微服务实例的心跳，EurekaServer将会注销该实例（默认90秒）。但是当网络分区故障发生时，微服务与EurekaServer之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过“自我保护模式”来解决这个问题——当EurekaServer节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，EurekaServer就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该Eureka Server节点会自动退出自我保护模式。 在自我保护模式中，Eureka Server会保护服务注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阈值以上时，该Eureka Server节点就会自动退出自我保护模式。它的设计哲学就是宁可保留错误的服务注册信息，也不盲目注销任何可能健康的服务实例。一句话讲解：好死不如赖活着 综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留），也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。 在Spring Cloud中，可以使用eureka.server.enable-self-preservation = false 禁用自我保护模式。 2.服务发现对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息 2.1 修改microservicecloud-provider-dept-8001工程的DeptController增加如下代码 1234567891011121314@Autowiredprivate DiscoveryClient client;@RequestMapping(value = \"/dept/discovery\", method = RequestMethod.GET)public Object discovery() { List&lt;String&gt; list = client.getServices(); System.out.println(\"**********\" + list); List&lt;ServiceInstance&gt; srvList = client.getInstances(\"MICROSERVICECLOUD-DEPT\"); for (ServiceInstance element : srvList) { System.out.println(element.getServiceId() + \"\\t\" + element.getHost() + \"\\t\" + element.getPort() + \"\\t\" + element.getUri()); } return this.client;} 导包注意事项 ：//import com.netflix.discovery.DiscoveryClient;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.discovery.DiscoveryClient;要导入springcloud的DiscoveryClient 2.2 DeptProvider8001_App主启动类12345678910@SpringBootApplication// 本服务启动后会自动注册进 eureka 服务中@EnableEurekaClient// 服务发现@EnableDiscoveryClientpublic class ProviderDept8001Application { public static void main(String[] args) { SpringApplication.run(ProviderDept8001Application.class, args); }} 2.3 修改microservicecloud-consumer-dept-80工程的DeptController_Consumer增加下面代码 12345//测试@EnableDiscoveryClient,消费端可以调用服务发现@RequestMapping(value=\"/consumer/dept/discovery\")public Object discovery() { return restTemplate.getForObject(REST_URL_PREFIX+\"/dept/discovery\", Object.class);} 2.4 测试访问URLhttp://localhost:8001/dept/discoveryhttp://localhost/consumer/dept/discovery 资源获取公众号回复 : Eureka自我保护和服务发现 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/25/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/03.2%20Eureka%E8%87%AA%E6%88%91%E4%BF%9D%E6%8A%A4%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"},{"title":"03.4 Eureka和Zookeeper对比","text":"1. CAPCAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三大类： CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。 CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。 AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 2. Eureka VS Zookeeper二者都作为服务注册中心，Eureka比Zookeeper好在哪里?著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性P在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。 2.1 Zookeeper保证CP当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。 2.2 Eureka保证APEureka看明白了这一点，因此在设计时就优先保证可用性。 Eureka各个节点都是平等的 ，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用) 当网络稳定时，当前实例新的注册信息会被同步到其它节点中 因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/27/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/03.4%20Eureka%E5%92%8CZookeeper%E5%AF%B9%E6%AF%94/"},{"title":"04.1 Ribbon简介","text":"1. 简介Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。 简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将Netflix的中间层服务连接在一起。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer（简称LB）后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们也很容易使用Ribbon实现自定义的负载均衡算法。 2. 负载均衡负载均衡(Load Balance)，在微服务或分布式集群中经常用的一种应用。负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA。常见的负载均衡有软件Nginx，LVS，硬件 F5等。相应的在中间件，例如：dubbo和SpringCloud中均给我们提供了负载均衡， SpringCloud的负载均衡算法可以自定义。 常见两种形式: 集中式LB 即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx), 由该设施负责把访问请求通过某种策略转发至服务的提供方； 进程内LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。 Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。 3. 官网介绍https://github.com/Netflix/ribbon/wiki/Getting-Started 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/28/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/04.1%20Ribbon%E7%AE%80%E4%BB%8B/"},{"title":"03.3 Eureka集群实战","text":"Eureka集群实战记录 1. Eureka集群原理 上图是来自eureka的官方架构图 基于集群配置的eureka 处于不同节点的eureka通过Replicate进行数据同步 Application Service为服务提供者 Application Client为服务消费者 Make Remote Call完成一次服务调用 服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址，然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。当服务注册中心Eureka Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例。 2. 修改hosts文件为了方便分辨不同的结点,在host文件中定义不同的域名来表示,可以手动修改hosts文件,但是并不推荐.推荐使用SwitchHosts工具(感兴趣的朋友这里下载:https://u20964900.pipipan.com/dir/20964900-35317200-59ca11)hosts文件中增加: 1234#尚硅谷springcloud教程127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com127.0.0.1 eureka7003.com 3. 组成集群3.1 新建工程新建microservicecloud-eureka-7002和microservicecloud-eureka-7003,也可以直接复制7001工程. 3.2 父工程pom.xml增加如下内容: 12&lt;module&gt;microservicecloud-eureka-7002&lt;/module&gt;&lt;module&gt;microservicecloud-eureka-7003&lt;/module&gt; 3.3 三个子工程的yml配置修改:123456789101112131415server: port: 7001eureka: instance: # eureka服务端的实例名称 hostname: eureka7001.com client: # #false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: # #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址 #defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 123456789101112131415server: port: 7002eureka: instance: # eureka服务端的实例名称 hostname: eureka7002.com client: # #false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: # #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址 # defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7003.com:7003/eureka/ 123456789101112131415server: port: 7003eureka: instance: # eureka服务端的实例名称 hostname: eureka7003.com client: # #false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: # #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址 # defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4. 修改provider yml文件配置由原来的单节点修改为集群模式 1234567891011eureka: client: # 客户端注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: # 自定义服务名称信息 instance-id: microservicecloud-dept8001 # 访问路径可以显示IP地址 prefer-ip-address: true 5. 验证分别启动eureka7001/7002/7003,然后启动provider8001下图表示集群启动成功,并且成功注册上provider8001服务 资源获取公众号回复 : Eureka集群实战 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/26/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/03.3%20Eureka%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98/"},{"title":"05.Feign负载均衡","text":"1. Feign简介Feign是一个声明式WebService客户端。使用Feign能让编写Web Service客户端更加简单, 它的使用方法是定义一个接口，然后在上面添加注解，同时也支持JAX-RS标准的注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。 Feign旨在使编写Java Http客户端变得更容易。前面在使用Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处， 往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。 所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下， 我们只需创建一个接口并使用注解的方式来配置它(以前是Dao接口上面标注Mapper注解,现在是一个微服务接口上面标注一个Feign注解即可) ，即可完成对服务提供方的接口绑定，简化了使用Spring cloud Ribbon时，自动封装服务调用客户端的开发量。 Feign集成了Ribbon利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡。而与Ribbon不同的是， 通过feign只需要定义服务绑定接口且以声明式的方法 ，优雅而简单的实现了服务调用 2. 实战2.1 修改microservicecloud-api工程pom中增加feign配置 12345&lt;!--Feign相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; 新建service包,并新建DeptClientService 1234567891011@FeignClient(value = \"MICROSERVICECLOUD-DEPT\")public interface DeptClientService { @RequestMapping(value = \"/dept/get/{id}\", method = RequestMethod.GET) public Dept get(@PathVariable(\"id\") long id); @RequestMapping(value = \"/dept/list\", method = RequestMethod.GET) public List&lt;Dept&gt; list(); @RequestMapping(value = \"/dept/add\", method = RequestMethod.POST) public boolean add(Dept dept);} 最后要重新编译打包此模块 1mvn clean &amp;&amp; mvn install 2.2 新建工程通过复制consumer-dept-80工程,新建microservicecloud-consumer-dept-feign 2.3 pom.xml配置增加feign配置 12345&lt;!--Feign相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; 2.4 controller调用service1234567891011121314151617@RestControllerpublic class DeptController_Feign { @Autowired private DeptClientService service; @RequestMapping(value = \"/consumer/dept/get/{id}\") public Dept get(@PathVariable(\"id\") Long id) { return this.service.get(id); } @RequestMapping(value = \"/consumer/dept/list\") public List&lt;Dept&gt; list() { return this.service.list(); } @RequestMapping(value = \"/consumer/dept/add\") public Object add(Dept dept) { return this.service.add(dept); }} 2.5 修改主启动类12345678@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages= {\"com.hellodev\"})public class ConsumerDeptFeignApplication { public static void main(String[] args) { SpringApplication.run(ConsumerDeptFeignApplication.class, args); }} 2.6 验证首先启动Eureka集群,集群启动成功后再启动三个provider工程 最后启动consumer工程,并访问接口验证 资源获取公众号回复 : Feign负载均衡 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/31/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/05.Feign%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"title":"03.1 Eureka单机实战","text":"Eureka单机版实战记录 1. Eureka 服务端1.1 microservicecloud-eureka-70011.1.1 创建Module 1.1.2 父工程增加模块信息123&lt;modules&gt; &lt;module&gt;microservicecloud-eureka-7001&lt;/module&gt;&lt;/modules&gt; 1.1.3 pom文件12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-eureka-7001&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;!--eureka-server服务端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1.1.4 yml文件1234567891011121314server: port: 7001eureka: instance: # eureka服务端的实例名称 hostname: localhost client: # #false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: # #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 1.1.5 Application启动类开启配置12345678@SpringBootApplication// EurekaServer服务器端启动类,接受其它微服务注册进来@EnableEurekaServerpublic class Eureka7001Application { public static void main(String[] args) { SpringApplication.run(Eureka7001Application.class, args); }} 1.1.6 启动验证访问 : http://localhost:7001 2. Eureka 客户端2.1 修改microservicecloud-provider-dept-8001pom.xml中增加eureka客户端配置 123456789&lt;!-- 将微服务provider侧注册进 eureka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 2.2 yml修改增加eureka配置 12345eureka: client: #客户端注册进eureka服务列表内 service-url: defaultZone: http://localhost:7001/eureka 2.3 Application启动类开启配置12345678@SpringBootApplication// 本服务启动后会自动注册进 eureka 服务中@EnableEurekaClientpublic class ProviderDept8001Application { public static void main(String[] args) { SpringApplication.run(ProviderDept8001Application.class, args); }} 2.4 验证先启动microservicecloud-eureka-7001,然后再启动microservicecloud-provider-dept-8001,界面出现provider的服务即成功. 3. actuator与注册微服务信息完善3.1 主机名称:服务名称修改当前问题: 显示的是ip地址,可读性差,交流不方便 修改microservicecloud-provider-dept-8001的yml配置文件 12345678eureka: client: # 客户端注册进eureka服务列表内 service-url: defaultZone: http://localhost:7001/eureka instance: # 自定义服务名称信息 instance-id: microservicecloud-dept8001 修改之后 3.2 访问信息有IP信息提示当前问题: 鼠标放在服务名称上,底部没有IP提示 修改microservicecloud-provider-dept-8001的yml配置文件 12345678910eureka: client: # 客户端注册进eureka服务列表内 service-url: defaultZone: http://localhost:7001/eureka instance: # 自定义服务名称信息 instance-id: microservicecloud-dept8001 # 访问路径可以显示IP地址 prefer-ip-address: true 修改之后 3.3 微服务info内容详细信息当前问题 : 超链接点击服务报告ErrorPage 修改microservicecloud-provider-dept-8001 POM 12345&lt;!-- actuator监控信息完善 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 总的父工程microservicecloud修改pom.xml添加构建build信息 1234567891011121314151617181920&lt;build&gt; &lt;finalName&gt;microservicecloud&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 修改microservicecloud-provider-dept-8001 YMl 123456# 微服务信息描述info: app.name: atguigu-microservicecloud company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version} 修改之后 资源获取公众号回复 : Eureka单机实战 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/24/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/03.1%20Eureka%E5%8D%95%E6%9C%BA%E5%AE%9E%E6%88%98/"},{"title":"06.0 Hystrix简介","text":"1. 分布式系统面临的问题复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。 服务雪崩多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的 “扇出” 。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”. 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 一般情况对于服务依赖的保护主要有3中解决方案： 熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 隔离模式：这种模式就像对系统请求按类型划分成一个个小岛的一样，当某个小岛被火少光了，不会影响到其他的小岛。例如可以对不同类型的请求使用线程池来资源隔离，每种类型的请求互不影响，如果一种类型的请求线程资源耗尽，则对后续的该类型请求直接返回，不再调用后续资源。这种模式使用场景非常多，例如将一个服务拆开，对于重要的服务使用单独服务器来部署，再或者公司最近推广的多中心。 限流模式：上述的熔断模式和隔离模式都属于出错后的容错处理机制，而限流模式则可以称为预防模式。限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。这种模式不能解决服务依赖的问题，只能解决系统整体资源分配问题，因为没有被限流的请求依然有可能造成雪崩效应。 2. Hystrix简介Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常 ，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 3. Hystrix功能 服务降级 服务熔断 服务限流 接近实时的监控 等等 3.1 服务降级Hystrix服务降级，其实就是线程池中单个线程障处理，防止单个线程请求时间太长，导致资源长期被占有而得不到释放，从而导致线程池被快速占用完，导致服务崩溃。 Hystrix能解决如下问题： 请求超时降级，线程资源不足降级，降级之后可以返回自定义数据 线程池隔离降级，分布式服务可以针对不同的服务使用不同的线程池，从而互不影响 自动触发降级与恢复 实现请求缓存和请求合并 3.2 服务熔断熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 3.3 服务限流备注：限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。这种模式不能解决服务依赖的问题，只能解决系统整体资源分配问题，因为没有被限流的请求依然有可能造成雪崩效应。 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/01/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/06.0%20Hystrix%E7%AE%80%E4%BB%8B/"},{"title":"04.2 Ribbon实战","text":"Ribbon单机配置与集群实战 1. 修改microservicecloud-consumer-dept-80工程1.1 pom文件增加内容12345678910111213&lt;!-- Ribbon相关 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 1.2 修改application.yml 追加eureka的服务注册地址123456eureka: client: register-with-eureka: false #客户端不注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 1.3 RestTemplate配置对ConfigBean进行新注解@LoadBalanced 获得Rest时加入Ribbon的配置 12345@Bean@LoadBalanced // 负载均衡注解public RestTemplate getRestTemplate() { return new RestTemplate();} 1.4 主启动类DeptConsumer80_App添加@EnableEurekaClient1234567@SpringBootApplication@EnableEurekaClientpublic class ConsumerDept80Application { public static void main(String[] args) { SpringApplication.run(ConsumerDept80Application.class, args); }} 1.5 修改DeptController_Consumer客户端访问类将原来由url访问改为通过微服务名称访问 12//private static final String REST_URL_PREFIX = \"http://localhost:8001\";private static final String REST_URL_PREFIX = \"http://MICROSERVICECLOUD-DEPT\"; Ribbon和Eureka整合后Consumer可以直接调用服务而不用再关心地址和端口号 1.6 单机验证先启动Eureka集群,然后启动provider-8001注册到Eureka集群中,最后启动consumer-80,后访问下面url 123http://localhost/consumer/dept/get/1http://localhost/consumer/dept/listhttp://localhost/consumer/dept/add?dname=大数据部 正常返回数据,即表明consumer配置正确 2. Ribbon集群2.1 架构说明 Ribbon在工作时分成两步 第一步先选择 EurekaServer ,它优先选择在同一个区域内负载较少的server。 第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。 其中Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权。 2.2 新建工程根据provider-8001工程分别复制出provider-8002和provider-8003两个工程,修改相应的配置 2.3 新建数据库8002数据库脚本 123456789101112131415DROP DATABASE IF EXISTS cloudDB02; CREATE DATABASE cloudDB02 CHARACTER SET UTF8; USE cloudDB02; CREATE TABLE dept ( deptno BIGINT NOT NULL PRIMARY KEY AUTO_INCREMENT, dname VARCHAR (60), db_source VARCHAR (60) ); INSERT INTO dept(dname,db_source) VALUES ( '开发部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '人事部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '财务部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '市场部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '运维部' ,DATABASE()); SELECT * FROM dept; 8003数据库脚本 123456789101112131415DROP DATABASE IF EXISTS cloudDB03; CREATE DATABASE cloudDB03 CHARACTER SET UTF8; USE cloudDB03; CREATE TABLE dept ( deptno BIGINT NOT NULL PRIMARY KEY AUTO_INCREMENT, dname VARCHAR (60), db_source VARCHAR (60) ); INSERT INTO dept(dname,db_source) VALUES ( '开发部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '人事部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '财务部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '市场部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '运维部' ,DATABASE()); SELECT * FROM dept; 2.4 修改两个工程的yml文件8002 yml文件 12345678910111213141516171819202122232425262728293031323334server: port: 8002mybatis: config-location: classpath:mybatis/mybatis.cfg.xml type-aliases-package: com.hellodev.entities mapper-locations: - classpath:mybatis/mapper/**/*.xmlspring: application: name: microservicecloud-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloudDB02 username: root password: 1234 dbcp2: min-idle: 5 initial-size: 5 max-total: 5 max-wait-millis: 200eureka: client: #客户端注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: microservicecloud-dept8002 prefer-ip-address: true #访问路径可以显示IP地址info: app.name: atguigu-microservicecloud company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version} 8003 yml文件 12345678910111213141516171819202122232425262728293031323334server: port: 8003mybatis: config-location: classpath:mybatis/mybatis.cfg.xml type-aliases-package: com.hellodev.entities mapper-locations: - classpath:mybatis/mapper/**/*.xmlspring: application: name: microservicecloud-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloudDB03 username: root password: 1234 dbcp2: min-idle: 5 initial-size: 5 max-total: 5 max-wait-millis: 200eureka: client: #客户端注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: microservicecloud-dept8003 prefer-ip-address: true #访问路径可以显示IP地址info: app.name: atguigu-microservicecloud company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version} 2.5 集群验证首先启动Eureka集群,集群启动成功后再启动三个provider工程 最后启动consumer工程,并访问接口验证 资源获取公众号回复 : Ribbon实战 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/29/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/04.2%20Ribbon%E5%AE%9E%E6%88%98/"},{"title":"06.1 Hystrix服务熔断","text":"熔断机制是应对雪崩效应的一种微服务链路保护机制。 当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级， 进而熔断该节点微服务的调用，快速返回”错误”的响应信息。 当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。熔断机制的注解是@HystrixCommand。 1. 创建工程参考microservicecloud-provider-dept-8001, 新建microservicecloud-provider-dept-hystrix-8001 2. pom.xml文件与provider-dept-8001相比,pom文件中增加了Hystrix配置 12345&lt;!--hystrix--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 3. yml文件与provider-dept-8001相比,yml中修改了服务注册进入eureka的实例名称 1instance-id: microservicecloud-dept8001-hystrix 4. 修改DeptController在精简原来代码的基础上,增加了@HystrixCommand注解,一旦调用服务方法失败并抛出了错误信息后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中的指定方法. 12345678910111213141516171819@RestControllerpublic class DeptController { @Autowired private DeptService service; @RequestMapping(value = \"/dept/get/{id}\", method = RequestMethod.GET) @HystrixCommand(fallbackMethod = \"processHystrix_Get\") public Dept get(@PathVariable(\"id\") Long id) { Dept dept = service.get(id); if (dept == null) { throw new RuntimeException(\"该ID:\" + id + \"没有对应的信息\"); } return dept; } public Dept processHystrix_Get(@PathVariable(\"id\") Long id) { return new Dept().setDeptno(id) .setDname(\"该ID:\" + id + \"没有对应的信息,null--@HystrixCommand\") .setDb_source(\"no this database in MySQL\"); }} 5. 主启动类修改123456789101112@SpringBootApplication// 本服务启动后会自动注册进 eureka 服务中@EnableEurekaClient// 服务发现@EnableDiscoveryClient// 对hystrix熔断机制的支持@EnableCircuitBreakerpublic class ProviderDeptHystrix8001Application { public static void main(String[] args) { SpringApplication.run(ProviderDeptHystrix8001Application.class, args); }} 6. 验证首先启动Eureka集群,然后启动provider-dept-hystrix-8001,等待服务注册 最后启动consumer-dept-8001,并访问验证 123456789101112curl http://localhost/consumer/dept/get/1{ &quot;deptno&quot;: 1, &quot;dname&quot;: &quot;开发部&quot;, &quot;db_source&quot;: &quot;cloudDB01&quot;}curl http://localhost/consumer/dept/get/112{ &quot;deptno&quot;: 112, &quot;dname&quot;: &quot;该ID:112没有对应的信息,null--@HystrixCommand&quot;, &quot;db_source&quot;: &quot;no this database in MySQL&quot;} 资源获取公众号回复 : Hystrix服务熔断 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/02/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/06.1%20Hystrix%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/"},{"title":"04.3 Ribbon核心组件IRule和自定义规则","text":"1. Ribbon负载均衡算法 RoundRobinRule 轮询算法,所有注册中心中的provider会按顺序访问 RandomRule 随机算法,随机访问注册中心中的provider AvailabilityFilteringRule 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，还有并发的连接数量超过阈值的服务，然后对剩余的服务列表按照轮询策略进行访问 WeightedResponseTimeRule 根据平均响应时间计算所有服务的权重，响应时间越快服务权重越大被选中的概率越高。刚启动时如果统计信息不足，则使用RoundRobinRule策略，等统计信息足够，会切换到WeightedResponseTimeRule RetryRule 先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重试，获取可用的服务 BestAvailableRule 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 ZoneAvoidanceRule 默认规则,复合判断server所在区域的性能和server的可用性选择服务器 2. 自定义负载均衡算法2.1 修改microservicecloud-consumer-dept-80新建package com.atguigu.myrule,并新建自定义Robbin规则类 MySelfRule 官方文档明确给出了警告：这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下，否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，也就是说我们达不到特殊化定制的目的了。 12345678@Configurationpublic class MySelfRule { @Bean public IRule myRule() { // return new RandomRule(); //Ribbon默认是轮询，我自定义为随机 return new NewRandomRule(); }} 2.2 修改主启动类12345678@SpringBootApplication@EnableEurekaClient@RibbonClient(name=\"MICROSERVICECLOUD-DEPT\", configuration= MySelfRule.class)public class ConsumerDept80Application { public static void main(String[] args) { SpringApplication.run(ConsumerDept80Application.class, args); }} 2.3 自定义规则轮询策略基础上，每个服务器要求被调用5次。也即以前是每台机器一次，现在是每台机器5次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class NewRandomRule extends AbstractLoadBalancerRule { private int total = 0; //总共被调用的次数，目前要求每台被调用5次 private int currentIndex = 0;//当前提供服务的机器号 public Server choose(ILoadBalancer lb, Object key) { if (lb == null) { return null; } Server server = null; while (server == null) { if (Thread.interrupted()) { return null; } List&lt;Server&gt; upList = lb.getReachableServers(); List&lt;Server&gt; allList = lb.getAllServers(); int serverCount = allList.size(); if (serverCount == 0) { /* * No servers. End regardless of pass, because subsequent passes * only get more restrictive. */ return null; }// int index = rand.nextInt(serverCount); // server = upList.get(index); if (total &lt; 5) { server = upList.get(currentIndex); total++; } else { total = 0; currentIndex++; if (currentIndex &gt;= upList.size()) { currentIndex = 0; } } if (server == null) { /* * The only time this should happen is if the server list were * somehow trimmed. This is a transient condition. Retry after * yielding. */ Thread.yield(); continue; } if (server.isAlive()) { return (server); } // Shouldn't actually happen.. but must be transient or a bug. server = null; Thread.yield(); } return server; } @Override public Server choose(Object key) { return choose(getLoadBalancer(), key); } @Override public void initWithNiwsConfig(IClientConfig clientConfig) { }} 2.4 效果演示 资源获取公众号回复 : Ribbon核心组件IRule和自定义规则 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/30/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/04.3%20Ribbon%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6IRule%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%84%E5%88%99/"},{"title":"06.2 Hystrix服务降级","text":"整体资源快不够用，先将某些服务关掉，待整体恢复后，再开启回来，服务降级处理是在客户端实现完成的，与服务端没有关系。 1. 修改microservicecloud-api工程根据已经有的DeptClientService接口新建一个实现了FallbackFactory接口的类DeptClientServiceFallbackFactory 12345678910111213141516171819202122@Component//不要忘记添加，不要忘记添加public class DeptClientServiceFallbackFactory implements FallbackFactory&lt;DeptClientService&gt; { @Override public DeptClientService create(Throwable throwable) { return new DeptClientService() { @Override public Dept get(long id) { return new Dept().setDeptno(id) .setDname(\"该ID：\" + id + \"没有没有对应的信息,Consumer客户端提供的降级信息,此刻服务Provider已经关闭\") .setDb_source(\"no this database in MySQL\"); } @Override public List&lt;Dept&gt; list() { return null; } @Override public boolean add(Dept dept) { return false; } }; }} 2. 修改DeptClientService接口在注解@FeignClient中添加fallbackFactory属性值 12345678910//@FeignClient(value = \"MICROSERVICECLOUD-DEPT\")@FeignClient (value = \"MICROSERVICECLOUD-DEPT\", fallbackFactory=DeptClientServiceFallbackFactory.class)public interface DeptClientService { @RequestMapping(value = \"/dept/get/{id}\", method = RequestMethod.GET) public Dept get(@PathVariable(\"id\") long id); @RequestMapping(value = \"/dept/list\", method = RequestMethod.GET) public List&lt;Dept&gt; list(); @RequestMapping(value = \"/dept/add\", method = RequestMethod.POST) public boolean add(Dept dept);} 重新编译microservicecloud-api工程 3. microservicecloud-consumer-dept-feign工程修改yml1234567891011server: port: 80feign: hystrix: enabled: trueeureka: client: register-with-eureka: false #客户端不注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 4. 验证启动Eureka集群, 再将微服务microservicecloud-provider-dept-8001启动, 最后启动microservicecloud-consumer-dept-feign 123456curl http://localhost/consumer/dept/get/1{ &quot;deptno&quot;: 1, &quot;dname&quot;: &quot;开发部&quot;, &quot;db_source&quot;: &quot;cloudDB01&quot;} 故意关闭微服务microservicecloud-provider-dept-8001 123456curl http://localhost/consumer/dept/get/1{ &quot;deptno&quot;: 1, &quot;dname&quot;: &quot;该ID：1没有没有对应的信息,Consumer客户端提供的降级信息,此刻服务Provider已经关闭&quot;, &quot;db_source&quot;: &quot;no this database in MySQL&quot;} 此时服务端provider已经down了，但是我们做了服务降级处理，让客户端在服务端不可用时也会获得提示信息而不会挂起耗死服务器 资源获取公众号回复 : Hystrix服务降级 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/03/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/06.2%20Hystrix%E6%9C%8D%E5%8A%A1%E9%99%8D%E7%BA%A7/"},{"title":"07.Zuul路由网关","text":"Zuul路由网关简介与实战 1. 概述Zuul包含了对请求的路由和过滤两个最主要的功能,其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础.Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他微服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。 注意：Zuul服务最终还是会注册进Eureka Zuul功能 代理 路由 过滤 官网 : https://github.com/Netflix/zuul/wiki/Getting-Started 2. 路由基本配置2.1 新建Module模块microservicecloud-zuul-gateway-9527 2.2 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-zuul-gateway-9527&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的 api 通用包，可以使用 Dept 部门Entity --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- zuul 路由网关 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 将微服务provider侧注册进 eureka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- actuator监控信息完善 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3 yml文件12345678910111213141516171819202122server: port: 9527spring: application: name: microservicecloud-zuul-gatewayeureka: client: # 客户端注册进eureka服务列表内 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: # 自定义服务名称信息 instance-id: gateway-9527.com # 访问路径可以显示IP地址 prefer-ip-address: true# 微服务信息描述info: app.name: atguigu-microservicecloud company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version} 2.4 修改hosts1127.0.0.1 myzuul.com 2.5 主启动类1234567@SpringBootApplication@EnableZuulProxypublic class ZuulGateway9527Application { public static void main(String[] args) { SpringApplication.run(ZuulGateway9527Application.class, args); }} 2.6 验证启动Eureka集群,然后启动provider-dept-8001,最后启动zuul-gateway-9527,访问接口 123456789101112不使用路由 : curl http://localhost:8001/dept/get/2{ &quot;deptno&quot;: 2, &quot;dname&quot;: &quot;人事部&quot;, &quot;db_source&quot;: &quot;cloudDB01&quot;}使用路由 : curl http://myzuul.com:9527/microservicecloud-dept/dept/get/2{ &quot;deptno&quot;: 2, &quot;dname&quot;: &quot;人事部&quot;, &quot;db_source&quot;: &quot;cloudDB01&quot;} 3. 路由访问映射规则3.1 自定义微服务别名修改yml 12345zuul: # 自定义微服务别名 routes: mydept.serviceId: microservicecloud-dept mydept.path: /mydept/** 此时即可通过别名的方式访问微服务 1curl http://myzuul.com:9527/mydept/dept/get/1 3.2 隐藏真实微服务名称上面修改方式,还是可以通过真实微服务名称访问接口,这依旧是不安全的,因此需要隐藏.修改yml 12345678zuul: # 隐藏真实服务名,不可通过真实微服务名称访问 多个微服务可以用\"*\" # ignored-services: microservicecloud-dept ignored-services: \"*\" # 自定义微服务别名 routes: mydept.serviceId: microservicecloud-dept mydept.path: /mydept/** 再次访问 12curl http://myzuul.com:9527/microservicecloud-dept/dept/get/2{&quot;timestamp&quot;:1566983040888,&quot;status&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:&quot;Not Found&quot;,&quot;path&quot;:&quot;/microservicecloud-dept/dept/get/2&quot;} 3.3 设置统一公共前缀修改yml文件 12345678910zuul: # 设置统一公共访问前缀 prefix: /atguigu # 隐藏真实服务名,不可通过真实微服务名称访问 多个微服务可以用\"*\" # ignored-services: microservicecloud-dept ignored-services: \"*\" # 自定义微服务别名 routes: mydept.serviceId: microservicecloud-dept mydept.path: /mydept/** 之后所有的请求都需要要增加统一前缀 资源获取公众号回复 : Zuul路由网关 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/05/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/07.Zuul%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"title":"08.1 SpringCloud Config配置中心简介","text":"微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。SpringCloud提供了ConfigServer来解决这个问题，我们每一个微服务自己带着一个application.yml，上百个配置文件的管理. 1. 是什么SpringCloud Config为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为 各个不同微服务应用 的所有环境提供了一个 中心化的外部配置 。 2. 怎么玩SpringCloud Config分为 服务端和客户端两部分 。 服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容。 3. 能干嘛 集中管理配置文件 不同环境不同配置，动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接口的形式暴露 4. 整合由于SpringCloud Config默认使用Git来存储配置文件(也有其它方式,比如支持SVN和本地文件)，但最推荐的还是Git，而且使用的是http/https访问的形式 资源获取公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/06/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/08.1%20SpringCloud%20Config%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E7%AE%80%E4%BB%8B/"},{"title":"06.3 Hystrix服务监控","text":"除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控（Hystrix Dashboard），Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。 1. 新建工程microservicecloud-consumer-hystrix-dashboard 2. pom.xml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-consumer-hystrix-dashboard-9001&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;!--自己定义的api --&gt; &lt;dependency&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--修改后立即生效，热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Ribbon相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--feign相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- hystrix和 hystrix-dashboard相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3. yml文件12server: port: 9001 4. 主启动类1234567@SpringBootApplication@EnableHystrixDashboardpublic class ConsumerHystrixDashboard9001Application { public static void main(String[] args) { SpringApplication.run(ConsumerHystrixDashboard9001Application.class, args); }} 5. Provider微服务监控所有Provider微服务提供类(8001/8002/8003)都需要监控依赖配置检查是否都有监控配置 12345&lt;!-- actuator监控信息完善 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 6. 启动microservicecloud-consumer-hystrix-dashboard访问 http://localhost:9001/hystrix 7. 验证启动Eureka集群, 再启动microservicecloud-provider-dept-hystrix-8001,访问 123456curl http://localhost:8001/dept/get/1{ &quot;deptno&quot;: 1, &quot;dname&quot;: &quot;开发部&quot;, &quot;db_source&quot;: &quot;cloudDB01&quot;} http://localhost:8001/hystrix.stream 8. 监控界面8.1 填写监控地址 Delay：该参数用来控制服务器上轮询监控信息的延迟时间，默认为2000毫秒，可以通过配置该属性来降低客户端的网络和CPU消耗。 Title：该参数对应了头部标题Hystrix Stream之后的内容，默认会使用具体监控实例的URL，可以通过配置该信息来展示更合适的标题。 8.2 监控界面 实心圆 : 共有两种含义。它通过颜色的变化代表了实例的健康程度，它的健康度从绿色&lt;黄色&lt;橙色&lt;红色递减。该实心圆除了颜色的变化之外，它的大小也会根据实例的请求流量发生变化，流量越大该实心圆就越大。所以通过该实心圆的展示，就可以在大量的实例中快速的发现 故障实例和高压力实例。 曲线 : 用来记录2分钟内流量的相对变化，可以通过它来观察到流量的上升和下降趋势。 整体说明 动图演示:多次刷新http://localhost:8001/dept/get/1 资源获取公众号回复 : Hystrix服务监控 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/04/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/06.3%20Hystrix%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7/"},{"title":"08.2 SpringCloud Config服务端配置","text":"SpringCloud Config服务端配置 1. Git托管配置文件本文使用Github私有仓库来实现,创建过程略(配置文件为敏感数据,尽量使用私有仓库模式) 创建完成后添加文件 application.yml文件 1234567891011121314151617spring: profiles: active: - dev---spring: #开发环境 profiles: dev application: name: microservicecloud-config-atguigu-dev---spring: #测试环境 profiles: test application: name: microservicecloud-config-atguigu-test#请保存为UTF-8格式 2. 服务端配置2.1 新建Module模块microservicecloud-config-3344它即为Cloud的配置中心模块 2.2 pom.xml文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-config-3344&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的 api 通用包，可以使用 Dept 部门Entity --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- springCloud Config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 避免 Config 的 Git 插件报错： org /eclipse/ jgit / api /TransportConfigCallback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;4.10.0.201712302008-r&lt;/version&gt; &lt;/dependency&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 将微服务provider侧注册进 eureka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- actuator监控信息完善 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3 yml文件1234567891011server: port: 3344spring: application: name: microservicecloud-config cloud: config: server: git: #GitHub上面的git仓库名字 uri: git@github.com:lujiahao0708/microservicecloud-config.git 2.4 主启动类1234567@SpringBootApplication@EnableConfigServerpublic class Config3344Application { public static void main(String[] args) { SpringApplication.run(Config3344Application.class, args); }} 2.5 hosts文件增加1127.0.0.1 config-3344.com 2.6 验证启动config-3344服务,访问url查看结果 前两个分别为dev环境和test环境,最后一个为不存在的环境 3. 配置读取规则/{application}-{profile}.yml http://config-3344.com:3344/application-dev.yml http://config-3344.com:3344/application-test.yml http://config-3344.com:3344/application-xxx.yml(不存在的配置) /{application}/{profile}[/{label}] http://config-3344.com:3344/application/dev/master http://config-3344.com:3344/application/test/master http://config-3344.com:3344/application/xxx/master /{label}/{application}-{profile}.yml http://config-3344.com:3344/master/application-dev.yml http://config-3344.com:3344/master/application-test.yml资源获取公众号回复 : SpringCloud Config服务端配置 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/07/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/08.2%20SpringCloud%20Config%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%85%8D%E7%BD%AE/"},{"title":"08.3 SpringCloud Config客户端配置","text":"SpringCloud Config客户端配置 1. 创建客户端配置文件在microservice-config工程中创建 microservicecloud-config-client.yml 文件,并推送到Github私有仓库中 1234567891011121314151617181920212223242526spring: profiles: active: - dev---server: port: 8201spring: profiles: dev application: name: microservicecloud-config-clienteureka: client: service-url: defaultZone: http://eureka-dev.com:7001/eureka/---server: port: 8202spring: profiles: test application: name: microservicecloud-config-clienteureka: client: service-url: defaultZone: http://eureka-test.com:7001/eureka/ 2. 创建客户端工程2.1 新建microservicecloud-config-client-3355略 2.2 pom.xml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-config-client-3355&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的 api 通用包，可以使用 Dept 部门Entity --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringCloud Config 客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter- config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 将微服务provider侧注册进 eureka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- actuator监控信息完善 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3 创建bootstrap.ymlapplicaiton.yml是用户级的资源配置项bootstrap.yml是系统级的， 优先级更加高Spring Cloud会创建一个Bootstrap Context，作为Spring应用的Application Context的 父上下文 。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。Bootstrap属性有高优先级，默认情况下，它们不会被本地配置覆盖。Bootstrap context和Application Context有着不同的约定，所以新增了一个bootstrap.yml文件，保证Bootstrap Context和Application Context配置的分离。 12345678910spring: cloud: config: #需要从github上读取的资源名称，注意没有yml后缀名 name: microservicecloud-config-client #本次访问的配置项 profile: dev label: master #本微服务启动后先去找3344号服务，通过SpringCloudConfig获取GitHub的服务地址 uri: http://config-3344.com:3344 2.4 创建application.yml文件123spring: application: name: microservicecloud-config-client 2.5 hosts文件增加1127.0.0.1 client-config.com 2.6 新建 ConfigClientRest123456789101112131415@RestControllerpublic class ConfigClientRest { @Value(\"${spring.application.name}\") private String applicationName; @Value(\"${eureka.client.service-url.defaultZone}\") private String eurekaServers; @Value(\"${server.port}\") private String port; @RequestMapping(\"/config\") public String getConfig() { String str = \"applicationName: \" + applicationName + \"\\t eurekaServers:\" + eurekaServers + \"\\t port: \" + port; System.out.println(\"******str: \" + str); return \"applicationName: \" + applicationName + \"\\t eurekaServers:\" + eurekaServers + \"\\t port: \" + port; }} 2.7 主启动类123456@SpringBootApplicationpublic class ConfigClient3355Application { public static void main(String[] args) { SpringApplication.run(ConfigClient3355Application.class, args); }} 2.8 验证 先启动config-3344服务,在启动config-client-3355 bootstrap.yml里面的profile值是什么，决定从github上读取什么 假如目前是 profile: dev ,dev默认在github上对应的端口就是8201,接口访问http://client-config.com:8201/config 假如目前是 profile: test,test默认在github上对应的端口就是8202,接口访问http://client-config.com:8202/config 成功实现了客户端3355访问SpringCloud Config3344通过GitHub获取配置信息 资源获取公众号回复 : SpringCloud Config客户端配置 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/08/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/08.3%20SpringCloud%20Config%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE/"},{"title":"08.4 SpringCloud Config配置实战","text":"部门微服务和注册中心微服务接入SpringCloud Config配置实战 1. Git配置文件本地配置创建配置文件并上传至Github私有仓库microservicecloud-config-eureka-client.yml 12345678910111213141516171819202122232425262728293031323334spring: profiles: active: - dev---server: port: 7001 #注册中心占用7001端口,冒号后面必须要有空格spring: profiles: dev application: name: microservicecloud-config-eureka-clienteureka: instance: hostname: eureka7001.com #冒号后面必须要有空格 client: register-with-eureka: false #当前的eureka-server自己不注册进服务列表中 fetch-registry: false #不通过eureka获取注册信息 service-url: defaultZone: http://eureka7001.com:7001/eureka/---server: port: 7001 #注册中心占用7001端口,冒号后面必须要有空格spring: profiles: test application: name: microservicecloud-config-eureka-clienteureka: instance: hostname: eureka7001.com #冒号后面必须要有空格 client: register-with-eureka: false #当前的eureka-server自己不注册进服务列表中 fetch-registry: false #不通过eureka获取注册信息 service-url: defaultZone: http://eureka7001.com:7001/eureka/ microservicecloud-config-dept-client.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576spring: profiles: active: - dev---server: port: 8001spring: profiles: dev application: name: microservicecloud-config-dept-client datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloudDB01 username: root password: 123456 dbcp2: min-idle: 5 initial-size: 5 max-total: 5 max-wait-millis: 200mybatis: config-location: classpath:mybatis/mybatis.cfg.xml type-aliases-package: com.hellodev.entities mapper-locations: - classpath:mybatis/mapper/**/*.xmleureka: client: #客户端注册进eureka服务列表内 service-url: defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: dept-8001.com prefer-ip-address: trueinfo: app.name: atguigu-microservicecloud-springcloudconfig01 company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version}---server: port: 8001spring: profiles: test application: name: microservicecloud-config-dept-client datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloudDB02 username: root password: 123456 dbcp2: min-idle: 5 initial-size: 5 max-total: 5 max-wait-millis: 200mybatis: config-location: classpath:mybatis/mybatis.cfg.xml type-aliases-package: com.hellodev.entities mapper-locations: - classpath:mybatis/mapper/**/*.xml eureka: client: #客户端注册进eureka服务列表内 service-url: defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: dept-8001.com prefer-ip-address: trueinfo: app.name: atguigu-microservicecloud-springcloudconfig02 company.name: www.atguigu.com build.artifactId: ${project.artifactId} build.version: ${project.version} 2. Config版的eureka服务端2.1 新建工程创建microservicecloud-config-eureka-client-7001工程,步骤省略. 2.2 POM1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-config-eureka-client-7001&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;!-- SpringCloudConfig配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-server服务端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3 bootstrap.yml123456789spring: cloud: config: #需要从github上读取的资源名称，注意没有yml后缀名 name: microservicecloud-config-eureka-client profile: dev label: master #SpringCloudConfig获取的服务地址 uri: http://config-3344.com:3344 2.4 application.yml123spring: application: name: microservicecloud-config-eureka-client 2.5 主启动类12345678@SpringBootApplication// EurekaServer服务器端启动类,接受其它微服务注册进来@EnableEurekaServerpublic class ConfigEureka7001Application { public static void main(String[] args) { SpringApplication.run(ConfigEureka7001Application.class, args); }} 2.6 验证 先启动microservicecloud-config-3344微服务，保证Config总配置是OK的 再启动microservicecloud-config-eureka-client-7001微服务 访问url http://eureka7001.com:7001/ 出现eureak主页表示成功启动 3. Config版的dept微服务3.1 创建工程参考之前的8001拷贝后新建工程microservicecloud-config-dept-client-8001 3.2 POM1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-config-dept-client-8001&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的 api 通用包，可以使用 Dept 部门Entity --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringCloudConfig配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--将微服务provider侧注册进eureka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator监控信息完善--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--修改后立即生效，热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3.3 bootstrap.yml1234567891011spring: cloud: config: #需要从github上读取的资源名称，注意没有yml后缀名 name: microservicecloud-config-dept-client #profile配置是什么就取什么配置dev or test profile: dev# profile: test label: master #SpringCloudConfig获取的服务地址 uri: http://config-3344.com:3344 3.4 application.yml123spring: application: name: microservicecloud-config-dept-client 3.5 主启动类12345678910@SpringBootApplication// 本服务启动后会自动注册进 eureka 服务中@EnableEurekaClient// 服务发现@EnableDiscoveryClientpublic class ConfigClientProviderDept8001Application { public static void main(String[] args) { SpringApplication.run(ConfigClientProviderDept8001Application.class, args); }} 3.6 验证本地换配置成dev 123456789101112131415161718192021222324252627282930313233curl http://localhost:8001/dept/list[ { \"deptno\": 1, \"dname\": \"开发部\", \"db_source\": \"cloudDB01\" }, { \"deptno\": 2, \"dname\": \"人事部\", \"db_source\": \"cloudDB01\" }, { \"deptno\": 3, \"dname\": \"财务部\", \"db_source\": \"cloudDB01\" }, { \"deptno\": 4, \"dname\": \"市场部\", \"db_source\": \"cloudDB01\" }, { \"deptno\": 5, \"dname\": \"运维部\", \"db_source\": \"cloudDB01\" }, { \"deptno\": 6, \"dname\": \"AI\", \"db_source\": \"cloudDB01\" }] 可以看到数据库配置是01 test配置默认访问 12345678910111213141516171819202122232425262728curl http://localhost:8001/dept/list[ { \"deptno\": 1, \"dname\": \"开发部\", \"db_source\": \"cloudDB02\" }, { \"deptno\": 2, \"dname\": \"人事部\", \"db_source\": \"cloudDB02\" }, { \"deptno\": 3, \"dname\": \"财务部\", \"db_source\": \"cloudDB02\" }, { \"deptno\": 4, \"dname\": \"市场部\", \"db_source\": \"cloudDB02\" }, { \"deptno\": 5, \"dname\": \"运维部\", \"db_source\": \"cloudDB02\" }] 可以看到数据库配置是02 资源获取公众号回复 : SpringCloud Config配置实战 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/09/09/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/08.4%20SpringCloud%20Config%E9%85%8D%E7%BD%AE%E5%AE%9E%E6%88%98/"},{"title":"02.Rest微服务构建案例","text":"1. 工程结构MicroServiceCloud |— microservicecloud-api # 封装整体entity/接口/公共配置等 |— microservicecloud-provider-dept-8001 # 微服务落地的服务提供者 |— microservicecloud-consumer-dept-80 # 微服务调用的客户端 2. Spring Cloud和Spring Boot版本1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 3. MicroServiceCloud父工程3.1 新建工程, packageing选择pom 3.2 pom文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;project.version&gt;0.0.1&lt;/project.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 4. microservicecloud-api4.1 创建Module 4.2 父工程增加模块信息123&lt;modules&gt; &lt;module&gt;microservicecloud-api&lt;/module&gt;&lt;/modules&gt; 4.3 pom文件1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 子类里面显示声明才能有明确的继承表现，无意外就是父类的默认版本否则自己定义 --&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;!-- 当前Module需要用到的jar包，按自己需求添加，如果父类已经包含了，可以不用写版本号 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 4.4 新建entities包并创建Dept部门类12345678910111213@SuppressWarnings(\"serial\")@NoArgsConstructor@Data@Accessors(chain = true)public class Dept implements Serializable { private Long deptno; //主键 private String dname; //部门名称 private String db_source; //来自那个数据库，因为微服务架构可以一个服务对应一个数据库，同一个信息被存储到不同数据库 public Dept(String dname) { super(); this.dname = dname; }} 4.5 maven编译12mvn clean install模块编译后可供其他工程使用,达到通用目的. 5. microservicecloud-provider-dept-80015.1 创建Module 5.2 父工程增加模块信息123&lt;modules&gt; &lt;module&gt;microservicecloud-provider-dept-8001&lt;/module&gt;&lt;/modules&gt; 5.3 pom文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-provider-dept-8001&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的 api 通用包，可以使用 Dept 部门Entity --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 5.4 yml文件123456789101112131415161718192021server: port: 8001mybatis: config-location: classpath:mybatis/mybatis.cfg.xml type-aliases-package: com.hellodev.api.entities mapper-locations: - classpath:mybatis/mapper/**/*.xmlspring: application: name: microservicecloud-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloudDB01 username: root password: 1234 dbcp2: min-idle: 5 initial-size: 5 max-total: 5 max-wait-millis: 200 5.5 整合mybatis—mybatis.cfg.xml在src/main/resources目录下新建mybatis文件夹,然后创建mybatis.cfg.xml 12345678&lt;?xml version = \"1.0\" encoding = \"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;!-- 二级缓存开启 --&gt; &lt;/settings&gt;&lt;/configuration&gt; 5.6 数据库初始化脚本1234567891011121314DROP DATABASE IF EXISTS cloudDB01; CREATE DATABASE cloudDB01 CHARACTER SET UTF8; USE cloudDB01; CREATE TABLE dept( deptno BIGINT NOT NULL PRIMARY KEY AUTO_INCREMENT, dname VARCHAR (60), db_source VARCHAR (60) ); INSERT INTO dept(dname,db_source) VALUES ( '开发部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '人事部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '财务部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '市场部' ,DATABASE()); INSERT INTO dept(dname,db_source) VALUES ( '运维部' ,DATABASE()); SELECT * FROM dept; 5.7 创建Mapper.xml在src/main/resources目录下新建mapper文件夹,然后创建DeptMapper.xml 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.hellodev.dao.DeptDao\"&gt; &lt;select id=\"findById\" resultType=\"com.hellodev.entities.Dept\" parameterType=\"Long\"&gt; select deptno , dname ,db_source from dept where deptno =#{ deptno }; &lt;/select&gt; &lt;select id=\"findAll\" resultType=\"com.hellodev.entities.Dept\"&gt; select deptno , dname ,db_source from dept ; &lt;/select&gt; &lt;insert id=\"addDept\" parameterType=\"com.hellodev.entities.Dept\"&gt; INSERT INTO dept ( dname ,db_source) VALUES(#{ dname }, DATABASE() ); &lt;/insert&gt;&lt;/mapper&gt; 5.8 编写Dao创建dao包,并创建DeptDao.java 123456@Mapperpublic interface DeptDao { public boolean addDept(Dept dept); public Dept findById(Long id); public List&lt;Dept&gt; findAll();} 5.9 编写Service及实现类创建service包,并创建DeptService.java和DeptServiceImpl.java 12345678910111213141516171819202122public interface DeptService { public boolean add(Dept dept); public Dept get(Long id); public List&lt;Dept&gt; list();}@Servicepublic class DeptServiceImpl implements DeptService { @Autowired private DeptDao dao; @Override public boolean add(Dept dept) { return dao.addDept(dept); } @Override public Dept get(Long id) { return dao.findById(id); } @Override public List&lt;Dept&gt; list() { return dao.findAll(); }} 5.10 编写Controller创建controller包,并创建DeptController.java 1234567891011121314151617@RestControllerpublic class DeptController { @Autowired private DeptService service; @RequestMapping(value = \"/dept/add\", method = RequestMethod.POST) public boolean add(@RequestBody Dept dept) { return service.add(dept); } @RequestMapping(value = \"/dept/get/{id}\", method = RequestMethod.GET) public Dept get(@PathVariable(\"id\") Long id) { return service.get(id); } @RequestMapping(value = \"/dept/list\", method = RequestMethod.GET) public List&lt;Dept&gt; list() { return service.list(); }} 5.11 验证启动工程,并使用curl命令验证 123456curl http://localhost:8001/dept/get/2{\"deptno\":2,\"dname\":\"人事部\",\"db_source\":\"cloudDB01”}curl http://localhost:8001/dept/list[{\"deptno\":1,\"dname\":\"开发部\",\"db_source\":\"cloudDB01\"},{\"deptno\":2,\"dname\":\"人事部\",\"db_source\":\"cloudDB01\"},{\"deptno\":3,\"dname\":\"财务部\",\"db_source\":\"cloudDB01\"},{\"deptno\":4,\"dname\":\"市场部\",\"db_source\":\"cloudDB01\"},{\"deptno\":5,\"dname\":\"运维部\",\"db_source\":\"cloudDB01\"}] 6. microservicecloud-consumer-dept-806.1 创建Module 6.2 父工程增加模块信息123&lt;modules&gt; &lt;module&gt;microservicecloud-consumer-dept-80&lt;/module&gt;&lt;/modules&gt; 6.3 pom文件123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;atguigu-microservicecloud&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;microservicecloud-consumer-dept-80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 自己定义的 api --&gt; &lt;groupId&gt;com.hellodev&lt;/groupId&gt; &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 6.4 yml文件12server: port: 80 6.5 配置RestTemplate RestTemplate : RestTemplate提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务模板类，是Spring提供的用于访问Rest服务的客户端模板工具集(https://docs.spring.io/spring-framework/docs/4.3.7.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html) 创建cfgbean包,并创建ConfigBean.java 1234567@Configurationpublic class ConfigBean { @Bean public RestTemplate getRestTemplate() { return new RestTemplate(); }} 6.6 使用RestTemplate创建controller包,并创建DeptController_Consumer.java 12345678910111213141516171819@RestControllerpublic class DeptController_Consumer { private static final String REST_URL_PREFIX = \"http://localhost:8001\"; @Autowired private RestTemplate restTemplate; @RequestMapping(value = \"/consumer/dept/add\") public boolean add(Dept dept) { return restTemplate.postForObject(REST_URL_PREFIX + \"/dept/add\", dept, Boolean.class); } @RequestMapping(value = \"/consumer/dept/get/{id}\") public Dept get(@PathVariable(\"id\") Long id) { return restTemplate.getForObject(REST_URL_PREFIX + \"/dept/get/\" + id, Dept.class); } @SuppressWarnings(\"unchecked\") @RequestMapping(value = \"/consumer/dept/list\") public List&lt;Dept&gt; list() { return restTemplate.getForObject(REST_URL_PREFIX + \"/dept/list\", List.class); }} 6.7 验证分别启动microservicecloud-provider-dept-8081和microservicecloud-consumer-dept-80 123456curl http://localhost/consumer/dept/get/2{&quot;deptno&quot;:2,&quot;dname&quot;:&quot;人事部&quot;,&quot;db_source&quot;:&quot;cloudDB01”}curl http://localhost/consumer/dept/list[{&quot;deptno&quot;:1,&quot;dname&quot;:&quot;开发部&quot;,&quot;db_source&quot;:&quot;cloudDB01&quot;},{&quot;deptno&quot;:2,&quot;dname&quot;:&quot;人事部&quot;,&quot;db_source&quot;:&quot;cloudDB01&quot;},{&quot;deptno&quot;:3,&quot;dname&quot;:&quot;财务部&quot;,&quot;db_source&quot;:&quot;cloudDB01&quot;},{&quot;deptno&quot;:4,&quot;dname&quot;:&quot;市场部&quot;,&quot;db_source&quot;:&quot;cloudDB01&quot;},{&quot;deptno&quot;:5,&quot;dname&quot;:&quot;运维部&quot;,&quot;db_source&quot;:&quot;cloudDB01&quot;}] 两个接口返回内容与上一个工程一致,这表明我们工程正确。 资源获取公众号回复 : Rest微服务构建案例 获取本节代码 公众号回复 : SpringCloud思维导图 Tips欢迎收藏和转发，感谢你的支持！(๑•̀ㅂ•́)و✧ 欢迎关注我的公众号：后端小哥，专注后端开发，希望和你一起进步！","link":"/2019/08/22/SpringCloud/%E5%B0%9A%E7%A1%85%E8%B0%B7-SpringCloud%E6%95%99%E7%A8%8B/02.Rest%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%84%E5%BB%BA%E6%A1%88%E4%BE%8B/"}],"tags":[{"name":"Http","slug":"Http","link":"/tags/Http/"},{"name":"打包","slug":"打包","link":"/tags/%E6%89%93%E5%8C%85/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"jar","slug":"jar","link":"/tags/jar/"},{"name":"aar","slug":"aar","link":"/tags/aar/"},{"name":"Volley","slug":"Volley","link":"/tags/Volley/"},{"name":"JavaEE","slug":"JavaEE","link":"/tags/JavaEE/"},{"name":"后台","slug":"后台","link":"/tags/%E5%90%8E%E5%8F%B0/"},{"name":"Java基础","slug":"Java基础","link":"/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"CI&amp;CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"持续集成","slug":"持续集成","link":"/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"博客系统","slug":"博客系统","link":"/tags/%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/"},{"name":"支付","slug":"支付","link":"/tags/%E6%94%AF%E4%BB%98/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"JavaWeb基础","slug":"JavaWeb基础","link":"/tags/JavaWeb%E5%9F%BA%E7%A1%80/"},{"name":"Servlet","slug":"Servlet","link":"/tags/Servlet/"},{"name":"JSP","slug":"JSP","link":"/tags/JSP/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Hibernate","slug":"Hibernate","link":"/tags/Hibernate/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"监听器","slug":"监听器","link":"/tags/%E7%9B%91%E5%90%AC%E5%99%A8/"},{"name":"IntellJ","slug":"IntellJ","link":"/tags/IntellJ/"},{"name":"MVC","slug":"MVC","link":"/tags/MVC/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"商城","slug":"商城","link":"/tags/%E5%95%86%E5%9F%8E/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"iterm2","slug":"iterm2","link":"/tags/iterm2/"},{"name":"分页","slug":"分页","link":"/tags/%E5%88%86%E9%A1%B5/"},{"name":"日志规范","slug":"日志规范","link":"/tags/%E6%97%A5%E5%BF%97%E8%A7%84%E8%8C%83/"},{"name":"淘淘商城","slug":"淘淘商城","link":"/tags/%E6%B7%98%E6%B7%98%E5%95%86%E5%9F%8E/"},{"name":"FTP","slug":"FTP","link":"/tags/FTP/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"主题","slug":"主题","link":"/tags/%E4%B8%BB%E9%A2%98/"},{"name":"Chrome","slug":"Chrome","link":"/tags/Chrome/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"Mac技巧","slug":"Mac技巧","link":"/tags/Mac%E6%8A%80%E5%B7%A7/"},{"name":"Flutter","slug":"Flutter","link":"/tags/Flutter/"},{"name":"开源项目","slug":"开源项目","link":"/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Shiro","slug":"Shiro","link":"/tags/Shiro/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"GitHub Actions","slug":"GitHub-Actions","link":"/tags/GitHub-Actions/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Response","slug":"Response","link":"/tags/Response/"},{"name":"Request","slug":"Request","link":"/tags/Request/"},{"name":"EL","slug":"EL","link":"/tags/EL/"},{"name":"JSTL","slug":"JSTL","link":"/tags/JSTL/"},{"name":"AJAX","slug":"AJAX","link":"/tags/AJAX/"},{"name":"Cookie","slug":"Cookie","link":"/tags/Cookie/"},{"name":"Session","slug":"Session","link":"/tags/Session/"},{"name":"MySql","slug":"MySql","link":"/tags/MySql/"},{"name":"过滤器","slug":"过滤器","link":"/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"name":"MySQL必知必会","slug":"MySQL必知必会","link":"/tags/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"}],"categories":[{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"JavaEE","slug":"JavaEE","link":"/categories/JavaEE/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Simpleblog博客系统","slug":"Simpleblog博客系统","link":"/categories/Simpleblog%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/"},{"name":"持续集成","slug":"持续集成","link":"/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"工具教程","slug":"工具教程","link":"/categories/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/"},{"name":"日志","slug":"日志","link":"/categories/%E6%97%A5%E5%BF%97/"},{"name":"Chrome","slug":"Chrome","link":"/categories/Chrome/"},{"name":"Mac","slug":"Mac","link":"/categories/Mac/"},{"name":"Flutter","slug":"Flutter","link":"/categories/Flutter/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"Shiro","slug":"Shiro","link":"/categories/Shiro/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"并发","slug":"并发","link":"/categories/%E5%B9%B6%E5%8F%91/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"MySQL必知必会","slug":"MySQL必知必会","link":"/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/categories/SpringCloud/"}]}